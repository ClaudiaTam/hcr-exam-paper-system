{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNAfBs1g8TfyCrS4xY2Mhrs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Download EMNIST_Byclass dataset with capital letter only"],"metadata":{"id":"GAzGbtiQ4ASp"}},{"cell_type":"code","source":["import torch\n","import random\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from PIL import Image\n","import os\n","import shutil\n","\n","# Define the augmentation pipeline\n","transform = transforms.Compose([\n","    transforms.Lambda(lambda x: x.transpose(Image.FLIP_LEFT_RIGHT)),\n","    transforms.Lambda(lambda x: x.rotate(90)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,)),\n","])\n","\n","# Custom dataset class\n","class LettersOnlyDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","# Paths\n","output_folder = '/content/emnist_capitals_dataset'\n","\n","# EMNIST capital letters (labels 10-35 correspond to A-Z)\n","emnist_capitals = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n","\n","# Load and filter EMNIST dataset with 'byclass' split\n","print(\"Loading and filtering EMNIST dataset (this may take a moment)...\")\n","emnist_dataset = datasets.EMNIST('../data', split='byclass', train=True, download=True, transform=transform)\n","filtered_data = [(img, label) for img, label in emnist_dataset if 10 <= label <= 35]  # Filter for capitals only (10-35)\n","letters_dataset = LettersOnlyDataset(filtered_data)\n","\n","# Create folder structure and save images\n","if os.path.exists(output_folder):\n","    shutil.rmtree(output_folder)  # Remove existing folder if it exists\n","os.makedirs(output_folder)\n","\n","# Create sub-folders for each class\n","for char in emnist_capitals:\n","    os.makedirs(os.path.join(output_folder, char), exist_ok=True)\n","\n","# Save images to corresponding class folders\n","print(\"Saving images to folder structure...\")\n","for idx, (image, label) in enumerate(letters_dataset):\n","    # Reverse normalization\n","    image = image * 0.3081 + 0.1307\n","    image = image.squeeze().numpy()\n","\n","    # Convert to PIL Image\n","    image = (image * 255).astype(np.uint8)\n","    pil_image = Image.fromarray(image)\n","\n","    # Get character from label (adjust by subtracting 10 to map 10-35 to 0-25)\n","    char = emnist_capitals[label - 10]\n","\n","    # Save image\n","    image_path = os.path.join(output_folder, char, f'image_{idx}.png')\n","    pil_image.save(image_path)\n","\n","print(f\"Dataset saved to {output_folder}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKt1zfb6wpYD","executionInfo":{"status":"ok","timestamp":1743436965224,"user_tz":-480,"elapsed":290965,"user":{"displayName":"Ryan R","userId":"16966029236028814230"}},"outputId":"568bb4fa-cde3-4830-f399-bdabdc0392e4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading and filtering EMNIST dataset (this may take a moment)...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 562M/562M [00:32<00:00, 17.3MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving images to folder structure...\n","Dataset saved to /content/emnist_capitals_dataset\n"]}]},{"cell_type":"code","source":["import os\n","\n","data_path = '/content/emnist_capitals_dataset'\n","for char in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ':\n","    folder_path = os.path.join(data_path, char)\n","    num_images = len(os.listdir(folder_path))\n","    print(f\"Class {char}: {num_images} images\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5QOHhARyyyj","executionInfo":{"status":"ok","timestamp":1743436985157,"user_tz":-480,"elapsed":79,"user":{"displayName":"Ryan R","userId":"16966029236028814230"}},"outputId":"a5878421-97f6-4e70-fbb1-d5d8a575a8dc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Class A: 6407 images\n","Class B: 3878 images\n","Class C: 10094 images\n","Class D: 4562 images\n","Class E: 4934 images\n","Class F: 9182 images\n","Class G: 2517 images\n","Class H: 3152 images\n","Class I: 11946 images\n","Class J: 3762 images\n","Class K: 2468 images\n","Class L: 5076 images\n","Class M: 9002 images\n","Class N: 8237 images\n","Class O: 24983 images\n","Class P: 8347 images\n","Class Q: 2605 images\n","Class R: 5073 images\n","Class S: 20764 images\n","Class T: 9820 images\n","Class U: 12602 images\n","Class V: 4637 images\n","Class W: 4695 images\n","Class X: 2771 images\n","Class Y: 4743 images\n","Class Z: 2701 images\n"]}]},{"cell_type":"markdown","source":["# Download Custom dataset"],"metadata":{"id":"FvT25Gd_4M09"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WylW2Wad8b6X","executionInfo":{"status":"ok","timestamp":1743437048499,"user_tz":-480,"elapsed":26328,"user":{"displayName":"Ryan R","userId":"16966029236028814230"}},"outputId":"77c7eb46-6536-4339-975e-fb74903c88c2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Add this at the beginning of main()\n","import os\n","import shutil\n","\n","# Copy dataset from Google Drive to local storage\n","local_data_path = '/content/letters'\n","if not os.path.exists(local_data_path):\n","    shutil.copytree('/content/drive/MyDrive/data/letters', local_data_path)"],"metadata":{"id":"w71At5nq4T8q","executionInfo":{"status":"ok","timestamp":1743437247255,"user_tz":-480,"elapsed":143473,"user":{"displayName":"Ryan R","userId":"16966029236028814230"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Train the model"],"metadata":{"id":"ZzWbOrjM4RPP"}},{"cell_type":"markdown","source":["## Without custom dataset"],"metadata":{"id":"kxVjZmeo4g1_"}},{"cell_type":"code","source":["import os\n","import random\n","import argparse\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, random_split\n","from torch.optim.lr_scheduler import StepLR\n","import matplotlib.pyplot as plt\n","\n","# Define the neural network\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 64, 3, 1)  # Input channels: 1 (grayscale), Output channels: 64\n","        self.conv2 = nn.Conv2d(64, 128, 3, 1)  # Output channels: 128\n","        self.conv3 = nn.Conv2d(128, 256, 3, 1)  # Third convolutional layer\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.dropout2 = nn.Dropout(0.4)\n","        self.fc1 = nn.Linear(256 * 5 * 5, 512)  # Adjusted for 28x28 input after pooling\n","        self.fc2 = nn.Linear(512, 256)  # Additional fully connected layer\n","        self.fc3 = nn.Linear(256, 26)  # Output layer: 26 classes (A-Z)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.conv3(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        output = F.log_softmax(x, dim=1)\n","        return output\n","\n","# Custom transformation to add Salt-and-Pepper noise\n","class AddSaltPepperNoise:\n","    def __init__(self, salt_prob=0.01, pepper_prob=0.01):\n","        self.salt_prob = salt_prob\n","        self.pepper_prob = pepper_prob\n","\n","    def __call__(self, tensor):\n","        img = tensor.numpy()\n","        noise = np.random.random(img.shape)\n","        img[noise < self.salt_prob] = 1.0\n","        img[noise > (1 - self.pepper_prob)] = 0.0\n","        return torch.from_numpy(img)\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + '(salt_prob={0}, pepper_prob={1})'.format(self.salt_prob, self.pepper_prob)\n","\n","# Training Function with Class Weighting\n","def train(args, model, device, train_loader, optimizer, epoch, criterion):\n","    model.train()\n","    train_loss = 0\n","    correct = 0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        pred = output.argmax(dim=1, keepdim=True)\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","        if batch_idx % args.log_interval == 0:\n","            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n","\n","    train_loss /= len(train_loader)\n","    accuracy = 100. * correct / len(train_loader.dataset)\n","    return train_loss, accuracy\n","\n","# Testing Function with Class Weighting\n","def test(model, device, test_loader, criterion):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    class_correct = [0] * 26\n","    class_total = [0] * 26\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(test_loader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            batch_loss = criterion(output, target).item()\n","            test_loss += batch_loss\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","            if batch_idx == 0:\n","                print(f\"Sample outputs (log probs): {output[:5]}\")\n","                print(f\"Predicted classes: {pred[:5].view(-1)}\")\n","                print(f\"Target classes: {target[:5]}\")\n","\n","            for t, p in zip(target, pred):\n","                class_correct[t.item()] += (t == p).item()\n","                class_total[t.item()] += 1\n","\n","    avg_test_loss = test_loss / len(test_loader)\n","    accuracy = 100. * correct / len(test_loader.dataset)\n","\n","    print(f'\\nTest set: Average loss: {avg_test_loss:.6f}, Total sum loss: {test_loss:.6f}, '\n","          f'Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n')\n","    for i, char in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n","        if class_total[i] > 0:\n","            print(f'Class {char}: {class_correct[i]}/{class_total[i]} ({100. * class_correct[i] / class_total[i]:.0f}%)')\n","\n","    return avg_test_loss, accuracy\n","\n","# Train and Evaluate\n","def train_and_evaluate(args, model, device, train_loader, test_loader, optimizer, scheduler, criterion):\n","    test_losses = []\n","    test_accuracies = []\n","    train_losses = []\n","    train_accuracies = []\n","\n","    best_test_loss = float('inf')\n","    patience = 8\n","    no_improvement_count = 0\n","\n","    # Updated model directory path to Google Drive\n","    model_dir = f\"/content/drive/MyDrive/Capitals_Model_seed_{args.seed}\"\n","    if not os.path.exists(model_dir):\n","        os.makedirs(model_dir)\n","\n","    for epoch in range(1, args.epochs + 1):\n","        train_loss, train_accuracy = train(args, model, device, train_loader, optimizer, epoch, criterion)\n","        test_loss, test_accuracy = test(model, device, test_loader, criterion)\n","\n","        train_losses.append(train_loss)\n","        train_accuracies.append(train_accuracy)\n","        test_losses.append(test_loss)\n","        test_accuracies.append(test_accuracy)\n","\n","        if test_loss < best_test_loss:\n","            best_test_loss = test_loss\n","            no_improvement_count = 0\n","            if args.save_model and epoch > 1:\n","                model_filename = f\"capitals_cnn_epoch:{epoch}_test-accuracy:{test_accuracy:.4f}_test-loss:{test_loss:.4f}.pt\"\n","                model_path = os.path.join(model_dir, model_filename)\n","                try:\n","                    torch.save(model.state_dict(), model_path)\n","                    print(f\"Model saved with new best test loss: {best_test_loss:.4f} \\n\")\n","                except Exception as e:\n","                    print(f\"Error saving model: {e}\")\n","        else:\n","            no_improvement_count += 1\n","\n","        if no_improvement_count >= patience:\n","            print(f\"\\nEarly stopping triggered after {epoch} epochs. No improvement in test loss for {patience} consecutive epochs.\")\n","            break\n","\n","        scheduler.step()\n","\n","    return train_losses, train_accuracies, test_losses, test_accuracies\n","\n","# Plot results\n","def plot_results(train_losses, train_accuracies, test_losses, test_accuracies):\n","    epochs = range(1, len(train_losses) + 1)\n","    plt.figure(figsize=(12, 5))\n","\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, train_losses, 'o-', label='Train Loss')\n","    plt.plot(epochs, test_losses, 'o-', label='Test Loss')\n","    plt.title('Loss vs. Epoch')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, train_accuracies, 'o-', label='Train Accuracy')\n","    plt.plot(epochs, test_accuracies, 'o-', label='Test Accuracy')\n","    plt.title('Accuracy vs. Epoch')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy (%)')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Main function\n","def main():\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    random_seed = random.randint(0, 100000)\n","    print(f\"Using random seed: {random_seed}\")\n","\n","    torch.manual_seed(random_seed)\n","    random.seed(random_seed)\n","\n","    args = argparse.Namespace(\n","        batch_size=64,\n","        test_batch_size=128,\n","        epochs=100,\n","        lr=1,\n","        gamma=0.9,\n","        no_cuda=False,\n","        no_mps=False,\n","        dry_run=False,\n","        seed=random_seed,\n","        log_interval=10,\n","        save_model=True\n","    )\n","\n","    use_cuda = not args.no_cuda and torch.cuda.is_available()\n","    use_mps = not args.no_mps and torch.backends.mps.is_available()\n","\n","    torch.manual_seed(args.seed)\n","\n","    if use_cuda:\n","        device = torch.device(\"cuda\")\n","    elif use_mps:\n","        device = torch.device(\"mps\")\n","    else:\n","        device = torch.device(\"cpu\")\n","\n","    train_kwargs = {'batch_size': args.batch_size}\n","    test_kwargs = {'batch_size': args.test_batch_size}\n","\n","    if use_cuda:\n","        cuda_kwargs = {'num_workers': 1, 'pin_memory': True, 'shuffle': True}\n","        train_kwargs.update(cuda_kwargs)\n","        test_kwargs.update(cuda_kwargs)\n","\n","    transform_train = transforms.Compose([\n","        transforms.Grayscale(),\n","        transforms.Resize((28, 28)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,)),\n","        transforms.RandomAffine(degrees=(-5, 5), translate=(0.1, 0.1), scale=(0.9, 1.1), shear=5),\n","        transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1)], p=0.3),\n","        transforms.RandomApply([AddSaltPepperNoise(salt_prob=0.01, pepper_prob=0.01)], p=0.2)\n","    ])\n","\n","    transform_test = transforms.Compose([\n","        transforms.Grayscale(),\n","        transforms.Resize((28, 28)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,))\n","    ])\n","\n","    data_path = '/content/emnist_capitals_dataset'\n","    capitals_dataset = datasets.ImageFolder(root=data_path, transform=transform_train)\n","\n","    train_size = int(0.8 * len(capitals_dataset))\n","    test_size = len(capitals_dataset) - train_size\n","    train_dataset, test_dataset = random_split(capitals_dataset, [train_size, test_size])\n","\n","    test_dataset.dataset.transform = transform_test\n","\n","    class_counts = [6407, 3878, 10094, 4562, 4934, 9182, 2517, 3152, 11946, 3762, 2468, 5076,\n","                    9002, 8237, 24983, 8347, 2605, 5073, 20764, 9820, 12602, 4637, 4695, 2771, 4743, 2701]\n","    class_weights = torch.tensor([1.0 / count for count in class_counts], dtype=torch.float).to(device)\n","    criterion = nn.NLLLoss(weight=class_weights, reduction='sum')\n","\n","    train_loader = DataLoader(train_dataset, **train_kwargs)\n","    test_loader = DataLoader(test_dataset, **test_kwargs)\n","\n","    model = Net().to(device)\n","    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n","    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n","\n","    train_losses, train_accuracies, test_losses, test_accuracies = train_and_evaluate(\n","        args, model, device, train_loader, test_loader, optimizer, scheduler, criterion\n","    )\n","\n","    plot_results(train_losses, train_accuracies, test_losses, test_accuracies)\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"0OHkYAhzxFvN","executionInfo":{"status":"error","timestamp":1743421155997,"user_tz":-480,"elapsed":2117402,"user":{"displayName":"Ryan R","userId":"16966029236028814230"}},"outputId":"1ca45ceb-731e-4c33-c404-d96b0bab4607"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43m串流輸出內容已截斷至最後 5000 行。\u001b[0m\n","Train Epoch: 4 [87040/151166 (58%)]\tLoss: 0.001285\n","Train Epoch: 4 [87680/151166 (58%)]\tLoss: 0.001464\n","Train Epoch: 4 [88320/151166 (58%)]\tLoss: 0.001075\n","Train Epoch: 4 [88960/151166 (59%)]\tLoss: 0.003061\n","Train Epoch: 4 [89600/151166 (59%)]\tLoss: 0.000767\n","Train Epoch: 4 [90240/151166 (60%)]\tLoss: 0.001824\n","Train Epoch: 4 [90880/151166 (60%)]\tLoss: 0.000905\n","Train Epoch: 4 [91520/151166 (61%)]\tLoss: 0.001543\n","Train Epoch: 4 [92160/151166 (61%)]\tLoss: 0.000584\n","Train Epoch: 4 [92800/151166 (61%)]\tLoss: 0.000982\n","Train Epoch: 4 [93440/151166 (62%)]\tLoss: 0.000650\n","Train Epoch: 4 [94080/151166 (62%)]\tLoss: 0.001735\n","Train Epoch: 4 [94720/151166 (63%)]\tLoss: 0.003665\n","Train Epoch: 4 [95360/151166 (63%)]\tLoss: 0.001738\n","Train Epoch: 4 [96000/151166 (64%)]\tLoss: 0.002788\n","Train Epoch: 4 [96640/151166 (64%)]\tLoss: 0.000420\n","Train Epoch: 4 [97280/151166 (64%)]\tLoss: 0.000735\n","Train Epoch: 4 [97920/151166 (65%)]\tLoss: 0.000902\n","Train Epoch: 4 [98560/151166 (65%)]\tLoss: 0.000962\n","Train Epoch: 4 [99200/151166 (66%)]\tLoss: 0.001996\n","Train Epoch: 4 [99840/151166 (66%)]\tLoss: 0.000733\n","Train Epoch: 4 [100480/151166 (66%)]\tLoss: 0.000706\n","Train Epoch: 4 [101120/151166 (67%)]\tLoss: 0.001419\n","Train Epoch: 4 [101760/151166 (67%)]\tLoss: 0.000438\n","Train Epoch: 4 [102400/151166 (68%)]\tLoss: 0.000904\n","Train Epoch: 4 [103040/151166 (68%)]\tLoss: 0.002313\n","Train Epoch: 4 [103680/151166 (69%)]\tLoss: 0.000370\n","Train Epoch: 4 [104320/151166 (69%)]\tLoss: 0.002300\n","Train Epoch: 4 [104960/151166 (69%)]\tLoss: 0.001733\n","Train Epoch: 4 [105600/151166 (70%)]\tLoss: 0.001508\n","Train Epoch: 4 [106240/151166 (70%)]\tLoss: 0.000867\n","Train Epoch: 4 [106880/151166 (71%)]\tLoss: 0.003701\n","Train Epoch: 4 [107520/151166 (71%)]\tLoss: 0.002155\n","Train Epoch: 4 [108160/151166 (72%)]\tLoss: 0.001508\n","Train Epoch: 4 [108800/151166 (72%)]\tLoss: 0.001071\n","Train Epoch: 4 [109440/151166 (72%)]\tLoss: 0.001409\n","Train Epoch: 4 [110080/151166 (73%)]\tLoss: 0.001141\n","Train Epoch: 4 [110720/151166 (73%)]\tLoss: 0.000934\n","Train Epoch: 4 [111360/151166 (74%)]\tLoss: 0.000736\n","Train Epoch: 4 [112000/151166 (74%)]\tLoss: 0.000806\n","Train Epoch: 4 [112640/151166 (75%)]\tLoss: 0.004222\n","Train Epoch: 4 [113280/151166 (75%)]\tLoss: 0.001134\n","Train Epoch: 4 [113920/151166 (75%)]\tLoss: 0.000974\n","Train Epoch: 4 [114560/151166 (76%)]\tLoss: 0.002001\n","Train Epoch: 4 [115200/151166 (76%)]\tLoss: 0.002642\n","Train Epoch: 4 [115840/151166 (77%)]\tLoss: 0.001381\n","Train Epoch: 4 [116480/151166 (77%)]\tLoss: 0.002730\n","Train Epoch: 4 [117120/151166 (77%)]\tLoss: 0.000550\n","Train Epoch: 4 [117760/151166 (78%)]\tLoss: 0.001380\n","Train Epoch: 4 [118400/151166 (78%)]\tLoss: 0.001282\n","Train Epoch: 4 [119040/151166 (79%)]\tLoss: 0.001275\n","Train Epoch: 4 [119680/151166 (79%)]\tLoss: 0.004137\n","Train Epoch: 4 [120320/151166 (80%)]\tLoss: 0.002450\n","Train Epoch: 4 [120960/151166 (80%)]\tLoss: 0.001928\n","Train Epoch: 4 [121600/151166 (80%)]\tLoss: 0.000865\n","Train Epoch: 4 [122240/151166 (81%)]\tLoss: 0.002559\n","Train Epoch: 4 [122880/151166 (81%)]\tLoss: 0.001567\n","Train Epoch: 4 [123520/151166 (82%)]\tLoss: 0.001459\n","Train Epoch: 4 [124160/151166 (82%)]\tLoss: 0.002218\n","Train Epoch: 4 [124800/151166 (83%)]\tLoss: 0.003284\n","Train Epoch: 4 [125440/151166 (83%)]\tLoss: 0.003416\n","Train Epoch: 4 [126080/151166 (83%)]\tLoss: 0.002336\n","Train Epoch: 4 [126720/151166 (84%)]\tLoss: 0.001159\n","Train Epoch: 4 [127360/151166 (84%)]\tLoss: 0.001578\n","Train Epoch: 4 [128000/151166 (85%)]\tLoss: 0.004959\n","Train Epoch: 4 [128640/151166 (85%)]\tLoss: 0.000856\n","Train Epoch: 4 [129280/151166 (86%)]\tLoss: 0.001034\n","Train Epoch: 4 [129920/151166 (86%)]\tLoss: 0.000658\n","Train Epoch: 4 [130560/151166 (86%)]\tLoss: 0.003200\n","Train Epoch: 4 [131200/151166 (87%)]\tLoss: 0.001391\n","Train Epoch: 4 [131840/151166 (87%)]\tLoss: 0.001172\n","Train Epoch: 4 [132480/151166 (88%)]\tLoss: 0.002853\n","Train Epoch: 4 [133120/151166 (88%)]\tLoss: 0.000525\n","Train Epoch: 4 [133760/151166 (88%)]\tLoss: 0.000999\n","Train Epoch: 4 [134400/151166 (89%)]\tLoss: 0.001011\n","Train Epoch: 4 [135040/151166 (89%)]\tLoss: 0.004290\n","Train Epoch: 4 [135680/151166 (90%)]\tLoss: 0.000849\n","Train Epoch: 4 [136320/151166 (90%)]\tLoss: 0.001951\n","Train Epoch: 4 [136960/151166 (91%)]\tLoss: 0.001310\n","Train Epoch: 4 [137600/151166 (91%)]\tLoss: 0.001174\n","Train Epoch: 4 [138240/151166 (91%)]\tLoss: 0.000624\n","Train Epoch: 4 [138880/151166 (92%)]\tLoss: 0.000648\n","Train Epoch: 4 [139520/151166 (92%)]\tLoss: 0.002065\n","Train Epoch: 4 [140160/151166 (93%)]\tLoss: 0.000853\n","Train Epoch: 4 [140800/151166 (93%)]\tLoss: 0.002835\n","Train Epoch: 4 [141440/151166 (94%)]\tLoss: 0.000419\n","Train Epoch: 4 [142080/151166 (94%)]\tLoss: 0.000771\n","Train Epoch: 4 [142720/151166 (94%)]\tLoss: 0.001034\n","Train Epoch: 4 [143360/151166 (95%)]\tLoss: 0.001004\n","Train Epoch: 4 [144000/151166 (95%)]\tLoss: 0.001040\n","Train Epoch: 4 [144640/151166 (96%)]\tLoss: 0.000559\n","Train Epoch: 4 [145280/151166 (96%)]\tLoss: 0.001108\n","Train Epoch: 4 [145920/151166 (97%)]\tLoss: 0.000971\n","Train Epoch: 4 [146560/151166 (97%)]\tLoss: 0.001160\n","Train Epoch: 4 [147200/151166 (97%)]\tLoss: 0.003892\n","Train Epoch: 4 [147840/151166 (98%)]\tLoss: 0.001105\n","Train Epoch: 4 [148480/151166 (98%)]\tLoss: 0.000887\n","Train Epoch: 4 [149120/151166 (99%)]\tLoss: 0.002059\n","Train Epoch: 4 [149760/151166 (99%)]\tLoss: 0.000761\n","Train Epoch: 4 [150400/151166 (99%)]\tLoss: 0.001480\n","Train Epoch: 4 [151040/151166 (100%)]\tLoss: 0.001964\n","Sample outputs (log probs): tensor([[-2.0573e+01, -1.6928e+01, -1.8017e+01, -2.0742e+01, -1.5582e+01,\n","         -1.9174e+01, -2.4049e+01, -2.7157e+01, -1.1387e+01, -2.0137e+01,\n","         -1.8957e+01, -1.4231e+01, -2.5606e+01, -2.4423e+01, -2.8352e+01,\n","         -2.1264e+01, -2.3894e+01, -1.1779e+01, -2.5407e+01, -1.7029e+01,\n","         -1.5844e+01, -2.1408e+01, -2.6079e+01, -1.0852e+01, -2.1304e+01,\n","         -3.9457e-05],\n","        [-9.8197e+00, -1.2164e+01, -9.0114e+00, -1.5829e+01, -1.2012e+01,\n","         -3.9447e+00, -1.4093e+01, -1.7137e+01, -1.5048e+01, -2.0045e+01,\n","         -1.8997e+01, -2.2795e+01, -2.1067e+01, -2.1653e+01, -1.5249e+01,\n","         -2.0030e-02, -1.2799e+01, -8.7197e+00, -1.6925e+01, -9.0533e+00,\n","         -2.4361e+01, -1.7412e+01, -2.5891e+01, -2.3648e+01, -1.3886e+01,\n","         -1.3869e+01],\n","        [-7.5632e+00, -1.4828e+01, -1.9862e+01, -1.3249e+01, -2.0999e+01,\n","         -1.5036e+01, -1.7486e+01, -4.8284e+00, -1.3453e+01, -1.3829e+01,\n","         -1.7311e+01, -1.5843e+01, -1.0670e+01, -1.3284e-01, -1.8118e+01,\n","         -1.1656e+01, -1.1242e+01, -1.0579e+01, -1.8138e+01, -1.5443e+01,\n","         -1.1058e+01, -1.3201e+01, -2.1560e+00, -1.4088e+01, -1.7591e+01,\n","         -1.8846e+01],\n","        [-2.7949e+01, -2.5402e+01, -1.9287e+01, -1.6346e+01, -2.1620e+01,\n","         -1.3694e+01, -2.9433e+01, -3.2586e+01, -9.8800e+00, -7.8855e+00,\n","         -2.4876e+01, -2.5561e+01, -2.4184e+01, -2.0269e+01, -2.2646e+01,\n","         -1.5576e+01, -2.6498e+01, -2.4691e+01, -2.3245e+01, -4.3192e-04,\n","         -2.2380e+01, -1.5002e+01, -2.4467e+01, -1.7716e+01, -1.2933e+01,\n","         -1.5115e+01],\n","        [-1.1602e+01, -7.7681e+00, -7.1326e+00, -7.6360e+00, -9.8110e+00,\n","         -1.4989e+01, -1.1959e+01, -1.6919e+01, -1.1018e+01, -1.2063e+01,\n","         -1.7867e+01, -1.7312e+01, -1.3338e+01, -1.3770e+01, -1.9607e-03,\n","         -1.2979e+01, -1.0184e+01, -1.3229e+01, -9.1463e+00, -1.4214e+01,\n","         -1.1729e+01, -1.4699e+01, -1.7306e+01, -2.0943e+01, -1.4339e+01,\n","         -1.4583e+01]], device='cuda:0')\n","Predicted classes: tensor([25, 15, 13, 19, 14], device='cuda:0')\n","Target classes: tensor([25, 15, 13, 19, 14], device='cuda:0')\n","\n","Test set: Average loss: 0.002259, Total sum loss: 0.668606, Accuracy: 36511/37792 (97%)\n","\n","Class A: 1203/1247 (96%)\n","Class B: 786/816 (96%)\n","Class C: 1897/1965 (97%)\n","Class D: 794/868 (91%)\n","Class E: 998/1024 (97%)\n","Class F: 1821/1869 (97%)\n","Class G: 498/519 (96%)\n","Class H: 596/621 (96%)\n","Class I: 2375/2410 (99%)\n","Class J: 719/754 (95%)\n","Class K: 472/502 (94%)\n","Class L: 966/987 (98%)\n","Class M: 1735/1774 (98%)\n","Class N: 1537/1622 (95%)\n","Class O: 4859/5064 (96%)\n","Class P: 1562/1615 (97%)\n","Class Q: 511/536 (95%)\n","Class R: 957/992 (96%)\n","Class S: 4151/4228 (98%)\n","Class T: 1908/1932 (99%)\n","Class U: 2477/2598 (95%)\n","Class V: 837/904 (93%)\n","Class W: 905/938 (96%)\n","Class X: 549/560 (98%)\n","Class Y: 884/924 (96%)\n","Class Z: 514/523 (98%)\n","Model saved with new best test loss: 0.0023 \n","\n","Train Epoch: 5 [0/151166 (0%)]\tLoss: 0.000862\n","Train Epoch: 5 [640/151166 (0%)]\tLoss: 0.002051\n","Train Epoch: 5 [1280/151166 (1%)]\tLoss: 0.000692\n","Train Epoch: 5 [1920/151166 (1%)]\tLoss: 0.002439\n","Train Epoch: 5 [2560/151166 (2%)]\tLoss: 0.001036\n","Train Epoch: 5 [3200/151166 (2%)]\tLoss: 0.001141\n","Train Epoch: 5 [3840/151166 (3%)]\tLoss: 0.001428\n","Train Epoch: 5 [4480/151166 (3%)]\tLoss: 0.001263\n","Train Epoch: 5 [5120/151166 (3%)]\tLoss: 0.000602\n","Train Epoch: 5 [5760/151166 (4%)]\tLoss: 0.004396\n","Train Epoch: 5 [6400/151166 (4%)]\tLoss: 0.001689\n","Train Epoch: 5 [7040/151166 (5%)]\tLoss: 0.001735\n","Train Epoch: 5 [7680/151166 (5%)]\tLoss: 0.001212\n","Train Epoch: 5 [8320/151166 (6%)]\tLoss: 0.001457\n","Train Epoch: 5 [8960/151166 (6%)]\tLoss: 0.000203\n","Train Epoch: 5 [9600/151166 (6%)]\tLoss: 0.000743\n","Train Epoch: 5 [10240/151166 (7%)]\tLoss: 0.001122\n","Train Epoch: 5 [10880/151166 (7%)]\tLoss: 0.002529\n","Train Epoch: 5 [11520/151166 (8%)]\tLoss: 0.000368\n","Train Epoch: 5 [12160/151166 (8%)]\tLoss: 0.000768\n","Train Epoch: 5 [12800/151166 (8%)]\tLoss: 0.002222\n","Train Epoch: 5 [13440/151166 (9%)]\tLoss: 0.000521\n","Train Epoch: 5 [14080/151166 (9%)]\tLoss: 0.001541\n","Train Epoch: 5 [14720/151166 (10%)]\tLoss: 0.000803\n","Train Epoch: 5 [15360/151166 (10%)]\tLoss: 0.000935\n","Train Epoch: 5 [16000/151166 (11%)]\tLoss: 0.000716\n","Train Epoch: 5 [16640/151166 (11%)]\tLoss: 0.000651\n","Train Epoch: 5 [17280/151166 (11%)]\tLoss: 0.000862\n","Train Epoch: 5 [17920/151166 (12%)]\tLoss: 0.001902\n","Train Epoch: 5 [18560/151166 (12%)]\tLoss: 0.001594\n","Train Epoch: 5 [19200/151166 (13%)]\tLoss: 0.002258\n","Train Epoch: 5 [19840/151166 (13%)]\tLoss: 0.000820\n","Train Epoch: 5 [20480/151166 (14%)]\tLoss: 0.000821\n","Train Epoch: 5 [21120/151166 (14%)]\tLoss: 0.001459\n","Train Epoch: 5 [21760/151166 (14%)]\tLoss: 0.000815\n","Train Epoch: 5 [22400/151166 (15%)]\tLoss: 0.000961\n","Train Epoch: 5 [23040/151166 (15%)]\tLoss: 0.000553\n","Train Epoch: 5 [23680/151166 (16%)]\tLoss: 0.002042\n","Train Epoch: 5 [24320/151166 (16%)]\tLoss: 0.000372\n","Train Epoch: 5 [24960/151166 (17%)]\tLoss: 0.000522\n","Train Epoch: 5 [25600/151166 (17%)]\tLoss: 0.000761\n","Train Epoch: 5 [26240/151166 (17%)]\tLoss: 0.000348\n","Train Epoch: 5 [26880/151166 (18%)]\tLoss: 0.001322\n","Train Epoch: 5 [27520/151166 (18%)]\tLoss: 0.001487\n","Train Epoch: 5 [28160/151166 (19%)]\tLoss: 0.002349\n","Train Epoch: 5 [28800/151166 (19%)]\tLoss: 0.000730\n","Train Epoch: 5 [29440/151166 (19%)]\tLoss: 0.002267\n","Train Epoch: 5 [30080/151166 (20%)]\tLoss: 0.001266\n","Train Epoch: 5 [30720/151166 (20%)]\tLoss: 0.000781\n","Train Epoch: 5 [31360/151166 (21%)]\tLoss: 0.001477\n","Train Epoch: 5 [32000/151166 (21%)]\tLoss: 0.000251\n","Train Epoch: 5 [32640/151166 (22%)]\tLoss: 0.001023\n","Train Epoch: 5 [33280/151166 (22%)]\tLoss: 0.000922\n","Train Epoch: 5 [33920/151166 (22%)]\tLoss: 0.000280\n","Train Epoch: 5 [34560/151166 (23%)]\tLoss: 0.001737\n","Train Epoch: 5 [35200/151166 (23%)]\tLoss: 0.000263\n","Train Epoch: 5 [35840/151166 (24%)]\tLoss: 0.001064\n","Train Epoch: 5 [36480/151166 (24%)]\tLoss: 0.002037\n","Train Epoch: 5 [37120/151166 (25%)]\tLoss: 0.000652\n","Train Epoch: 5 [37760/151166 (25%)]\tLoss: 0.001922\n","Train Epoch: 5 [38400/151166 (25%)]\tLoss: 0.003441\n","Train Epoch: 5 [39040/151166 (26%)]\tLoss: 0.001271\n","Train Epoch: 5 [39680/151166 (26%)]\tLoss: 0.000454\n","Train Epoch: 5 [40320/151166 (27%)]\tLoss: 0.001224\n","Train Epoch: 5 [40960/151166 (27%)]\tLoss: 0.001678\n","Train Epoch: 5 [41600/151166 (28%)]\tLoss: 0.001738\n","Train Epoch: 5 [42240/151166 (28%)]\tLoss: 0.001442\n","Train Epoch: 5 [42880/151166 (28%)]\tLoss: 0.001635\n","Train Epoch: 5 [43520/151166 (29%)]\tLoss: 0.000393\n","Train Epoch: 5 [44160/151166 (29%)]\tLoss: 0.000767\n","Train Epoch: 5 [44800/151166 (30%)]\tLoss: 0.000358\n","Train Epoch: 5 [45440/151166 (30%)]\tLoss: 0.000600\n","Train Epoch: 5 [46080/151166 (30%)]\tLoss: 0.000324\n","Train Epoch: 5 [46720/151166 (31%)]\tLoss: 0.000545\n","Train Epoch: 5 [47360/151166 (31%)]\tLoss: 0.002021\n","Train Epoch: 5 [48000/151166 (32%)]\tLoss: 0.001237\n","Train Epoch: 5 [48640/151166 (32%)]\tLoss: 0.000918\n","Train Epoch: 5 [49280/151166 (33%)]\tLoss: 0.001591\n","Train Epoch: 5 [49920/151166 (33%)]\tLoss: 0.002360\n","Train Epoch: 5 [50560/151166 (33%)]\tLoss: 0.001098\n","Train Epoch: 5 [51200/151166 (34%)]\tLoss: 0.001173\n","Train Epoch: 5 [51840/151166 (34%)]\tLoss: 0.000596\n","Train Epoch: 5 [52480/151166 (35%)]\tLoss: 0.001391\n","Train Epoch: 5 [53120/151166 (35%)]\tLoss: 0.002689\n","Train Epoch: 5 [53760/151166 (36%)]\tLoss: 0.001095\n","Train Epoch: 5 [54400/151166 (36%)]\tLoss: 0.000652\n","Train Epoch: 5 [55040/151166 (36%)]\tLoss: 0.001876\n","Train Epoch: 5 [55680/151166 (37%)]\tLoss: 0.000876\n","Train Epoch: 5 [56320/151166 (37%)]\tLoss: 0.001080\n","Train Epoch: 5 [56960/151166 (38%)]\tLoss: 0.000525\n","Train Epoch: 5 [57600/151166 (38%)]\tLoss: 0.000796\n","Train Epoch: 5 [58240/151166 (39%)]\tLoss: 0.000507\n","Train Epoch: 5 [58880/151166 (39%)]\tLoss: 0.000485\n","Train Epoch: 5 [59520/151166 (39%)]\tLoss: 0.000848\n","Train Epoch: 5 [60160/151166 (40%)]\tLoss: 0.001585\n","Train Epoch: 5 [60800/151166 (40%)]\tLoss: 0.001921\n","Train Epoch: 5 [61440/151166 (41%)]\tLoss: 0.002028\n","Train Epoch: 5 [62080/151166 (41%)]\tLoss: 0.000550\n","Train Epoch: 5 [62720/151166 (41%)]\tLoss: 0.000561\n","Train Epoch: 5 [63360/151166 (42%)]\tLoss: 0.001190\n","Train Epoch: 5 [64000/151166 (42%)]\tLoss: 0.000272\n","Train Epoch: 5 [64640/151166 (43%)]\tLoss: 0.000213\n","Train Epoch: 5 [65280/151166 (43%)]\tLoss: 0.001431\n","Train Epoch: 5 [65920/151166 (44%)]\tLoss: 0.000981\n","Train Epoch: 5 [66560/151166 (44%)]\tLoss: 0.000788\n","Train Epoch: 5 [67200/151166 (44%)]\tLoss: 0.001580\n","Train Epoch: 5 [67840/151166 (45%)]\tLoss: 0.001518\n","Train Epoch: 5 [68480/151166 (45%)]\tLoss: 0.000553\n","Train Epoch: 5 [69120/151166 (46%)]\tLoss: 0.000248\n","Train Epoch: 5 [69760/151166 (46%)]\tLoss: 0.001959\n","Train Epoch: 5 [70400/151166 (47%)]\tLoss: 0.001545\n","Train Epoch: 5 [71040/151166 (47%)]\tLoss: 0.002395\n","Train Epoch: 5 [71680/151166 (47%)]\tLoss: 0.000260\n","Train Epoch: 5 [72320/151166 (48%)]\tLoss: 0.000738\n","Train Epoch: 5 [72960/151166 (48%)]\tLoss: 0.000643\n","Train Epoch: 5 [73600/151166 (49%)]\tLoss: 0.001511\n","Train Epoch: 5 [74240/151166 (49%)]\tLoss: 0.000712\n","Train Epoch: 5 [74880/151166 (50%)]\tLoss: 0.000472\n","Train Epoch: 5 [75520/151166 (50%)]\tLoss: 0.001084\n","Train Epoch: 5 [76160/151166 (50%)]\tLoss: 0.001103\n","Train Epoch: 5 [76800/151166 (51%)]\tLoss: 0.000479\n","Train Epoch: 5 [77440/151166 (51%)]\tLoss: 0.005006\n","Train Epoch: 5 [78080/151166 (52%)]\tLoss: 0.001526\n","Train Epoch: 5 [78720/151166 (52%)]\tLoss: 0.000957\n","Train Epoch: 5 [79360/151166 (52%)]\tLoss: 0.000529\n","Train Epoch: 5 [80000/151166 (53%)]\tLoss: 0.001497\n","Train Epoch: 5 [80640/151166 (53%)]\tLoss: 0.000330\n","Train Epoch: 5 [81280/151166 (54%)]\tLoss: 0.000671\n","Train Epoch: 5 [81920/151166 (54%)]\tLoss: 0.001095\n","Train Epoch: 5 [82560/151166 (55%)]\tLoss: 0.001109\n","Train Epoch: 5 [83200/151166 (55%)]\tLoss: 0.001356\n","Train Epoch: 5 [83840/151166 (55%)]\tLoss: 0.001671\n","Train Epoch: 5 [84480/151166 (56%)]\tLoss: 0.001256\n","Train Epoch: 5 [85120/151166 (56%)]\tLoss: 0.001050\n","Train Epoch: 5 [85760/151166 (57%)]\tLoss: 0.001450\n","Train Epoch: 5 [86400/151166 (57%)]\tLoss: 0.000844\n","Train Epoch: 5 [87040/151166 (58%)]\tLoss: 0.002575\n","Train Epoch: 5 [87680/151166 (58%)]\tLoss: 0.001206\n","Train Epoch: 5 [88320/151166 (58%)]\tLoss: 0.000248\n","Train Epoch: 5 [88960/151166 (59%)]\tLoss: 0.000558\n","Train Epoch: 5 [89600/151166 (59%)]\tLoss: 0.001487\n","Train Epoch: 5 [90240/151166 (60%)]\tLoss: 0.001939\n","Train Epoch: 5 [90880/151166 (60%)]\tLoss: 0.002860\n","Train Epoch: 5 [91520/151166 (61%)]\tLoss: 0.000637\n","Train Epoch: 5 [92160/151166 (61%)]\tLoss: 0.001096\n","Train Epoch: 5 [92800/151166 (61%)]\tLoss: 0.000239\n","Train Epoch: 5 [93440/151166 (62%)]\tLoss: 0.001078\n","Train Epoch: 5 [94080/151166 (62%)]\tLoss: 0.000498\n","Train Epoch: 5 [94720/151166 (63%)]\tLoss: 0.000991\n","Train Epoch: 5 [95360/151166 (63%)]\tLoss: 0.001887\n","Train Epoch: 5 [96000/151166 (64%)]\tLoss: 0.000594\n","Train Epoch: 5 [96640/151166 (64%)]\tLoss: 0.002117\n","Train Epoch: 5 [97280/151166 (64%)]\tLoss: 0.000611\n","Train Epoch: 5 [97920/151166 (65%)]\tLoss: 0.000889\n","Train Epoch: 5 [98560/151166 (65%)]\tLoss: 0.001427\n","Train Epoch: 5 [99200/151166 (66%)]\tLoss: 0.000459\n","Train Epoch: 5 [99840/151166 (66%)]\tLoss: 0.000647\n","Train Epoch: 5 [100480/151166 (66%)]\tLoss: 0.001260\n","Train Epoch: 5 [101120/151166 (67%)]\tLoss: 0.000421\n","Train Epoch: 5 [101760/151166 (67%)]\tLoss: 0.000403\n","Train Epoch: 5 [102400/151166 (68%)]\tLoss: 0.000461\n","Train Epoch: 5 [103040/151166 (68%)]\tLoss: 0.001256\n","Train Epoch: 5 [103680/151166 (69%)]\tLoss: 0.000553\n","Train Epoch: 5 [104320/151166 (69%)]\tLoss: 0.002729\n","Train Epoch: 5 [104960/151166 (69%)]\tLoss: 0.001194\n","Train Epoch: 5 [105600/151166 (70%)]\tLoss: 0.000550\n","Train Epoch: 5 [106240/151166 (70%)]\tLoss: 0.000828\n","Train Epoch: 5 [106880/151166 (71%)]\tLoss: 0.001271\n","Train Epoch: 5 [107520/151166 (71%)]\tLoss: 0.000497\n","Train Epoch: 5 [108160/151166 (72%)]\tLoss: 0.000772\n","Train Epoch: 5 [108800/151166 (72%)]\tLoss: 0.002470\n","Train Epoch: 5 [109440/151166 (72%)]\tLoss: 0.001736\n","Train Epoch: 5 [110080/151166 (73%)]\tLoss: 0.001760\n","Train Epoch: 5 [110720/151166 (73%)]\tLoss: 0.000373\n","Train Epoch: 5 [111360/151166 (74%)]\tLoss: 0.004293\n","Train Epoch: 5 [112000/151166 (74%)]\tLoss: 0.000501\n","Train Epoch: 5 [112640/151166 (75%)]\tLoss: 0.001190\n","Train Epoch: 5 [113280/151166 (75%)]\tLoss: 0.001620\n","Train Epoch: 5 [113920/151166 (75%)]\tLoss: 0.002247\n","Train Epoch: 5 [114560/151166 (76%)]\tLoss: 0.000906\n","Train Epoch: 5 [115200/151166 (76%)]\tLoss: 0.001092\n","Train Epoch: 5 [115840/151166 (77%)]\tLoss: 0.000268\n","Train Epoch: 5 [116480/151166 (77%)]\tLoss: 0.000592\n","Train Epoch: 5 [117120/151166 (77%)]\tLoss: 0.002458\n","Train Epoch: 5 [117760/151166 (78%)]\tLoss: 0.000959\n","Train Epoch: 5 [118400/151166 (78%)]\tLoss: 0.000741\n","Train Epoch: 5 [119040/151166 (79%)]\tLoss: 0.001496\n","Train Epoch: 5 [119680/151166 (79%)]\tLoss: 0.000302\n","Train Epoch: 5 [120320/151166 (80%)]\tLoss: 0.000820\n","Train Epoch: 5 [120960/151166 (80%)]\tLoss: 0.001229\n","Train Epoch: 5 [121600/151166 (80%)]\tLoss: 0.000705\n","Train Epoch: 5 [122240/151166 (81%)]\tLoss: 0.000589\n","Train Epoch: 5 [122880/151166 (81%)]\tLoss: 0.002362\n","Train Epoch: 5 [123520/151166 (82%)]\tLoss: 0.003501\n","Train Epoch: 5 [124160/151166 (82%)]\tLoss: 0.000322\n","Train Epoch: 5 [124800/151166 (83%)]\tLoss: 0.000212\n","Train Epoch: 5 [125440/151166 (83%)]\tLoss: 0.000987\n","Train Epoch: 5 [126080/151166 (83%)]\tLoss: 0.001893\n","Train Epoch: 5 [126720/151166 (84%)]\tLoss: 0.000843\n","Train Epoch: 5 [127360/151166 (84%)]\tLoss: 0.001560\n","Train Epoch: 5 [128000/151166 (85%)]\tLoss: 0.000772\n","Train Epoch: 5 [128640/151166 (85%)]\tLoss: 0.001094\n","Train Epoch: 5 [129280/151166 (86%)]\tLoss: 0.001911\n","Train Epoch: 5 [129920/151166 (86%)]\tLoss: 0.000292\n","Train Epoch: 5 [130560/151166 (86%)]\tLoss: 0.001414\n","Train Epoch: 5 [131200/151166 (87%)]\tLoss: 0.001262\n","Train Epoch: 5 [131840/151166 (87%)]\tLoss: 0.000885\n","Train Epoch: 5 [132480/151166 (88%)]\tLoss: 0.002423\n","Train Epoch: 5 [133120/151166 (88%)]\tLoss: 0.001678\n","Train Epoch: 5 [133760/151166 (88%)]\tLoss: 0.000613\n","Train Epoch: 5 [134400/151166 (89%)]\tLoss: 0.000556\n","Train Epoch: 5 [135040/151166 (89%)]\tLoss: 0.000782\n","Train Epoch: 5 [135680/151166 (90%)]\tLoss: 0.001562\n","Train Epoch: 5 [136320/151166 (90%)]\tLoss: 0.002242\n","Train Epoch: 5 [136960/151166 (91%)]\tLoss: 0.001710\n","Train Epoch: 5 [137600/151166 (91%)]\tLoss: 0.000646\n","Train Epoch: 5 [138240/151166 (91%)]\tLoss: 0.002454\n","Train Epoch: 5 [138880/151166 (92%)]\tLoss: 0.000293\n","Train Epoch: 5 [139520/151166 (92%)]\tLoss: 0.000621\n","Train Epoch: 5 [140160/151166 (93%)]\tLoss: 0.001340\n","Train Epoch: 5 [140800/151166 (93%)]\tLoss: 0.001626\n","Train Epoch: 5 [141440/151166 (94%)]\tLoss: 0.001683\n","Train Epoch: 5 [142080/151166 (94%)]\tLoss: 0.000789\n","Train Epoch: 5 [142720/151166 (94%)]\tLoss: 0.001925\n","Train Epoch: 5 [143360/151166 (95%)]\tLoss: 0.000522\n","Train Epoch: 5 [144000/151166 (95%)]\tLoss: 0.001176\n","Train Epoch: 5 [144640/151166 (96%)]\tLoss: 0.001009\n","Train Epoch: 5 [145280/151166 (96%)]\tLoss: 0.001492\n","Train Epoch: 5 [145920/151166 (97%)]\tLoss: 0.000440\n","Train Epoch: 5 [146560/151166 (97%)]\tLoss: 0.000850\n","Train Epoch: 5 [147200/151166 (97%)]\tLoss: 0.000972\n","Train Epoch: 5 [147840/151166 (98%)]\tLoss: 0.000704\n","Train Epoch: 5 [148480/151166 (98%)]\tLoss: 0.000536\n","Train Epoch: 5 [149120/151166 (99%)]\tLoss: 0.002261\n","Train Epoch: 5 [149760/151166 (99%)]\tLoss: 0.000897\n","Train Epoch: 5 [150400/151166 (99%)]\tLoss: 0.000614\n","Train Epoch: 5 [151040/151166 (100%)]\tLoss: 0.002559\n","Sample outputs (log probs): tensor([[-1.4069e+01, -1.4335e+01, -1.7279e+01, -1.5001e+01, -1.9990e+01,\n","         -7.9016e+00, -1.8965e+01, -1.7397e+01, -1.7670e+01, -2.4816e+01,\n","         -2.0312e+01, -2.4064e+01, -2.0381e+01, -1.9238e+01, -1.9327e+01,\n","         -4.2632e-04, -1.4480e+01, -9.9645e+00, -2.1653e+01, -1.1982e+01,\n","         -2.4319e+01, -1.8405e+01, -2.4223e+01, -2.3046e+01, -1.4403e+01,\n","         -1.8799e+01],\n","        [-1.5009e+01, -1.8984e+01, -1.8796e+01, -2.5931e+01, -1.1516e+01,\n","         -1.9908e-05, -1.3322e+01, -2.8472e+01, -2.4827e+01, -2.2659e+01,\n","         -2.6401e+01, -3.3299e+01, -3.1239e+01, -3.3183e+01, -2.7975e+01,\n","         -1.1773e+01, -2.0712e+01, -1.8736e+01, -1.9358e+01, -1.4944e+01,\n","         -3.6665e+01, -2.5575e+01, -3.6012e+01, -3.2477e+01, -2.3533e+01,\n","         -1.9274e+01],\n","        [-6.8549e+00, -8.5262e+00, -1.2494e+01, -1.0284e+01, -1.5518e+01,\n","         -1.3964e+01, -7.1974e+00, -9.4283e+00, -1.5512e+01, -1.5237e+01,\n","         -1.1136e+01, -1.5721e+01, -2.6248e-03, -8.7108e+00, -1.0566e+01,\n","         -1.4165e+01, -1.1244e+01, -1.1475e+01, -1.4610e+01, -1.1366e+01,\n","         -1.1884e+01, -1.4655e+01, -8.2902e+00, -1.4854e+01, -1.5776e+01,\n","         -1.6038e+01],\n","        [-2.5778e+00, -1.0159e+01, -1.0877e+01, -8.8577e+00, -1.7659e+01,\n","         -8.2435e+00, -9.1376e+00, -2.7496e+00, -2.1235e+00, -2.8250e+00,\n","         -5.1141e+00, -5.6954e+00, -6.2995e+00, -3.6664e+00, -9.6130e+00,\n","         -9.7805e+00, -4.3630e+00, -8.4858e+00, -8.7265e+00, -3.6713e+00,\n","         -2.0674e+00, -5.6845e+00, -6.6846e+00, -9.4995e-01, -2.4402e+00,\n","         -9.3135e+00],\n","        [-1.3545e+01, -1.0027e+01, -7.5033e+00, -6.9770e+00, -1.5876e+01,\n","         -1.7225e+01, -1.3612e+01, -1.7536e+01, -1.1821e+01, -1.1210e+01,\n","         -2.1682e+01, -1.7125e+01, -1.4780e+01, -1.3778e+01, -1.8836e-03,\n","         -1.2742e+01, -1.0087e+01, -1.6190e+01, -1.3820e+01, -1.4694e+01,\n","         -8.1832e+00, -1.3104e+01, -1.7898e+01, -2.3408e+01, -1.4039e+01,\n","         -1.7150e+01]], device='cuda:0')\n","Predicted classes: tensor([15,  5, 12, 23, 14], device='cuda:0')\n","Target classes: tensor([15,  5, 12,  8, 14], device='cuda:0')\n","\n","Test set: Average loss: 0.001995, Total sum loss: 0.590665, Accuracy: 36578/37792 (97%)\n","\n","Class A: 1229/1247 (99%)\n","Class B: 796/816 (98%)\n","Class C: 1906/1965 (97%)\n","Class D: 824/868 (95%)\n","Class E: 991/1024 (97%)\n","Class F: 1826/1869 (98%)\n","Class G: 507/519 (98%)\n","Class H: 599/621 (96%)\n","Class I: 2372/2410 (98%)\n","Class J: 723/754 (96%)\n","Class K: 486/502 (97%)\n","Class L: 966/987 (98%)\n","Class M: 1734/1774 (98%)\n","Class N: 1562/1622 (96%)\n","Class O: 4749/5064 (94%)\n","Class P: 1564/1615 (97%)\n","Class Q: 508/536 (95%)\n","Class R: 955/992 (96%)\n","Class S: 4177/4228 (99%)\n","Class T: 1903/1932 (98%)\n","Class U: 2496/2598 (96%)\n","Class V: 847/904 (94%)\n","Class W: 916/938 (98%)\n","Class X: 538/560 (96%)\n","Class Y: 893/924 (97%)\n","Class Z: 511/523 (98%)\n","Model saved with new best test loss: 0.0020 \n","\n","Train Epoch: 6 [0/151166 (0%)]\tLoss: 0.001360\n","Train Epoch: 6 [640/151166 (0%)]\tLoss: 0.000655\n","Train Epoch: 6 [1280/151166 (1%)]\tLoss: 0.000604\n","Train Epoch: 6 [1920/151166 (1%)]\tLoss: 0.000975\n","Train Epoch: 6 [2560/151166 (2%)]\tLoss: 0.001304\n","Train Epoch: 6 [3200/151166 (2%)]\tLoss: 0.000563\n","Train Epoch: 6 [3840/151166 (3%)]\tLoss: 0.001789\n","Train Epoch: 6 [4480/151166 (3%)]\tLoss: 0.000207\n","Train Epoch: 6 [5120/151166 (3%)]\tLoss: 0.000861\n","Train Epoch: 6 [5760/151166 (4%)]\tLoss: 0.000508\n","Train Epoch: 6 [6400/151166 (4%)]\tLoss: 0.002052\n","Train Epoch: 6 [7040/151166 (5%)]\tLoss: 0.000462\n","Train Epoch: 6 [7680/151166 (5%)]\tLoss: 0.000609\n","Train Epoch: 6 [8320/151166 (6%)]\tLoss: 0.003025\n","Train Epoch: 6 [8960/151166 (6%)]\tLoss: 0.003487\n","Train Epoch: 6 [9600/151166 (6%)]\tLoss: 0.000425\n","Train Epoch: 6 [10240/151166 (7%)]\tLoss: 0.000443\n","Train Epoch: 6 [10880/151166 (7%)]\tLoss: 0.000376\n","Train Epoch: 6 [11520/151166 (8%)]\tLoss: 0.001281\n","Train Epoch: 6 [12160/151166 (8%)]\tLoss: 0.000659\n","Train Epoch: 6 [12800/151166 (8%)]\tLoss: 0.000143\n","Train Epoch: 6 [13440/151166 (9%)]\tLoss: 0.000806\n","Train Epoch: 6 [14080/151166 (9%)]\tLoss: 0.000438\n","Train Epoch: 6 [14720/151166 (10%)]\tLoss: 0.001252\n","Train Epoch: 6 [15360/151166 (10%)]\tLoss: 0.001907\n","Train Epoch: 6 [16000/151166 (11%)]\tLoss: 0.001129\n","Train Epoch: 6 [16640/151166 (11%)]\tLoss: 0.000567\n","Train Epoch: 6 [17280/151166 (11%)]\tLoss: 0.001225\n","Train Epoch: 6 [17920/151166 (12%)]\tLoss: 0.001649\n","Train Epoch: 6 [18560/151166 (12%)]\tLoss: 0.002889\n","Train Epoch: 6 [19200/151166 (13%)]\tLoss: 0.000318\n","Train Epoch: 6 [19840/151166 (13%)]\tLoss: 0.000954\n","Train Epoch: 6 [20480/151166 (14%)]\tLoss: 0.001039\n","Train Epoch: 6 [21120/151166 (14%)]\tLoss: 0.000535\n","Train Epoch: 6 [21760/151166 (14%)]\tLoss: 0.000113\n","Train Epoch: 6 [22400/151166 (15%)]\tLoss: 0.001848\n","Train Epoch: 6 [23040/151166 (15%)]\tLoss: 0.000796\n","Train Epoch: 6 [23680/151166 (16%)]\tLoss: 0.001083\n","Train Epoch: 6 [24320/151166 (16%)]\tLoss: 0.001782\n","Train Epoch: 6 [24960/151166 (17%)]\tLoss: 0.000677\n","Train Epoch: 6 [25600/151166 (17%)]\tLoss: 0.002313\n","Train Epoch: 6 [26240/151166 (17%)]\tLoss: 0.001161\n","Train Epoch: 6 [26880/151166 (18%)]\tLoss: 0.000817\n","Train Epoch: 6 [27520/151166 (18%)]\tLoss: 0.001588\n","Train Epoch: 6 [28160/151166 (19%)]\tLoss: 0.002608\n","Train Epoch: 6 [28800/151166 (19%)]\tLoss: 0.000865\n","Train Epoch: 6 [29440/151166 (19%)]\tLoss: 0.000658\n","Train Epoch: 6 [30080/151166 (20%)]\tLoss: 0.000770\n","Train Epoch: 6 [30720/151166 (20%)]\tLoss: 0.002084\n","Train Epoch: 6 [31360/151166 (21%)]\tLoss: 0.003166\n","Train Epoch: 6 [32000/151166 (21%)]\tLoss: 0.001608\n","Train Epoch: 6 [32640/151166 (22%)]\tLoss: 0.003390\n","Train Epoch: 6 [33280/151166 (22%)]\tLoss: 0.000716\n","Train Epoch: 6 [33920/151166 (22%)]\tLoss: 0.000559\n","Train Epoch: 6 [34560/151166 (23%)]\tLoss: 0.001155\n","Train Epoch: 6 [35200/151166 (23%)]\tLoss: 0.001201\n","Train Epoch: 6 [35840/151166 (24%)]\tLoss: 0.000731\n","Train Epoch: 6 [36480/151166 (24%)]\tLoss: 0.001502\n","Train Epoch: 6 [37120/151166 (25%)]\tLoss: 0.001229\n","Train Epoch: 6 [37760/151166 (25%)]\tLoss: 0.001425\n","Train Epoch: 6 [38400/151166 (25%)]\tLoss: 0.002395\n","Train Epoch: 6 [39040/151166 (26%)]\tLoss: 0.003085\n","Train Epoch: 6 [39680/151166 (26%)]\tLoss: 0.002073\n","Train Epoch: 6 [40320/151166 (27%)]\tLoss: 0.002389\n","Train Epoch: 6 [40960/151166 (27%)]\tLoss: 0.002075\n","Train Epoch: 6 [41600/151166 (28%)]\tLoss: 0.003113\n","Train Epoch: 6 [42240/151166 (28%)]\tLoss: 0.000692\n","Train Epoch: 6 [42880/151166 (28%)]\tLoss: 0.002020\n","Train Epoch: 6 [43520/151166 (29%)]\tLoss: 0.000787\n","Train Epoch: 6 [44160/151166 (29%)]\tLoss: 0.000230\n","Train Epoch: 6 [44800/151166 (30%)]\tLoss: 0.001989\n","Train Epoch: 6 [45440/151166 (30%)]\tLoss: 0.000352\n","Train Epoch: 6 [46080/151166 (30%)]\tLoss: 0.001012\n","Train Epoch: 6 [46720/151166 (31%)]\tLoss: 0.001184\n","Train Epoch: 6 [47360/151166 (31%)]\tLoss: 0.002829\n","Train Epoch: 6 [48000/151166 (32%)]\tLoss: 0.000696\n","Train Epoch: 6 [48640/151166 (32%)]\tLoss: 0.001406\n","Train Epoch: 6 [49280/151166 (33%)]\tLoss: 0.002664\n","Train Epoch: 6 [49920/151166 (33%)]\tLoss: 0.000992\n","Train Epoch: 6 [50560/151166 (33%)]\tLoss: 0.000470\n","Train Epoch: 6 [51200/151166 (34%)]\tLoss: 0.001729\n","Train Epoch: 6 [51840/151166 (34%)]\tLoss: 0.003732\n","Train Epoch: 6 [52480/151166 (35%)]\tLoss: 0.000645\n","Train Epoch: 6 [53120/151166 (35%)]\tLoss: 0.000907\n","Train Epoch: 6 [53760/151166 (36%)]\tLoss: 0.001214\n","Train Epoch: 6 [54400/151166 (36%)]\tLoss: 0.002401\n","Train Epoch: 6 [55040/151166 (36%)]\tLoss: 0.000264\n","Train Epoch: 6 [55680/151166 (37%)]\tLoss: 0.000530\n","Train Epoch: 6 [56320/151166 (37%)]\tLoss: 0.000658\n","Train Epoch: 6 [56960/151166 (38%)]\tLoss: 0.001109\n","Train Epoch: 6 [57600/151166 (38%)]\tLoss: 0.000834\n","Train Epoch: 6 [58240/151166 (39%)]\tLoss: 0.001722\n","Train Epoch: 6 [58880/151166 (39%)]\tLoss: 0.000669\n","Train Epoch: 6 [59520/151166 (39%)]\tLoss: 0.001797\n","Train Epoch: 6 [60160/151166 (40%)]\tLoss: 0.001604\n","Train Epoch: 6 [60800/151166 (40%)]\tLoss: 0.000999\n","Train Epoch: 6 [61440/151166 (41%)]\tLoss: 0.000468\n","Train Epoch: 6 [62080/151166 (41%)]\tLoss: 0.000996\n","Train Epoch: 6 [62720/151166 (41%)]\tLoss: 0.001281\n","Train Epoch: 6 [63360/151166 (42%)]\tLoss: 0.000546\n","Train Epoch: 6 [64000/151166 (42%)]\tLoss: 0.002053\n","Train Epoch: 6 [64640/151166 (43%)]\tLoss: 0.000846\n","Train Epoch: 6 [65280/151166 (43%)]\tLoss: 0.000438\n","Train Epoch: 6 [65920/151166 (44%)]\tLoss: 0.002626\n","Train Epoch: 6 [66560/151166 (44%)]\tLoss: 0.000709\n","Train Epoch: 6 [67200/151166 (44%)]\tLoss: 0.000188\n","Train Epoch: 6 [67840/151166 (45%)]\tLoss: 0.000924\n","Train Epoch: 6 [68480/151166 (45%)]\tLoss: 0.001950\n","Train Epoch: 6 [69120/151166 (46%)]\tLoss: 0.000972\n","Train Epoch: 6 [69760/151166 (46%)]\tLoss: 0.000360\n","Train Epoch: 6 [70400/151166 (47%)]\tLoss: 0.004214\n","Train Epoch: 6 [71040/151166 (47%)]\tLoss: 0.000460\n","Train Epoch: 6 [71680/151166 (47%)]\tLoss: 0.001062\n","Train Epoch: 6 [72320/151166 (48%)]\tLoss: 0.002924\n","Train Epoch: 6 [72960/151166 (48%)]\tLoss: 0.001102\n","Train Epoch: 6 [73600/151166 (49%)]\tLoss: 0.000673\n","Train Epoch: 6 [74240/151166 (49%)]\tLoss: 0.002360\n","Train Epoch: 6 [74880/151166 (50%)]\tLoss: 0.001811\n","Train Epoch: 6 [75520/151166 (50%)]\tLoss: 0.002138\n","Train Epoch: 6 [76160/151166 (50%)]\tLoss: 0.000355\n","Train Epoch: 6 [76800/151166 (51%)]\tLoss: 0.001535\n","Train Epoch: 6 [77440/151166 (51%)]\tLoss: 0.000697\n","Train Epoch: 6 [78080/151166 (52%)]\tLoss: 0.001158\n","Train Epoch: 6 [78720/151166 (52%)]\tLoss: 0.000483\n","Train Epoch: 6 [79360/151166 (52%)]\tLoss: 0.000835\n","Train Epoch: 6 [80000/151166 (53%)]\tLoss: 0.000583\n","Train Epoch: 6 [80640/151166 (53%)]\tLoss: 0.001323\n","Train Epoch: 6 [81280/151166 (54%)]\tLoss: 0.000497\n","Train Epoch: 6 [81920/151166 (54%)]\tLoss: 0.001826\n","Train Epoch: 6 [82560/151166 (55%)]\tLoss: 0.000788\n","Train Epoch: 6 [83200/151166 (55%)]\tLoss: 0.000550\n","Train Epoch: 6 [83840/151166 (55%)]\tLoss: 0.005133\n","Train Epoch: 6 [84480/151166 (56%)]\tLoss: 0.000385\n","Train Epoch: 6 [85120/151166 (56%)]\tLoss: 0.001606\n","Train Epoch: 6 [85760/151166 (57%)]\tLoss: 0.001314\n","Train Epoch: 6 [86400/151166 (57%)]\tLoss: 0.002309\n","Train Epoch: 6 [87040/151166 (58%)]\tLoss: 0.000864\n","Train Epoch: 6 [87680/151166 (58%)]\tLoss: 0.000425\n","Train Epoch: 6 [88320/151166 (58%)]\tLoss: 0.001491\n","Train Epoch: 6 [88960/151166 (59%)]\tLoss: 0.000949\n","Train Epoch: 6 [89600/151166 (59%)]\tLoss: 0.000373\n","Train Epoch: 6 [90240/151166 (60%)]\tLoss: 0.002026\n","Train Epoch: 6 [90880/151166 (60%)]\tLoss: 0.001657\n","Train Epoch: 6 [91520/151166 (61%)]\tLoss: 0.000810\n","Train Epoch: 6 [92160/151166 (61%)]\tLoss: 0.001779\n","Train Epoch: 6 [92800/151166 (61%)]\tLoss: 0.001756\n","Train Epoch: 6 [93440/151166 (62%)]\tLoss: 0.001160\n","Train Epoch: 6 [94080/151166 (62%)]\tLoss: 0.001411\n","Train Epoch: 6 [94720/151166 (63%)]\tLoss: 0.002180\n","Train Epoch: 6 [95360/151166 (63%)]\tLoss: 0.001171\n","Train Epoch: 6 [96000/151166 (64%)]\tLoss: 0.003605\n","Train Epoch: 6 [96640/151166 (64%)]\tLoss: 0.001137\n","Train Epoch: 6 [97280/151166 (64%)]\tLoss: 0.000526\n","Train Epoch: 6 [97920/151166 (65%)]\tLoss: 0.001674\n","Train Epoch: 6 [98560/151166 (65%)]\tLoss: 0.001349\n","Train Epoch: 6 [99200/151166 (66%)]\tLoss: 0.000435\n","Train Epoch: 6 [99840/151166 (66%)]\tLoss: 0.001693\n","Train Epoch: 6 [100480/151166 (66%)]\tLoss: 0.000457\n","Train Epoch: 6 [101120/151166 (67%)]\tLoss: 0.001357\n","Train Epoch: 6 [101760/151166 (67%)]\tLoss: 0.001669\n","Train Epoch: 6 [102400/151166 (68%)]\tLoss: 0.000792\n","Train Epoch: 6 [103040/151166 (68%)]\tLoss: 0.002988\n","Train Epoch: 6 [103680/151166 (69%)]\tLoss: 0.000853\n","Train Epoch: 6 [104320/151166 (69%)]\tLoss: 0.000936\n","Train Epoch: 6 [104960/151166 (69%)]\tLoss: 0.000778\n","Train Epoch: 6 [105600/151166 (70%)]\tLoss: 0.000388\n","Train Epoch: 6 [106240/151166 (70%)]\tLoss: 0.001771\n","Train Epoch: 6 [106880/151166 (71%)]\tLoss: 0.000593\n","Train Epoch: 6 [107520/151166 (71%)]\tLoss: 0.000272\n","Train Epoch: 6 [108160/151166 (72%)]\tLoss: 0.000183\n","Train Epoch: 6 [108800/151166 (72%)]\tLoss: 0.001028\n","Train Epoch: 6 [109440/151166 (72%)]\tLoss: 0.000509\n","Train Epoch: 6 [110080/151166 (73%)]\tLoss: 0.000954\n","Train Epoch: 6 [110720/151166 (73%)]\tLoss: 0.000823\n","Train Epoch: 6 [111360/151166 (74%)]\tLoss: 0.000988\n","Train Epoch: 6 [112000/151166 (74%)]\tLoss: 0.000573\n","Train Epoch: 6 [112640/151166 (75%)]\tLoss: 0.001896\n","Train Epoch: 6 [113280/151166 (75%)]\tLoss: 0.001283\n","Train Epoch: 6 [113920/151166 (75%)]\tLoss: 0.000654\n","Train Epoch: 6 [114560/151166 (76%)]\tLoss: 0.000811\n","Train Epoch: 6 [115200/151166 (76%)]\tLoss: 0.000916\n","Train Epoch: 6 [115840/151166 (77%)]\tLoss: 0.000617\n","Train Epoch: 6 [116480/151166 (77%)]\tLoss: 0.000453\n","Train Epoch: 6 [117120/151166 (77%)]\tLoss: 0.000538\n","Train Epoch: 6 [117760/151166 (78%)]\tLoss: 0.000942\n","Train Epoch: 6 [118400/151166 (78%)]\tLoss: 0.002258\n","Train Epoch: 6 [119040/151166 (79%)]\tLoss: 0.001415\n","Train Epoch: 6 [119680/151166 (79%)]\tLoss: 0.001889\n","Train Epoch: 6 [120320/151166 (80%)]\tLoss: 0.001105\n","Train Epoch: 6 [120960/151166 (80%)]\tLoss: 0.000630\n","Train Epoch: 6 [121600/151166 (80%)]\tLoss: 0.000458\n","Train Epoch: 6 [122240/151166 (81%)]\tLoss: 0.000451\n","Train Epoch: 6 [122880/151166 (81%)]\tLoss: 0.000800\n","Train Epoch: 6 [123520/151166 (82%)]\tLoss: 0.001241\n","Train Epoch: 6 [124160/151166 (82%)]\tLoss: 0.000729\n","Train Epoch: 6 [124800/151166 (83%)]\tLoss: 0.001739\n","Train Epoch: 6 [125440/151166 (83%)]\tLoss: 0.000238\n","Train Epoch: 6 [126080/151166 (83%)]\tLoss: 0.001046\n","Train Epoch: 6 [126720/151166 (84%)]\tLoss: 0.000493\n","Train Epoch: 6 [127360/151166 (84%)]\tLoss: 0.000430\n","Train Epoch: 6 [128000/151166 (85%)]\tLoss: 0.000401\n","Train Epoch: 6 [128640/151166 (85%)]\tLoss: 0.001303\n","Train Epoch: 6 [129280/151166 (86%)]\tLoss: 0.000817\n","Train Epoch: 6 [129920/151166 (86%)]\tLoss: 0.001896\n","Train Epoch: 6 [130560/151166 (86%)]\tLoss: 0.000601\n","Train Epoch: 6 [131200/151166 (87%)]\tLoss: 0.002879\n","Train Epoch: 6 [131840/151166 (87%)]\tLoss: 0.000522\n","Train Epoch: 6 [132480/151166 (88%)]\tLoss: 0.000468\n","Train Epoch: 6 [133120/151166 (88%)]\tLoss: 0.001153\n","Train Epoch: 6 [133760/151166 (88%)]\tLoss: 0.000180\n","Train Epoch: 6 [134400/151166 (89%)]\tLoss: 0.001300\n","Train Epoch: 6 [135040/151166 (89%)]\tLoss: 0.000996\n","Train Epoch: 6 [135680/151166 (90%)]\tLoss: 0.001561\n","Train Epoch: 6 [136320/151166 (90%)]\tLoss: 0.000425\n","Train Epoch: 6 [136960/151166 (91%)]\tLoss: 0.001896\n","Train Epoch: 6 [137600/151166 (91%)]\tLoss: 0.000513\n","Train Epoch: 6 [138240/151166 (91%)]\tLoss: 0.000915\n","Train Epoch: 6 [138880/151166 (92%)]\tLoss: 0.000423\n","Train Epoch: 6 [139520/151166 (92%)]\tLoss: 0.000959\n","Train Epoch: 6 [140160/151166 (93%)]\tLoss: 0.001353\n","Train Epoch: 6 [140800/151166 (93%)]\tLoss: 0.002793\n","Train Epoch: 6 [141440/151166 (94%)]\tLoss: 0.000390\n","Train Epoch: 6 [142080/151166 (94%)]\tLoss: 0.000841\n","Train Epoch: 6 [142720/151166 (94%)]\tLoss: 0.000413\n","Train Epoch: 6 [143360/151166 (95%)]\tLoss: 0.001007\n","Train Epoch: 6 [144000/151166 (95%)]\tLoss: 0.000688\n","Train Epoch: 6 [144640/151166 (96%)]\tLoss: 0.001299\n","Train Epoch: 6 [145280/151166 (96%)]\tLoss: 0.000578\n","Train Epoch: 6 [145920/151166 (97%)]\tLoss: 0.000555\n","Train Epoch: 6 [146560/151166 (97%)]\tLoss: 0.002080\n","Train Epoch: 6 [147200/151166 (97%)]\tLoss: 0.002188\n","Train Epoch: 6 [147840/151166 (98%)]\tLoss: 0.001337\n","Train Epoch: 6 [148480/151166 (98%)]\tLoss: 0.001187\n","Train Epoch: 6 [149120/151166 (99%)]\tLoss: 0.000825\n","Train Epoch: 6 [149760/151166 (99%)]\tLoss: 0.001259\n","Train Epoch: 6 [150400/151166 (99%)]\tLoss: 0.001048\n","Train Epoch: 6 [151040/151166 (100%)]\tLoss: 0.003795\n","Sample outputs (log probs): tensor([[-1.5022e+01, -1.8397e+01, -2.0917e+01, -1.3551e+01, -2.4929e+01,\n","         -2.2666e+01, -1.9022e+01, -7.9325e+00, -1.7741e+01, -1.5200e+01,\n","         -2.0206e+01, -1.9908e+01, -1.0670e+01, -2.2313e-01, -1.5790e+01,\n","         -1.4915e+01, -1.1652e+01, -1.6752e+01, -1.9565e+01, -1.7487e+01,\n","         -1.0132e+01, -9.3976e+00, -1.6121e+00, -1.8776e+01, -1.6296e+01,\n","         -2.6640e+01],\n","        [-3.0452e+01, -2.9240e+01, -3.0237e+01, -2.2145e+01, -3.5729e+01,\n","         -3.4938e+01, -2.5214e+01, -2.0145e+01, -2.6719e+01, -2.3985e+01,\n","         -2.9833e+01, -2.6094e+01, -1.8418e+01, -1.2591e+01, -2.7776e+01,\n","         -2.7213e+01, -1.9744e+01, -3.1602e+01, -2.9790e+01, -2.9501e+01,\n","         -1.1601e+01, -1.4515e+01, -1.3113e-05, -2.7600e+01, -2.5683e+01,\n","         -3.6785e+01],\n","        [-1.8927e+01, -1.5762e+01, -1.1831e+01, -8.6084e+00, -1.8580e+01,\n","         -1.7910e+01, -1.4535e+01, -1.2629e+01, -1.1410e+01, -8.8880e+00,\n","         -1.9159e+01, -1.0334e+01, -1.3178e+01, -9.6582e+00, -1.0528e+01,\n","         -1.3509e+01, -1.2462e+01, -1.9349e+01, -1.6655e+01, -1.3765e+01,\n","         -2.5448e-02, -3.7339e+00, -7.2115e+00, -1.6126e+01, -1.1150e+01,\n","         -1.5439e+01],\n","        [-1.4010e+01, -1.5639e+01, -1.4330e+01, -1.1138e+01, -1.5482e+01,\n","         -9.8208e+00, -1.6258e+01, -1.2421e+01, -5.9869e+00, -8.8660e+00,\n","         -1.1453e+01, -8.6063e+00, -1.1590e+01, -1.0240e+01, -1.5098e+01,\n","         -6.5433e+00, -1.6183e+01, -1.5390e+01, -1.2348e+01, -6.3966e+00,\n","         -1.1182e+01, -7.6069e+00, -1.3060e+01, -6.1463e+00, -8.7840e-03,\n","         -1.1213e+01],\n","        [-1.1019e+01, -1.2960e+01, -1.4418e+01, -1.7650e+01, -1.2057e+01,\n","         -1.1569e+01, -1.3175e+01, -7.2585e+00, -1.3924e+01, -1.8753e+01,\n","         -6.2204e-03, -9.0337e+00, -1.1419e+01, -6.8674e+00, -1.9604e+01,\n","         -8.1744e+00, -1.7134e+01, -5.8312e+00, -1.6783e+01, -1.3048e+01,\n","         -1.5614e+01, -1.1326e+01, -1.1079e+01, -6.8941e+00, -1.0476e+01,\n","         -1.6387e+01]], device='cuda:0')\n","Predicted classes: tensor([13, 22, 20, 24, 10], device='cuda:0')\n","Target classes: tensor([13, 22, 21, 24, 10], device='cuda:0')\n","\n","Test set: Average loss: 0.001914, Total sum loss: 0.566585, Accuracy: 36663/37792 (97%)\n","\n","Class A: 1219/1247 (98%)\n","Class B: 797/816 (98%)\n","Class C: 1902/1965 (97%)\n","Class D: 820/868 (94%)\n","Class E: 1002/1024 (98%)\n","Class F: 1823/1869 (98%)\n","Class G: 498/519 (96%)\n","Class H: 594/621 (96%)\n","Class I: 2365/2410 (98%)\n","Class J: 730/754 (97%)\n","Class K: 479/502 (95%)\n","Class L: 969/987 (98%)\n","Class M: 1731/1774 (98%)\n","Class N: 1592/1622 (98%)\n","Class O: 4844/5064 (96%)\n","Class P: 1569/1615 (97%)\n","Class Q: 511/536 (95%)\n","Class R: 953/992 (96%)\n","Class S: 4155/4228 (98%)\n","Class T: 1912/1932 (99%)\n","Class U: 2482/2598 (96%)\n","Class V: 866/904 (96%)\n","Class W: 909/938 (97%)\n","Class X: 547/560 (98%)\n","Class Y: 880/924 (95%)\n","Class Z: 514/523 (98%)\n","Model saved with new best test loss: 0.0019 \n","\n","Train Epoch: 7 [0/151166 (0%)]\tLoss: 0.000408\n","Train Epoch: 7 [640/151166 (0%)]\tLoss: 0.000335\n","Train Epoch: 7 [1280/151166 (1%)]\tLoss: 0.000542\n","Train Epoch: 7 [1920/151166 (1%)]\tLoss: 0.001148\n","Train Epoch: 7 [2560/151166 (2%)]\tLoss: 0.000469\n","Train Epoch: 7 [3200/151166 (2%)]\tLoss: 0.001700\n","Train Epoch: 7 [3840/151166 (3%)]\tLoss: 0.001208\n","Train Epoch: 7 [4480/151166 (3%)]\tLoss: 0.000683\n","Train Epoch: 7 [5120/151166 (3%)]\tLoss: 0.000548\n","Train Epoch: 7 [5760/151166 (4%)]\tLoss: 0.001072\n","Train Epoch: 7 [6400/151166 (4%)]\tLoss: 0.000408\n","Train Epoch: 7 [7040/151166 (5%)]\tLoss: 0.000964\n","Train Epoch: 7 [7680/151166 (5%)]\tLoss: 0.001226\n","Train Epoch: 7 [8320/151166 (6%)]\tLoss: 0.000781\n","Train Epoch: 7 [8960/151166 (6%)]\tLoss: 0.000247\n","Train Epoch: 7 [9600/151166 (6%)]\tLoss: 0.001048\n","Train Epoch: 7 [10240/151166 (7%)]\tLoss: 0.002313\n","Train Epoch: 7 [10880/151166 (7%)]\tLoss: 0.000332\n","Train Epoch: 7 [11520/151166 (8%)]\tLoss: 0.001467\n","Train Epoch: 7 [12160/151166 (8%)]\tLoss: 0.000416\n","Train Epoch: 7 [12800/151166 (8%)]\tLoss: 0.000979\n","Train Epoch: 7 [13440/151166 (9%)]\tLoss: 0.000744\n","Train Epoch: 7 [14080/151166 (9%)]\tLoss: 0.000158\n","Train Epoch: 7 [14720/151166 (10%)]\tLoss: 0.000140\n","Train Epoch: 7 [15360/151166 (10%)]\tLoss: 0.001166\n","Train Epoch: 7 [16000/151166 (11%)]\tLoss: 0.000397\n","Train Epoch: 7 [16640/151166 (11%)]\tLoss: 0.002647\n","Train Epoch: 7 [17280/151166 (11%)]\tLoss: 0.001701\n","Train Epoch: 7 [17920/151166 (12%)]\tLoss: 0.000762\n","Train Epoch: 7 [18560/151166 (12%)]\tLoss: 0.002069\n","Train Epoch: 7 [19200/151166 (13%)]\tLoss: 0.000344\n","Train Epoch: 7 [19840/151166 (13%)]\tLoss: 0.000934\n","Train Epoch: 7 [20480/151166 (14%)]\tLoss: 0.001155\n","Train Epoch: 7 [21120/151166 (14%)]\tLoss: 0.001613\n","Train Epoch: 7 [21760/151166 (14%)]\tLoss: 0.000765\n","Train Epoch: 7 [22400/151166 (15%)]\tLoss: 0.001093\n","Train Epoch: 7 [23040/151166 (15%)]\tLoss: 0.000156\n","Train Epoch: 7 [23680/151166 (16%)]\tLoss: 0.000580\n","Train Epoch: 7 [24320/151166 (16%)]\tLoss: 0.004448\n","Train Epoch: 7 [24960/151166 (17%)]\tLoss: 0.000801\n","Train Epoch: 7 [25600/151166 (17%)]\tLoss: 0.000936\n","Train Epoch: 7 [26240/151166 (17%)]\tLoss: 0.000093\n","Train Epoch: 7 [26880/151166 (18%)]\tLoss: 0.000563\n","Train Epoch: 7 [27520/151166 (18%)]\tLoss: 0.000908\n","Train Epoch: 7 [28160/151166 (19%)]\tLoss: 0.000414\n","Train Epoch: 7 [28800/151166 (19%)]\tLoss: 0.000748\n","Train Epoch: 7 [29440/151166 (19%)]\tLoss: 0.000923\n","Train Epoch: 7 [30080/151166 (20%)]\tLoss: 0.001761\n","Train Epoch: 7 [30720/151166 (20%)]\tLoss: 0.000749\n","Train Epoch: 7 [31360/151166 (21%)]\tLoss: 0.000577\n","Train Epoch: 7 [32000/151166 (21%)]\tLoss: 0.000212\n","Train Epoch: 7 [32640/151166 (22%)]\tLoss: 0.000685\n","Train Epoch: 7 [33280/151166 (22%)]\tLoss: 0.000305\n","Train Epoch: 7 [33920/151166 (22%)]\tLoss: 0.001462\n","Train Epoch: 7 [34560/151166 (23%)]\tLoss: 0.003738\n","Train Epoch: 7 [35200/151166 (23%)]\tLoss: 0.001378\n","Train Epoch: 7 [35840/151166 (24%)]\tLoss: 0.000956\n","Train Epoch: 7 [36480/151166 (24%)]\tLoss: 0.001970\n","Train Epoch: 7 [37120/151166 (25%)]\tLoss: 0.000408\n","Train Epoch: 7 [37760/151166 (25%)]\tLoss: 0.001756\n","Train Epoch: 7 [38400/151166 (25%)]\tLoss: 0.000533\n","Train Epoch: 7 [39040/151166 (26%)]\tLoss: 0.000479\n","Train Epoch: 7 [39680/151166 (26%)]\tLoss: 0.001187\n","Train Epoch: 7 [40320/151166 (27%)]\tLoss: 0.000973\n","Train Epoch: 7 [40960/151166 (27%)]\tLoss: 0.000910\n","Train Epoch: 7 [41600/151166 (28%)]\tLoss: 0.001580\n","Train Epoch: 7 [42240/151166 (28%)]\tLoss: 0.001416\n","Train Epoch: 7 [42880/151166 (28%)]\tLoss: 0.000745\n","Train Epoch: 7 [43520/151166 (29%)]\tLoss: 0.000875\n","Train Epoch: 7 [44160/151166 (29%)]\tLoss: 0.000410\n","Train Epoch: 7 [44800/151166 (30%)]\tLoss: 0.002836\n","Train Epoch: 7 [45440/151166 (30%)]\tLoss: 0.000144\n","Train Epoch: 7 [46080/151166 (30%)]\tLoss: 0.000923\n","Train Epoch: 7 [46720/151166 (31%)]\tLoss: 0.000749\n","Train Epoch: 7 [47360/151166 (31%)]\tLoss: 0.000976\n","Train Epoch: 7 [48000/151166 (32%)]\tLoss: 0.001112\n","Train Epoch: 7 [48640/151166 (32%)]\tLoss: 0.000802\n","Train Epoch: 7 [49280/151166 (33%)]\tLoss: 0.000530\n","Train Epoch: 7 [49920/151166 (33%)]\tLoss: 0.000307\n","Train Epoch: 7 [50560/151166 (33%)]\tLoss: 0.003730\n","Train Epoch: 7 [51200/151166 (34%)]\tLoss: 0.000500\n","Train Epoch: 7 [51840/151166 (34%)]\tLoss: 0.001693\n","Train Epoch: 7 [52480/151166 (35%)]\tLoss: 0.001830\n","Train Epoch: 7 [53120/151166 (35%)]\tLoss: 0.002199\n","Train Epoch: 7 [53760/151166 (36%)]\tLoss: 0.000967\n","Train Epoch: 7 [54400/151166 (36%)]\tLoss: 0.000262\n","Train Epoch: 7 [55040/151166 (36%)]\tLoss: 0.002991\n","Train Epoch: 7 [55680/151166 (37%)]\tLoss: 0.000633\n","Train Epoch: 7 [56320/151166 (37%)]\tLoss: 0.001475\n","Train Epoch: 7 [56960/151166 (38%)]\tLoss: 0.002514\n","Train Epoch: 7 [57600/151166 (38%)]\tLoss: 0.000383\n","Train Epoch: 7 [58240/151166 (39%)]\tLoss: 0.000744\n","Train Epoch: 7 [58880/151166 (39%)]\tLoss: 0.001271\n","Train Epoch: 7 [59520/151166 (39%)]\tLoss: 0.000106\n","Train Epoch: 7 [60160/151166 (40%)]\tLoss: 0.000517\n","Train Epoch: 7 [60800/151166 (40%)]\tLoss: 0.000884\n","Train Epoch: 7 [61440/151166 (41%)]\tLoss: 0.000571\n","Train Epoch: 7 [62080/151166 (41%)]\tLoss: 0.001093\n","Train Epoch: 7 [62720/151166 (41%)]\tLoss: 0.001114\n","Train Epoch: 7 [63360/151166 (42%)]\tLoss: 0.001153\n","Train Epoch: 7 [64000/151166 (42%)]\tLoss: 0.000638\n","Train Epoch: 7 [64640/151166 (43%)]\tLoss: 0.001323\n","Train Epoch: 7 [65280/151166 (43%)]\tLoss: 0.001666\n","Train Epoch: 7 [65920/151166 (44%)]\tLoss: 0.000633\n","Train Epoch: 7 [66560/151166 (44%)]\tLoss: 0.000726\n","Train Epoch: 7 [67200/151166 (44%)]\tLoss: 0.002023\n","Train Epoch: 7 [67840/151166 (45%)]\tLoss: 0.000687\n","Train Epoch: 7 [68480/151166 (45%)]\tLoss: 0.000752\n","Train Epoch: 7 [69120/151166 (46%)]\tLoss: 0.001578\n","Train Epoch: 7 [69760/151166 (46%)]\tLoss: 0.001684\n","Train Epoch: 7 [70400/151166 (47%)]\tLoss: 0.000488\n","Train Epoch: 7 [71040/151166 (47%)]\tLoss: 0.000958\n","Train Epoch: 7 [71680/151166 (47%)]\tLoss: 0.000691\n","Train Epoch: 7 [72320/151166 (48%)]\tLoss: 0.000535\n","Train Epoch: 7 [72960/151166 (48%)]\tLoss: 0.000777\n","Train Epoch: 7 [73600/151166 (49%)]\tLoss: 0.000864\n","Train Epoch: 7 [74240/151166 (49%)]\tLoss: 0.000490\n","Train Epoch: 7 [74880/151166 (50%)]\tLoss: 0.000360\n","Train Epoch: 7 [75520/151166 (50%)]\tLoss: 0.001158\n","Train Epoch: 7 [76160/151166 (50%)]\tLoss: 0.001018\n","Train Epoch: 7 [76800/151166 (51%)]\tLoss: 0.000430\n","Train Epoch: 7 [77440/151166 (51%)]\tLoss: 0.001510\n","Train Epoch: 7 [78080/151166 (52%)]\tLoss: 0.000632\n","Train Epoch: 7 [78720/151166 (52%)]\tLoss: 0.000701\n","Train Epoch: 7 [79360/151166 (52%)]\tLoss: 0.000199\n","Train Epoch: 7 [80000/151166 (53%)]\tLoss: 0.001309\n","Train Epoch: 7 [80640/151166 (53%)]\tLoss: 0.000463\n","Train Epoch: 7 [81280/151166 (54%)]\tLoss: 0.000501\n","Train Epoch: 7 [81920/151166 (54%)]\tLoss: 0.001144\n","Train Epoch: 7 [82560/151166 (55%)]\tLoss: 0.000336\n","Train Epoch: 7 [83200/151166 (55%)]\tLoss: 0.000993\n","Train Epoch: 7 [83840/151166 (55%)]\tLoss: 0.002564\n","Train Epoch: 7 [84480/151166 (56%)]\tLoss: 0.000286\n","Train Epoch: 7 [85120/151166 (56%)]\tLoss: 0.000519\n","Train Epoch: 7 [85760/151166 (57%)]\tLoss: 0.001492\n","Train Epoch: 7 [86400/151166 (57%)]\tLoss: 0.001000\n","Train Epoch: 7 [87040/151166 (58%)]\tLoss: 0.000459\n","Train Epoch: 7 [87680/151166 (58%)]\tLoss: 0.003720\n","Train Epoch: 7 [88320/151166 (58%)]\tLoss: 0.000311\n","Train Epoch: 7 [88960/151166 (59%)]\tLoss: 0.000806\n","Train Epoch: 7 [89600/151166 (59%)]\tLoss: 0.001003\n","Train Epoch: 7 [90240/151166 (60%)]\tLoss: 0.000950\n","Train Epoch: 7 [90880/151166 (60%)]\tLoss: 0.000454\n","Train Epoch: 7 [91520/151166 (61%)]\tLoss: 0.000532\n","Train Epoch: 7 [92160/151166 (61%)]\tLoss: 0.002549\n","Train Epoch: 7 [92800/151166 (61%)]\tLoss: 0.001873\n","Train Epoch: 7 [93440/151166 (62%)]\tLoss: 0.000931\n","Train Epoch: 7 [94080/151166 (62%)]\tLoss: 0.000714\n","Train Epoch: 7 [94720/151166 (63%)]\tLoss: 0.000541\n","Train Epoch: 7 [95360/151166 (63%)]\tLoss: 0.000419\n","Train Epoch: 7 [96000/151166 (64%)]\tLoss: 0.000264\n","Train Epoch: 7 [96640/151166 (64%)]\tLoss: 0.001039\n","Train Epoch: 7 [97280/151166 (64%)]\tLoss: 0.000175\n","Train Epoch: 7 [97920/151166 (65%)]\tLoss: 0.000689\n","Train Epoch: 7 [98560/151166 (65%)]\tLoss: 0.000682\n","Train Epoch: 7 [99200/151166 (66%)]\tLoss: 0.000652\n","Train Epoch: 7 [99840/151166 (66%)]\tLoss: 0.001520\n","Train Epoch: 7 [100480/151166 (66%)]\tLoss: 0.000669\n","Train Epoch: 7 [101120/151166 (67%)]\tLoss: 0.001230\n","Train Epoch: 7 [101760/151166 (67%)]\tLoss: 0.001585\n","Train Epoch: 7 [102400/151166 (68%)]\tLoss: 0.000552\n","Train Epoch: 7 [103040/151166 (68%)]\tLoss: 0.000468\n","Train Epoch: 7 [103680/151166 (69%)]\tLoss: 0.000455\n","Train Epoch: 7 [104320/151166 (69%)]\tLoss: 0.000326\n","Train Epoch: 7 [104960/151166 (69%)]\tLoss: 0.002951\n","Train Epoch: 7 [105600/151166 (70%)]\tLoss: 0.001562\n","Train Epoch: 7 [106240/151166 (70%)]\tLoss: 0.000819\n","Train Epoch: 7 [106880/151166 (71%)]\tLoss: 0.000570\n","Train Epoch: 7 [107520/151166 (71%)]\tLoss: 0.000105\n","Train Epoch: 7 [108160/151166 (72%)]\tLoss: 0.000642\n","Train Epoch: 7 [108800/151166 (72%)]\tLoss: 0.000515\n","Train Epoch: 7 [109440/151166 (72%)]\tLoss: 0.000545\n","Train Epoch: 7 [110080/151166 (73%)]\tLoss: 0.000999\n","Train Epoch: 7 [110720/151166 (73%)]\tLoss: 0.001587\n","Train Epoch: 7 [111360/151166 (74%)]\tLoss: 0.000532\n","Train Epoch: 7 [112000/151166 (74%)]\tLoss: 0.000351\n","Train Epoch: 7 [112640/151166 (75%)]\tLoss: 0.001793\n","Train Epoch: 7 [113280/151166 (75%)]\tLoss: 0.001179\n","Train Epoch: 7 [113920/151166 (75%)]\tLoss: 0.000472\n","Train Epoch: 7 [114560/151166 (76%)]\tLoss: 0.001297\n","Train Epoch: 7 [115200/151166 (76%)]\tLoss: 0.000742\n","Train Epoch: 7 [115840/151166 (77%)]\tLoss: 0.001116\n","Train Epoch: 7 [116480/151166 (77%)]\tLoss: 0.000714\n","Train Epoch: 7 [117120/151166 (77%)]\tLoss: 0.003121\n","Train Epoch: 7 [117760/151166 (78%)]\tLoss: 0.000882\n","Train Epoch: 7 [118400/151166 (78%)]\tLoss: 0.000898\n","Train Epoch: 7 [119040/151166 (79%)]\tLoss: 0.000740\n","Train Epoch: 7 [119680/151166 (79%)]\tLoss: 0.003945\n","Train Epoch: 7 [120320/151166 (80%)]\tLoss: 0.000852\n","Train Epoch: 7 [120960/151166 (80%)]\tLoss: 0.001645\n","Train Epoch: 7 [121600/151166 (80%)]\tLoss: 0.000579\n","Train Epoch: 7 [122240/151166 (81%)]\tLoss: 0.000419\n","Train Epoch: 7 [122880/151166 (81%)]\tLoss: 0.000115\n","Train Epoch: 7 [123520/151166 (82%)]\tLoss: 0.000550\n","Train Epoch: 7 [124160/151166 (82%)]\tLoss: 0.000740\n","Train Epoch: 7 [124800/151166 (83%)]\tLoss: 0.000689\n","Train Epoch: 7 [125440/151166 (83%)]\tLoss: 0.000477\n","Train Epoch: 7 [126080/151166 (83%)]\tLoss: 0.000172\n","Train Epoch: 7 [126720/151166 (84%)]\tLoss: 0.000390\n","Train Epoch: 7 [127360/151166 (84%)]\tLoss: 0.002001\n","Train Epoch: 7 [128000/151166 (85%)]\tLoss: 0.000578\n","Train Epoch: 7 [128640/151166 (85%)]\tLoss: 0.000373\n","Train Epoch: 7 [129280/151166 (86%)]\tLoss: 0.001648\n","Train Epoch: 7 [129920/151166 (86%)]\tLoss: 0.001909\n","Train Epoch: 7 [130560/151166 (86%)]\tLoss: 0.000496\n","Train Epoch: 7 [131200/151166 (87%)]\tLoss: 0.000378\n","Train Epoch: 7 [131840/151166 (87%)]\tLoss: 0.000975\n","Train Epoch: 7 [132480/151166 (88%)]\tLoss: 0.001450\n","Train Epoch: 7 [133120/151166 (88%)]\tLoss: 0.000629\n","Train Epoch: 7 [133760/151166 (88%)]\tLoss: 0.003233\n","Train Epoch: 7 [134400/151166 (89%)]\tLoss: 0.000429\n","Train Epoch: 7 [135040/151166 (89%)]\tLoss: 0.000244\n","Train Epoch: 7 [135680/151166 (90%)]\tLoss: 0.000443\n","Train Epoch: 7 [136320/151166 (90%)]\tLoss: 0.001436\n","Train Epoch: 7 [136960/151166 (91%)]\tLoss: 0.001623\n","Train Epoch: 7 [137600/151166 (91%)]\tLoss: 0.000470\n","Train Epoch: 7 [138240/151166 (91%)]\tLoss: 0.000502\n","Train Epoch: 7 [138880/151166 (92%)]\tLoss: 0.001991\n","Train Epoch: 7 [139520/151166 (92%)]\tLoss: 0.001545\n","Train Epoch: 7 [140160/151166 (93%)]\tLoss: 0.001247\n","Train Epoch: 7 [140800/151166 (93%)]\tLoss: 0.001997\n","Train Epoch: 7 [141440/151166 (94%)]\tLoss: 0.001068\n","Train Epoch: 7 [142080/151166 (94%)]\tLoss: 0.001274\n","Train Epoch: 7 [142720/151166 (94%)]\tLoss: 0.000532\n","Train Epoch: 7 [143360/151166 (95%)]\tLoss: 0.001830\n","Train Epoch: 7 [144000/151166 (95%)]\tLoss: 0.000255\n","Train Epoch: 7 [144640/151166 (96%)]\tLoss: 0.002353\n","Train Epoch: 7 [145280/151166 (96%)]\tLoss: 0.000697\n","Train Epoch: 7 [145920/151166 (97%)]\tLoss: 0.000592\n","Train Epoch: 7 [146560/151166 (97%)]\tLoss: 0.001005\n","Train Epoch: 7 [147200/151166 (97%)]\tLoss: 0.000664\n","Train Epoch: 7 [147840/151166 (98%)]\tLoss: 0.003118\n","Train Epoch: 7 [148480/151166 (98%)]\tLoss: 0.000647\n","Train Epoch: 7 [149120/151166 (99%)]\tLoss: 0.000319\n","Train Epoch: 7 [149760/151166 (99%)]\tLoss: 0.000107\n","Train Epoch: 7 [150400/151166 (99%)]\tLoss: 0.000255\n","Train Epoch: 7 [151040/151166 (100%)]\tLoss: 0.001870\n","Sample outputs (log probs): tensor([[-1.7723e+01, -1.9751e+01, -2.0618e+01, -2.4508e+01, -1.0697e+01,\n","         -2.3961e-05, -1.4601e+01, -2.7513e+01, -2.1885e+01, -2.3380e+01,\n","         -1.9402e+01, -2.5823e+01, -3.1142e+01, -2.8781e+01, -2.9110e+01,\n","         -1.4282e+01, -2.3896e+01, -1.7655e+01, -1.5937e+01, -1.6838e+01,\n","         -3.3911e+01, -2.5593e+01, -3.0712e+01, -2.4112e+01, -2.4456e+01,\n","         -2.1203e+01],\n","        [-1.3277e+01, -3.9361e-02, -6.0562e+00, -1.0083e+01, -9.4016e+00,\n","         -1.3421e+01, -3.3569e+00, -1.4088e+01, -1.6042e+01, -1.3759e+01,\n","         -7.7696e+00, -1.1383e+01, -1.2450e+01, -1.4987e+01, -8.6700e+00,\n","         -1.2223e+01, -8.1943e+00, -9.8100e+00, -8.0428e+00, -1.5953e+01,\n","         -1.2089e+01, -1.7386e+01, -1.4412e+01, -1.6645e+01, -1.1917e+01,\n","         -1.5617e+01],\n","        [-1.7664e+01, -9.0610e+00, -1.1779e+01, -8.1507e-01, -1.9916e+01,\n","         -1.9302e+01, -1.7805e+01, -1.9663e+01, -1.3046e+01, -9.3554e+00,\n","         -2.4886e+01, -1.8094e+01, -1.4912e+01, -1.2043e+01, -5.8536e-01,\n","         -1.2532e+01, -1.1077e+01, -1.9788e+01, -1.1032e+01, -1.4771e+01,\n","         -8.3800e+00, -1.3932e+01, -1.5886e+01, -2.2444e+01, -1.4472e+01,\n","         -1.8308e+01],\n","        [-2.0312e+01, -1.2668e+01, -1.9196e+00, -1.4091e+01, -1.3999e+01,\n","         -1.6315e+01, -1.6142e-01, -2.2990e+01, -1.7242e+01, -1.5028e+01,\n","         -1.8717e+01, -9.5926e+00, -2.2470e+01, -2.0310e+01, -7.5893e+00,\n","         -2.0051e+01, -6.3087e+00, -2.0604e+01, -1.3594e+01, -1.8576e+01,\n","         -1.1772e+01, -2.0720e+01, -1.7860e+01, -2.8723e+01, -1.7516e+01,\n","         -2.2118e+01],\n","        [-1.2515e+01, -1.6752e+01, -1.9722e+01, -1.8410e+01, -1.0980e+01,\n","         -3.9311e-03, -1.7788e+01, -2.1667e+01, -1.8450e+01, -1.9179e+01,\n","         -1.8636e+01, -2.6296e+01, -2.1339e+01, -2.0819e+01, -2.1903e+01,\n","         -5.5829e+00, -1.9775e+01, -1.2926e+01, -1.6654e+01, -8.8941e+00,\n","         -2.6078e+01, -1.6489e+01, -2.4397e+01, -1.9403e+01, -1.6569e+01,\n","         -1.3929e+01]], device='cuda:0')\n","Predicted classes: tensor([ 5,  1, 14,  6,  5], device='cuda:0')\n","Target classes: tensor([ 5,  1, 14,  6,  5], device='cuda:0')\n","\n","Test set: Average loss: 0.001818, Total sum loss: 0.538175, Accuracy: 36825/37792 (97%)\n","\n","Class A: 1213/1247 (97%)\n","Class B: 801/816 (98%)\n","Class C: 1916/1965 (98%)\n","Class D: 802/868 (92%)\n","Class E: 1002/1024 (98%)\n","Class F: 1801/1869 (96%)\n","Class G: 503/519 (97%)\n","Class H: 596/621 (96%)\n","Class I: 2375/2410 (99%)\n","Class J: 730/754 (97%)\n","Class K: 486/502 (97%)\n","Class L: 963/987 (98%)\n","Class M: 1744/1774 (98%)\n","Class N: 1584/1622 (98%)\n","Class O: 4924/5064 (97%)\n","Class P: 1580/1615 (98%)\n","Class Q: 520/536 (97%)\n","Class R: 960/992 (97%)\n","Class S: 4172/4228 (99%)\n","Class T: 1911/1932 (99%)\n","Class U: 2531/2598 (97%)\n","Class V: 847/904 (94%)\n","Class W: 916/938 (98%)\n","Class X: 546/560 (98%)\n","Class Y: 891/924 (96%)\n","Class Z: 511/523 (98%)\n","Model saved with new best test loss: 0.0018 \n","\n","Train Epoch: 8 [0/151166 (0%)]\tLoss: 0.001079\n","Train Epoch: 8 [640/151166 (0%)]\tLoss: 0.001359\n","Train Epoch: 8 [1280/151166 (1%)]\tLoss: 0.000425\n","Train Epoch: 8 [1920/151166 (1%)]\tLoss: 0.000761\n","Train Epoch: 8 [2560/151166 (2%)]\tLoss: 0.001321\n","Train Epoch: 8 [3200/151166 (2%)]\tLoss: 0.000603\n","Train Epoch: 8 [3840/151166 (3%)]\tLoss: 0.000272\n","Train Epoch: 8 [4480/151166 (3%)]\tLoss: 0.001187\n","Train Epoch: 8 [5120/151166 (3%)]\tLoss: 0.000241\n","Train Epoch: 8 [5760/151166 (4%)]\tLoss: 0.000984\n","Train Epoch: 8 [6400/151166 (4%)]\tLoss: 0.001500\n","Train Epoch: 8 [7040/151166 (5%)]\tLoss: 0.000367\n","Train Epoch: 8 [7680/151166 (5%)]\tLoss: 0.001461\n","Train Epoch: 8 [8320/151166 (6%)]\tLoss: 0.000839\n","Train Epoch: 8 [8960/151166 (6%)]\tLoss: 0.002429\n","Train Epoch: 8 [9600/151166 (6%)]\tLoss: 0.000358\n","Train Epoch: 8 [10240/151166 (7%)]\tLoss: 0.001464\n","Train Epoch: 8 [10880/151166 (7%)]\tLoss: 0.001748\n","Train Epoch: 8 [11520/151166 (8%)]\tLoss: 0.001507\n","Train Epoch: 8 [12160/151166 (8%)]\tLoss: 0.001344\n","Train Epoch: 8 [12800/151166 (8%)]\tLoss: 0.001497\n","Train Epoch: 8 [13440/151166 (9%)]\tLoss: 0.002180\n","Train Epoch: 8 [14080/151166 (9%)]\tLoss: 0.001049\n","Train Epoch: 8 [14720/151166 (10%)]\tLoss: 0.000504\n","Train Epoch: 8 [15360/151166 (10%)]\tLoss: 0.004138\n","Train Epoch: 8 [16000/151166 (11%)]\tLoss: 0.000427\n","Train Epoch: 8 [16640/151166 (11%)]\tLoss: 0.000550\n","Train Epoch: 8 [17280/151166 (11%)]\tLoss: 0.000438\n","Train Epoch: 8 [17920/151166 (12%)]\tLoss: 0.000255\n","Train Epoch: 8 [18560/151166 (12%)]\tLoss: 0.000312\n","Train Epoch: 8 [19200/151166 (13%)]\tLoss: 0.000713\n","Train Epoch: 8 [19840/151166 (13%)]\tLoss: 0.000595\n","Train Epoch: 8 [20480/151166 (14%)]\tLoss: 0.000519\n","Train Epoch: 8 [21120/151166 (14%)]\tLoss: 0.001758\n","Train Epoch: 8 [21760/151166 (14%)]\tLoss: 0.000635\n","Train Epoch: 8 [22400/151166 (15%)]\tLoss: 0.001118\n","Train Epoch: 8 [23040/151166 (15%)]\tLoss: 0.000294\n","Train Epoch: 8 [23680/151166 (16%)]\tLoss: 0.001101\n","Train Epoch: 8 [24320/151166 (16%)]\tLoss: 0.001129\n","Train Epoch: 8 [24960/151166 (17%)]\tLoss: 0.000310\n","Train Epoch: 8 [25600/151166 (17%)]\tLoss: 0.001020\n","Train Epoch: 8 [26240/151166 (17%)]\tLoss: 0.000758\n","Train Epoch: 8 [26880/151166 (18%)]\tLoss: 0.001175\n","Train Epoch: 8 [27520/151166 (18%)]\tLoss: 0.000941\n","Train Epoch: 8 [28160/151166 (19%)]\tLoss: 0.000946\n","Train Epoch: 8 [28800/151166 (19%)]\tLoss: 0.001088\n","Train Epoch: 8 [29440/151166 (19%)]\tLoss: 0.001340\n","Train Epoch: 8 [30080/151166 (20%)]\tLoss: 0.001386\n","Train Epoch: 8 [30720/151166 (20%)]\tLoss: 0.000753\n","Train Epoch: 8 [31360/151166 (21%)]\tLoss: 0.001648\n","Train Epoch: 8 [32000/151166 (21%)]\tLoss: 0.001544\n","Train Epoch: 8 [32640/151166 (22%)]\tLoss: 0.000410\n","Train Epoch: 8 [33280/151166 (22%)]\tLoss: 0.000440\n","Train Epoch: 8 [33920/151166 (22%)]\tLoss: 0.001045\n","Train Epoch: 8 [34560/151166 (23%)]\tLoss: 0.001194\n","Train Epoch: 8 [35200/151166 (23%)]\tLoss: 0.000702\n","Train Epoch: 8 [35840/151166 (24%)]\tLoss: 0.001129\n","Train Epoch: 8 [36480/151166 (24%)]\tLoss: 0.001207\n","Train Epoch: 8 [37120/151166 (25%)]\tLoss: 0.001264\n","Train Epoch: 8 [37760/151166 (25%)]\tLoss: 0.000326\n","Train Epoch: 8 [38400/151166 (25%)]\tLoss: 0.001358\n","Train Epoch: 8 [39040/151166 (26%)]\tLoss: 0.000502\n","Train Epoch: 8 [39680/151166 (26%)]\tLoss: 0.001494\n","Train Epoch: 8 [40320/151166 (27%)]\tLoss: 0.000663\n","Train Epoch: 8 [40960/151166 (27%)]\tLoss: 0.000712\n","Train Epoch: 8 [41600/151166 (28%)]\tLoss: 0.000719\n","Train Epoch: 8 [42240/151166 (28%)]\tLoss: 0.001865\n","Train Epoch: 8 [42880/151166 (28%)]\tLoss: 0.001153\n","Train Epoch: 8 [43520/151166 (29%)]\tLoss: 0.000327\n","Train Epoch: 8 [44160/151166 (29%)]\tLoss: 0.000836\n","Train Epoch: 8 [44800/151166 (30%)]\tLoss: 0.000496\n","Train Epoch: 8 [45440/151166 (30%)]\tLoss: 0.001847\n","Train Epoch: 8 [46080/151166 (30%)]\tLoss: 0.000520\n","Train Epoch: 8 [46720/151166 (31%)]\tLoss: 0.000463\n","Train Epoch: 8 [47360/151166 (31%)]\tLoss: 0.001629\n","Train Epoch: 8 [48000/151166 (32%)]\tLoss: 0.000268\n","Train Epoch: 8 [48640/151166 (32%)]\tLoss: 0.000541\n","Train Epoch: 8 [49280/151166 (33%)]\tLoss: 0.001090\n","Train Epoch: 8 [49920/151166 (33%)]\tLoss: 0.000239\n","Train Epoch: 8 [50560/151166 (33%)]\tLoss: 0.000725\n","Train Epoch: 8 [51200/151166 (34%)]\tLoss: 0.000605\n","Train Epoch: 8 [51840/151166 (34%)]\tLoss: 0.000858\n","Train Epoch: 8 [52480/151166 (35%)]\tLoss: 0.001029\n","Train Epoch: 8 [53120/151166 (35%)]\tLoss: 0.000370\n","Train Epoch: 8 [53760/151166 (36%)]\tLoss: 0.000245\n","Train Epoch: 8 [54400/151166 (36%)]\tLoss: 0.000896\n","Train Epoch: 8 [55040/151166 (36%)]\tLoss: 0.000939\n","Train Epoch: 8 [55680/151166 (37%)]\tLoss: 0.000294\n","Train Epoch: 8 [56320/151166 (37%)]\tLoss: 0.000467\n","Train Epoch: 8 [56960/151166 (38%)]\tLoss: 0.001220\n","Train Epoch: 8 [57600/151166 (38%)]\tLoss: 0.000171\n","Train Epoch: 8 [58240/151166 (39%)]\tLoss: 0.000387\n","Train Epoch: 8 [58880/151166 (39%)]\tLoss: 0.002231\n","Train Epoch: 8 [59520/151166 (39%)]\tLoss: 0.002215\n","Train Epoch: 8 [60160/151166 (40%)]\tLoss: 0.000301\n","Train Epoch: 8 [60800/151166 (40%)]\tLoss: 0.001276\n","Train Epoch: 8 [61440/151166 (41%)]\tLoss: 0.000667\n","Train Epoch: 8 [62080/151166 (41%)]\tLoss: 0.000248\n","Train Epoch: 8 [62720/151166 (41%)]\tLoss: 0.001182\n","Train Epoch: 8 [63360/151166 (42%)]\tLoss: 0.000705\n","Train Epoch: 8 [64000/151166 (42%)]\tLoss: 0.001123\n","Train Epoch: 8 [64640/151166 (43%)]\tLoss: 0.001589\n","Train Epoch: 8 [65280/151166 (43%)]\tLoss: 0.000548\n","Train Epoch: 8 [65920/151166 (44%)]\tLoss: 0.002325\n","Train Epoch: 8 [66560/151166 (44%)]\tLoss: 0.001033\n","Train Epoch: 8 [67200/151166 (44%)]\tLoss: 0.000761\n","Train Epoch: 8 [67840/151166 (45%)]\tLoss: 0.000677\n","Train Epoch: 8 [68480/151166 (45%)]\tLoss: 0.000167\n","Train Epoch: 8 [69120/151166 (46%)]\tLoss: 0.000178\n","Train Epoch: 8 [69760/151166 (46%)]\tLoss: 0.000537\n","Train Epoch: 8 [70400/151166 (47%)]\tLoss: 0.001484\n","Train Epoch: 8 [71040/151166 (47%)]\tLoss: 0.001250\n","Train Epoch: 8 [71680/151166 (47%)]\tLoss: 0.000255\n","Train Epoch: 8 [72320/151166 (48%)]\tLoss: 0.000528\n","Train Epoch: 8 [72960/151166 (48%)]\tLoss: 0.001701\n","Train Epoch: 8 [73600/151166 (49%)]\tLoss: 0.000619\n","Train Epoch: 8 [74240/151166 (49%)]\tLoss: 0.000821\n","Train Epoch: 8 [74880/151166 (50%)]\tLoss: 0.000720\n","Train Epoch: 8 [75520/151166 (50%)]\tLoss: 0.001036\n","Train Epoch: 8 [76160/151166 (50%)]\tLoss: 0.000790\n","Train Epoch: 8 [76800/151166 (51%)]\tLoss: 0.000950\n","Train Epoch: 8 [77440/151166 (51%)]\tLoss: 0.000427\n","Train Epoch: 8 [78080/151166 (52%)]\tLoss: 0.000391\n","Train Epoch: 8 [78720/151166 (52%)]\tLoss: 0.000388\n","Train Epoch: 8 [79360/151166 (52%)]\tLoss: 0.001283\n","Train Epoch: 8 [80000/151166 (53%)]\tLoss: 0.001644\n","Train Epoch: 8 [80640/151166 (53%)]\tLoss: 0.000696\n","Train Epoch: 8 [81280/151166 (54%)]\tLoss: 0.000852\n","Train Epoch: 8 [81920/151166 (54%)]\tLoss: 0.000588\n","Train Epoch: 8 [82560/151166 (55%)]\tLoss: 0.004370\n","Train Epoch: 8 [83200/151166 (55%)]\tLoss: 0.001314\n","Train Epoch: 8 [83840/151166 (55%)]\tLoss: 0.000443\n","Train Epoch: 8 [84480/151166 (56%)]\tLoss: 0.000678\n","Train Epoch: 8 [85120/151166 (56%)]\tLoss: 0.000227\n","Train Epoch: 8 [85760/151166 (57%)]\tLoss: 0.001250\n","Train Epoch: 8 [86400/151166 (57%)]\tLoss: 0.002438\n","Train Epoch: 8 [87040/151166 (58%)]\tLoss: 0.000135\n","Train Epoch: 8 [87680/151166 (58%)]\tLoss: 0.001215\n","Train Epoch: 8 [88320/151166 (58%)]\tLoss: 0.008177\n","Train Epoch: 8 [88960/151166 (59%)]\tLoss: 0.001192\n","Train Epoch: 8 [89600/151166 (59%)]\tLoss: 0.001044\n","Train Epoch: 8 [90240/151166 (60%)]\tLoss: 0.000396\n","Train Epoch: 8 [90880/151166 (60%)]\tLoss: 0.001055\n","Train Epoch: 8 [91520/151166 (61%)]\tLoss: 0.003303\n","Train Epoch: 8 [92160/151166 (61%)]\tLoss: 0.000771\n","Train Epoch: 8 [92800/151166 (61%)]\tLoss: 0.000521\n","Train Epoch: 8 [93440/151166 (62%)]\tLoss: 0.000581\n","Train Epoch: 8 [94080/151166 (62%)]\tLoss: 0.001435\n","Train Epoch: 8 [94720/151166 (63%)]\tLoss: 0.000960\n","Train Epoch: 8 [95360/151166 (63%)]\tLoss: 0.001713\n","Train Epoch: 8 [96000/151166 (64%)]\tLoss: 0.000983\n","Train Epoch: 8 [96640/151166 (64%)]\tLoss: 0.000552\n","Train Epoch: 8 [97280/151166 (64%)]\tLoss: 0.001067\n","Train Epoch: 8 [97920/151166 (65%)]\tLoss: 0.001346\n","Train Epoch: 8 [98560/151166 (65%)]\tLoss: 0.001508\n","Train Epoch: 8 [99200/151166 (66%)]\tLoss: 0.001389\n","Train Epoch: 8 [99840/151166 (66%)]\tLoss: 0.001418\n","Train Epoch: 8 [100480/151166 (66%)]\tLoss: 0.001013\n","Train Epoch: 8 [101120/151166 (67%)]\tLoss: 0.001381\n","Train Epoch: 8 [101760/151166 (67%)]\tLoss: 0.000774\n","Train Epoch: 8 [102400/151166 (68%)]\tLoss: 0.000930\n","Train Epoch: 8 [103040/151166 (68%)]\tLoss: 0.000357\n","Train Epoch: 8 [103680/151166 (69%)]\tLoss: 0.000710\n","Train Epoch: 8 [104320/151166 (69%)]\tLoss: 0.000754\n","Train Epoch: 8 [104960/151166 (69%)]\tLoss: 0.000671\n","Train Epoch: 8 [105600/151166 (70%)]\tLoss: 0.000708\n","Train Epoch: 8 [106240/151166 (70%)]\tLoss: 0.003614\n","Train Epoch: 8 [106880/151166 (71%)]\tLoss: 0.000308\n","Train Epoch: 8 [107520/151166 (71%)]\tLoss: 0.001174\n","Train Epoch: 8 [108160/151166 (72%)]\tLoss: 0.001045\n","Train Epoch: 8 [108800/151166 (72%)]\tLoss: 0.000213\n","Train Epoch: 8 [109440/151166 (72%)]\tLoss: 0.001282\n","Train Epoch: 8 [110080/151166 (73%)]\tLoss: 0.001223\n","Train Epoch: 8 [110720/151166 (73%)]\tLoss: 0.000470\n","Train Epoch: 8 [111360/151166 (74%)]\tLoss: 0.002090\n","Train Epoch: 8 [112000/151166 (74%)]\tLoss: 0.000744\n","Train Epoch: 8 [112640/151166 (75%)]\tLoss: 0.002170\n","Train Epoch: 8 [113280/151166 (75%)]\tLoss: 0.000316\n","Train Epoch: 8 [113920/151166 (75%)]\tLoss: 0.000858\n","Train Epoch: 8 [114560/151166 (76%)]\tLoss: 0.000438\n","Train Epoch: 8 [115200/151166 (76%)]\tLoss: 0.002301\n","Train Epoch: 8 [115840/151166 (77%)]\tLoss: 0.001332\n","Train Epoch: 8 [116480/151166 (77%)]\tLoss: 0.000424\n","Train Epoch: 8 [117120/151166 (77%)]\tLoss: 0.000332\n","Train Epoch: 8 [117760/151166 (78%)]\tLoss: 0.000481\n","Train Epoch: 8 [118400/151166 (78%)]\tLoss: 0.000692\n","Train Epoch: 8 [119040/151166 (79%)]\tLoss: 0.000523\n","Train Epoch: 8 [119680/151166 (79%)]\tLoss: 0.001280\n","Train Epoch: 8 [120320/151166 (80%)]\tLoss: 0.001716\n","Train Epoch: 8 [120960/151166 (80%)]\tLoss: 0.000699\n","Train Epoch: 8 [121600/151166 (80%)]\tLoss: 0.000599\n","Train Epoch: 8 [122240/151166 (81%)]\tLoss: 0.001320\n","Train Epoch: 8 [122880/151166 (81%)]\tLoss: 0.000329\n","Train Epoch: 8 [123520/151166 (82%)]\tLoss: 0.005253\n","Train Epoch: 8 [124160/151166 (82%)]\tLoss: 0.001077\n","Train Epoch: 8 [124800/151166 (83%)]\tLoss: 0.000898\n","Train Epoch: 8 [125440/151166 (83%)]\tLoss: 0.001073\n","Train Epoch: 8 [126080/151166 (83%)]\tLoss: 0.000699\n","Train Epoch: 8 [126720/151166 (84%)]\tLoss: 0.000514\n","Train Epoch: 8 [127360/151166 (84%)]\tLoss: 0.000189\n","Train Epoch: 8 [128000/151166 (85%)]\tLoss: 0.001858\n","Train Epoch: 8 [128640/151166 (85%)]\tLoss: 0.000691\n","Train Epoch: 8 [129280/151166 (86%)]\tLoss: 0.001304\n","Train Epoch: 8 [129920/151166 (86%)]\tLoss: 0.002750\n","Train Epoch: 8 [130560/151166 (86%)]\tLoss: 0.001469\n","Train Epoch: 8 [131200/151166 (87%)]\tLoss: 0.000712\n","Train Epoch: 8 [131840/151166 (87%)]\tLoss: 0.000511\n","Train Epoch: 8 [132480/151166 (88%)]\tLoss: 0.003201\n","Train Epoch: 8 [133120/151166 (88%)]\tLoss: 0.000318\n","Train Epoch: 8 [133760/151166 (88%)]\tLoss: 0.001928\n","Train Epoch: 8 [134400/151166 (89%)]\tLoss: 0.000826\n","Train Epoch: 8 [135040/151166 (89%)]\tLoss: 0.000992\n","Train Epoch: 8 [135680/151166 (90%)]\tLoss: 0.000816\n","Train Epoch: 8 [136320/151166 (90%)]\tLoss: 0.003663\n","Train Epoch: 8 [136960/151166 (91%)]\tLoss: 0.000592\n","Train Epoch: 8 [137600/151166 (91%)]\tLoss: 0.000499\n","Train Epoch: 8 [138240/151166 (91%)]\tLoss: 0.001542\n","Train Epoch: 8 [138880/151166 (92%)]\tLoss: 0.000723\n","Train Epoch: 8 [139520/151166 (92%)]\tLoss: 0.001571\n","Train Epoch: 8 [140160/151166 (93%)]\tLoss: 0.001697\n","Train Epoch: 8 [140800/151166 (93%)]\tLoss: 0.000287\n","Train Epoch: 8 [141440/151166 (94%)]\tLoss: 0.001110\n","Train Epoch: 8 [142080/151166 (94%)]\tLoss: 0.003005\n","Train Epoch: 8 [142720/151166 (94%)]\tLoss: 0.000551\n","Train Epoch: 8 [143360/151166 (95%)]\tLoss: 0.001168\n","Train Epoch: 8 [144000/151166 (95%)]\tLoss: 0.000330\n","Train Epoch: 8 [144640/151166 (96%)]\tLoss: 0.001156\n","Train Epoch: 8 [145280/151166 (96%)]\tLoss: 0.004720\n","Train Epoch: 8 [145920/151166 (97%)]\tLoss: 0.000554\n","Train Epoch: 8 [146560/151166 (97%)]\tLoss: 0.000899\n","Train Epoch: 8 [147200/151166 (97%)]\tLoss: 0.001503\n","Train Epoch: 8 [147840/151166 (98%)]\tLoss: 0.000477\n","Train Epoch: 8 [148480/151166 (98%)]\tLoss: 0.001306\n","Train Epoch: 8 [149120/151166 (99%)]\tLoss: 0.000327\n","Train Epoch: 8 [149760/151166 (99%)]\tLoss: 0.000756\n","Train Epoch: 8 [150400/151166 (99%)]\tLoss: 0.000534\n","Train Epoch: 8 [151040/151166 (100%)]\tLoss: 0.001059\n","Sample outputs (log probs): tensor([[-1.5605e+01, -1.0996e+01, -8.5289e+00, -6.6453e+00, -1.7142e+01,\n","         -1.7414e+01, -1.4517e+01, -2.0507e+01, -1.3740e+01, -1.1687e+01,\n","         -2.2940e+01, -1.6793e+01, -1.6653e+01, -1.6177e+01, -1.5605e-03,\n","         -1.3891e+01, -1.1744e+01, -1.8945e+01, -1.2891e+01, -1.5966e+01,\n","         -1.0701e+01, -1.6535e+01, -1.9602e+01, -2.4610e+01, -1.5289e+01,\n","         -1.8311e+01],\n","        [-3.4066e+00, -1.2501e+01, -1.1430e+01, -8.9309e+00, -1.8908e+01,\n","         -8.3734e+00, -1.0798e+01, -5.2296e+00, -1.6749e+00, -3.2019e+00,\n","         -6.7612e+00, -5.7808e+00, -8.3889e+00, -4.4648e+00, -1.0724e+01,\n","         -9.6645e+00, -5.7174e+00, -1.0243e+01, -9.4274e+00, -3.3419e+00,\n","         -4.1778e+00, -7.1356e+00, -8.2261e+00, -4.7943e-01, -3.1557e+00,\n","         -9.1142e+00],\n","        [-2.5060e+01, -1.8299e+01, -6.9165e-04, -1.5334e+01, -1.0074e+01,\n","         -1.6264e+01, -1.1725e+01, -3.0229e+01, -1.1689e+01, -1.7055e+01,\n","         -1.7791e+01, -7.3737e+00, -2.5239e+01, -2.1553e+01, -1.3033e+01,\n","         -2.2099e+01, -1.3822e+01, -1.5615e+01, -1.6169e+01, -1.9424e+01,\n","         -1.4713e+01, -2.1727e+01, -2.2864e+01, -2.5571e+01, -1.9692e+01,\n","         -1.3831e+01],\n","        [-6.5615e+00, -8.9520e+00, -1.0494e+01, -7.8222e+00, -1.0805e+01,\n","         -8.3385e+00, -9.1899e+00, -4.6387e+00, -1.1574e+01, -1.2022e+01,\n","         -8.4537e+00, -1.1804e+01, -3.4165e+00, -8.0217e-02, -1.0380e+01,\n","         -3.6680e+00, -1.0113e+01, -8.1030e+00, -1.1451e+01, -7.9598e+00,\n","         -8.9436e+00, -7.0248e+00, -5.3973e+00, -1.0622e+01, -8.6145e+00,\n","         -1.3457e+01],\n","        [-1.0710e+01, -1.2774e+01, -2.2204e+01, -1.1305e+01, -2.7875e+01,\n","         -2.6675e+01, -1.9925e+01, -1.7245e+01, -2.6556e+01, -2.5384e+01,\n","         -2.2630e+01, -2.9261e+01, -1.3541e-04, -9.4208e+00, -1.2374e+01,\n","         -1.6590e+01, -1.2647e+01, -1.1853e+01, -2.6125e+01, -1.9615e+01,\n","         -1.6435e+01, -1.9996e+01, -1.3038e+01, -2.3858e+01, -2.3485e+01,\n","         -2.5042e+01]], device='cuda:0')\n","Predicted classes: tensor([14, 23,  2, 13, 12], device='cuda:0')\n","Target classes: tensor([14,  8,  2, 13, 12], device='cuda:0')\n","\n","Test set: Average loss: 0.001755, Total sum loss: 0.519500, Accuracy: 36757/37792 (97%)\n","\n","Class A: 1216/1247 (98%)\n","Class B: 799/816 (98%)\n","Class C: 1919/1965 (98%)\n","Class D: 824/868 (95%)\n","Class E: 1007/1024 (98%)\n","Class F: 1826/1869 (98%)\n","Class G: 489/519 (94%)\n","Class H: 598/621 (96%)\n","Class I: 2376/2410 (99%)\n","Class J: 729/754 (97%)\n","Class K: 487/502 (97%)\n","Class L: 964/987 (98%)\n","Class M: 1743/1774 (98%)\n","Class N: 1588/1622 (98%)\n","Class O: 4817/5064 (95%)\n","Class P: 1582/1615 (98%)\n","Class Q: 516/536 (96%)\n","Class R: 973/992 (98%)\n","Class S: 4168/4228 (99%)\n","Class T: 1914/1932 (99%)\n","Class U: 2499/2598 (96%)\n","Class V: 859/904 (95%)\n","Class W: 915/938 (98%)\n","Class X: 545/560 (97%)\n","Class Y: 893/924 (97%)\n","Class Z: 511/523 (98%)\n","Model saved with new best test loss: 0.0018 \n","\n","Train Epoch: 9 [0/151166 (0%)]\tLoss: 0.000370\n","Train Epoch: 9 [640/151166 (0%)]\tLoss: 0.000616\n","Train Epoch: 9 [1280/151166 (1%)]\tLoss: 0.000703\n","Train Epoch: 9 [1920/151166 (1%)]\tLoss: 0.000372\n","Train Epoch: 9 [2560/151166 (2%)]\tLoss: 0.000515\n","Train Epoch: 9 [3200/151166 (2%)]\tLoss: 0.000362\n","Train Epoch: 9 [3840/151166 (3%)]\tLoss: 0.001043\n","Train Epoch: 9 [4480/151166 (3%)]\tLoss: 0.000401\n","Train Epoch: 9 [5120/151166 (3%)]\tLoss: 0.001310\n","Train Epoch: 9 [5760/151166 (4%)]\tLoss: 0.000345\n","Train Epoch: 9 [6400/151166 (4%)]\tLoss: 0.001839\n","Train Epoch: 9 [7040/151166 (5%)]\tLoss: 0.002195\n","Train Epoch: 9 [7680/151166 (5%)]\tLoss: 0.000482\n","Train Epoch: 9 [8320/151166 (6%)]\tLoss: 0.000625\n","Train Epoch: 9 [8960/151166 (6%)]\tLoss: 0.002076\n","Train Epoch: 9 [9600/151166 (6%)]\tLoss: 0.000446\n","Train Epoch: 9 [10240/151166 (7%)]\tLoss: 0.001453\n","Train Epoch: 9 [10880/151166 (7%)]\tLoss: 0.000808\n","Train Epoch: 9 [11520/151166 (8%)]\tLoss: 0.000824\n","Train Epoch: 9 [12160/151166 (8%)]\tLoss: 0.001359\n","Train Epoch: 9 [12800/151166 (8%)]\tLoss: 0.001316\n","Train Epoch: 9 [13440/151166 (9%)]\tLoss: 0.000503\n","Train Epoch: 9 [14080/151166 (9%)]\tLoss: 0.000300\n","Train Epoch: 9 [14720/151166 (10%)]\tLoss: 0.001019\n","Train Epoch: 9 [15360/151166 (10%)]\tLoss: 0.000740\n","Train Epoch: 9 [16000/151166 (11%)]\tLoss: 0.001686\n","Train Epoch: 9 [16640/151166 (11%)]\tLoss: 0.001204\n","Train Epoch: 9 [17280/151166 (11%)]\tLoss: 0.000525\n","Train Epoch: 9 [17920/151166 (12%)]\tLoss: 0.000666\n","Train Epoch: 9 [18560/151166 (12%)]\tLoss: 0.000414\n","Train Epoch: 9 [19200/151166 (13%)]\tLoss: 0.000286\n","Train Epoch: 9 [19840/151166 (13%)]\tLoss: 0.002782\n","Train Epoch: 9 [20480/151166 (14%)]\tLoss: 0.001521\n","Train Epoch: 9 [21120/151166 (14%)]\tLoss: 0.001159\n","Train Epoch: 9 [21760/151166 (14%)]\tLoss: 0.002221\n","Train Epoch: 9 [22400/151166 (15%)]\tLoss: 0.000609\n","Train Epoch: 9 [23040/151166 (15%)]\tLoss: 0.000827\n","Train Epoch: 9 [23680/151166 (16%)]\tLoss: 0.001167\n","Train Epoch: 9 [24320/151166 (16%)]\tLoss: 0.000759\n","Train Epoch: 9 [24960/151166 (17%)]\tLoss: 0.000935\n","Train Epoch: 9 [25600/151166 (17%)]\tLoss: 0.000901\n","Train Epoch: 9 [26240/151166 (17%)]\tLoss: 0.001326\n","Train Epoch: 9 [26880/151166 (18%)]\tLoss: 0.000232\n","Train Epoch: 9 [27520/151166 (18%)]\tLoss: 0.000505\n","Train Epoch: 9 [28160/151166 (19%)]\tLoss: 0.000742\n","Train Epoch: 9 [28800/151166 (19%)]\tLoss: 0.000881\n","Train Epoch: 9 [29440/151166 (19%)]\tLoss: 0.000505\n","Train Epoch: 9 [30080/151166 (20%)]\tLoss: 0.000835\n","Train Epoch: 9 [30720/151166 (20%)]\tLoss: 0.000466\n","Train Epoch: 9 [31360/151166 (21%)]\tLoss: 0.003291\n","Train Epoch: 9 [32000/151166 (21%)]\tLoss: 0.000251\n","Train Epoch: 9 [32640/151166 (22%)]\tLoss: 0.000445\n","Train Epoch: 9 [33280/151166 (22%)]\tLoss: 0.000457\n","Train Epoch: 9 [33920/151166 (22%)]\tLoss: 0.000386\n","Train Epoch: 9 [34560/151166 (23%)]\tLoss: 0.000885\n","Train Epoch: 9 [35200/151166 (23%)]\tLoss: 0.000282\n","Train Epoch: 9 [35840/151166 (24%)]\tLoss: 0.000339\n","Train Epoch: 9 [36480/151166 (24%)]\tLoss: 0.000473\n","Train Epoch: 9 [37120/151166 (25%)]\tLoss: 0.000973\n","Train Epoch: 9 [37760/151166 (25%)]\tLoss: 0.000459\n","Train Epoch: 9 [38400/151166 (25%)]\tLoss: 0.000537\n","Train Epoch: 9 [39040/151166 (26%)]\tLoss: 0.003250\n","Train Epoch: 9 [39680/151166 (26%)]\tLoss: 0.000252\n","Train Epoch: 9 [40320/151166 (27%)]\tLoss: 0.000675\n","Train Epoch: 9 [40960/151166 (27%)]\tLoss: 0.001603\n","Train Epoch: 9 [41600/151166 (28%)]\tLoss: 0.001121\n","Train Epoch: 9 [42240/151166 (28%)]\tLoss: 0.001893\n","Train Epoch: 9 [42880/151166 (28%)]\tLoss: 0.001635\n","Train Epoch: 9 [43520/151166 (29%)]\tLoss: 0.002615\n","Train Epoch: 9 [44160/151166 (29%)]\tLoss: 0.000750\n","Train Epoch: 9 [44800/151166 (30%)]\tLoss: 0.000336\n","Train Epoch: 9 [45440/151166 (30%)]\tLoss: 0.000470\n","Train Epoch: 9 [46080/151166 (30%)]\tLoss: 0.000417\n","Train Epoch: 9 [46720/151166 (31%)]\tLoss: 0.000268\n","Train Epoch: 9 [47360/151166 (31%)]\tLoss: 0.001547\n","Train Epoch: 9 [48000/151166 (32%)]\tLoss: 0.000320\n","Train Epoch: 9 [48640/151166 (32%)]\tLoss: 0.001345\n","Train Epoch: 9 [49280/151166 (33%)]\tLoss: 0.000206\n","Train Epoch: 9 [49920/151166 (33%)]\tLoss: 0.000326\n","Train Epoch: 9 [50560/151166 (33%)]\tLoss: 0.000243\n","Train Epoch: 9 [51200/151166 (34%)]\tLoss: 0.000224\n","Train Epoch: 9 [51840/151166 (34%)]\tLoss: 0.000449\n","Train Epoch: 9 [52480/151166 (35%)]\tLoss: 0.000272\n","Train Epoch: 9 [53120/151166 (35%)]\tLoss: 0.000457\n","Train Epoch: 9 [53760/151166 (36%)]\tLoss: 0.000907\n","Train Epoch: 9 [54400/151166 (36%)]\tLoss: 0.002112\n","Train Epoch: 9 [55040/151166 (36%)]\tLoss: 0.001542\n","Train Epoch: 9 [55680/151166 (37%)]\tLoss: 0.002151\n","Train Epoch: 9 [56320/151166 (37%)]\tLoss: 0.000199\n","Train Epoch: 9 [56960/151166 (38%)]\tLoss: 0.002556\n","Train Epoch: 9 [57600/151166 (38%)]\tLoss: 0.000445\n","Train Epoch: 9 [58240/151166 (39%)]\tLoss: 0.001813\n","Train Epoch: 9 [58880/151166 (39%)]\tLoss: 0.000441\n","Train Epoch: 9 [59520/151166 (39%)]\tLoss: 0.000226\n","Train Epoch: 9 [60160/151166 (40%)]\tLoss: 0.000429\n","Train Epoch: 9 [60800/151166 (40%)]\tLoss: 0.000265\n","Train Epoch: 9 [61440/151166 (41%)]\tLoss: 0.000394\n","Train Epoch: 9 [62080/151166 (41%)]\tLoss: 0.001560\n","Train Epoch: 9 [62720/151166 (41%)]\tLoss: 0.001282\n","Train Epoch: 9 [63360/151166 (42%)]\tLoss: 0.000511\n","Train Epoch: 9 [64000/151166 (42%)]\tLoss: 0.001203\n","Train Epoch: 9 [64640/151166 (43%)]\tLoss: 0.000433\n","Train Epoch: 9 [65280/151166 (43%)]\tLoss: 0.000190\n","Train Epoch: 9 [65920/151166 (44%)]\tLoss: 0.000838\n","Train Epoch: 9 [66560/151166 (44%)]\tLoss: 0.000219\n","Train Epoch: 9 [67200/151166 (44%)]\tLoss: 0.000546\n","Train Epoch: 9 [67840/151166 (45%)]\tLoss: 0.003567\n","Train Epoch: 9 [68480/151166 (45%)]\tLoss: 0.000373\n","Train Epoch: 9 [69120/151166 (46%)]\tLoss: 0.000221\n","Train Epoch: 9 [69760/151166 (46%)]\tLoss: 0.000477\n","Train Epoch: 9 [70400/151166 (47%)]\tLoss: 0.000782\n","Train Epoch: 9 [71040/151166 (47%)]\tLoss: 0.000418\n","Train Epoch: 9 [71680/151166 (47%)]\tLoss: 0.002143\n","Train Epoch: 9 [72320/151166 (48%)]\tLoss: 0.000536\n","Train Epoch: 9 [72960/151166 (48%)]\tLoss: 0.000258\n","Train Epoch: 9 [73600/151166 (49%)]\tLoss: 0.000550\n","Train Epoch: 9 [74240/151166 (49%)]\tLoss: 0.001995\n","Train Epoch: 9 [74880/151166 (50%)]\tLoss: 0.000902\n","Train Epoch: 9 [75520/151166 (50%)]\tLoss: 0.001216\n","Train Epoch: 9 [76160/151166 (50%)]\tLoss: 0.000631\n","Train Epoch: 9 [76800/151166 (51%)]\tLoss: 0.000991\n","Train Epoch: 9 [77440/151166 (51%)]\tLoss: 0.002703\n","Train Epoch: 9 [78080/151166 (52%)]\tLoss: 0.000816\n","Train Epoch: 9 [78720/151166 (52%)]\tLoss: 0.000301\n","Train Epoch: 9 [79360/151166 (52%)]\tLoss: 0.001194\n","Train Epoch: 9 [80000/151166 (53%)]\tLoss: 0.000675\n","Train Epoch: 9 [80640/151166 (53%)]\tLoss: 0.000877\n","Train Epoch: 9 [81280/151166 (54%)]\tLoss: 0.000772\n","Train Epoch: 9 [81920/151166 (54%)]\tLoss: 0.000748\n","Train Epoch: 9 [82560/151166 (55%)]\tLoss: 0.001751\n","Train Epoch: 9 [83200/151166 (55%)]\tLoss: 0.002459\n","Train Epoch: 9 [83840/151166 (55%)]\tLoss: 0.000543\n","Train Epoch: 9 [84480/151166 (56%)]\tLoss: 0.000652\n","Train Epoch: 9 [85120/151166 (56%)]\tLoss: 0.000812\n","Train Epoch: 9 [85760/151166 (57%)]\tLoss: 0.001063\n","Train Epoch: 9 [86400/151166 (57%)]\tLoss: 0.001835\n","Train Epoch: 9 [87040/151166 (58%)]\tLoss: 0.001197\n","Train Epoch: 9 [87680/151166 (58%)]\tLoss: 0.000664\n","Train Epoch: 9 [88320/151166 (58%)]\tLoss: 0.000546\n","Train Epoch: 9 [88960/151166 (59%)]\tLoss: 0.000961\n","Train Epoch: 9 [89600/151166 (59%)]\tLoss: 0.001179\n","Train Epoch: 9 [90240/151166 (60%)]\tLoss: 0.001144\n","Train Epoch: 9 [90880/151166 (60%)]\tLoss: 0.000867\n","Train Epoch: 9 [91520/151166 (61%)]\tLoss: 0.000340\n","Train Epoch: 9 [92160/151166 (61%)]\tLoss: 0.000549\n","Train Epoch: 9 [92800/151166 (61%)]\tLoss: 0.001115\n","Train Epoch: 9 [93440/151166 (62%)]\tLoss: 0.000350\n","Train Epoch: 9 [94080/151166 (62%)]\tLoss: 0.001489\n","Train Epoch: 9 [94720/151166 (63%)]\tLoss: 0.000838\n","Train Epoch: 9 [95360/151166 (63%)]\tLoss: 0.000168\n","Train Epoch: 9 [96000/151166 (64%)]\tLoss: 0.001205\n","Train Epoch: 9 [96640/151166 (64%)]\tLoss: 0.000095\n","Train Epoch: 9 [97280/151166 (64%)]\tLoss: 0.000329\n","Train Epoch: 9 [97920/151166 (65%)]\tLoss: 0.001248\n","Train Epoch: 9 [98560/151166 (65%)]\tLoss: 0.000624\n","Train Epoch: 9 [99200/151166 (66%)]\tLoss: 0.000695\n","Train Epoch: 9 [99840/151166 (66%)]\tLoss: 0.000830\n","Train Epoch: 9 [100480/151166 (66%)]\tLoss: 0.001135\n","Train Epoch: 9 [101120/151166 (67%)]\tLoss: 0.001454\n","Train Epoch: 9 [101760/151166 (67%)]\tLoss: 0.001348\n","Train Epoch: 9 [102400/151166 (68%)]\tLoss: 0.000415\n","Train Epoch: 9 [103040/151166 (68%)]\tLoss: 0.000786\n","Train Epoch: 9 [103680/151166 (69%)]\tLoss: 0.000335\n","Train Epoch: 9 [104320/151166 (69%)]\tLoss: 0.000517\n","Train Epoch: 9 [104960/151166 (69%)]\tLoss: 0.000672\n","Train Epoch: 9 [105600/151166 (70%)]\tLoss: 0.001635\n","Train Epoch: 9 [106240/151166 (70%)]\tLoss: 0.000658\n","Train Epoch: 9 [106880/151166 (71%)]\tLoss: 0.000534\n","Train Epoch: 9 [107520/151166 (71%)]\tLoss: 0.000893\n","Train Epoch: 9 [108160/151166 (72%)]\tLoss: 0.001492\n","Train Epoch: 9 [108800/151166 (72%)]\tLoss: 0.000271\n","Train Epoch: 9 [109440/151166 (72%)]\tLoss: 0.000691\n","Train Epoch: 9 [110080/151166 (73%)]\tLoss: 0.001848\n","Train Epoch: 9 [110720/151166 (73%)]\tLoss: 0.001912\n","Train Epoch: 9 [111360/151166 (74%)]\tLoss: 0.001555\n","Train Epoch: 9 [112000/151166 (74%)]\tLoss: 0.001419\n","Train Epoch: 9 [112640/151166 (75%)]\tLoss: 0.000480\n","Train Epoch: 9 [113280/151166 (75%)]\tLoss: 0.000328\n","Train Epoch: 9 [113920/151166 (75%)]\tLoss: 0.000827\n","Train Epoch: 9 [114560/151166 (76%)]\tLoss: 0.000465\n","Train Epoch: 9 [115200/151166 (76%)]\tLoss: 0.000159\n","Train Epoch: 9 [115840/151166 (77%)]\tLoss: 0.000905\n","Train Epoch: 9 [116480/151166 (77%)]\tLoss: 0.001128\n","Train Epoch: 9 [117120/151166 (77%)]\tLoss: 0.000527\n","Train Epoch: 9 [117760/151166 (78%)]\tLoss: 0.000898\n","Train Epoch: 9 [118400/151166 (78%)]\tLoss: 0.000659\n","Train Epoch: 9 [119040/151166 (79%)]\tLoss: 0.000623\n","Train Epoch: 9 [119680/151166 (79%)]\tLoss: 0.000521\n","Train Epoch: 9 [120320/151166 (80%)]\tLoss: 0.000287\n","Train Epoch: 9 [120960/151166 (80%)]\tLoss: 0.001272\n","Train Epoch: 9 [121600/151166 (80%)]\tLoss: 0.000647\n","Train Epoch: 9 [122240/151166 (81%)]\tLoss: 0.000716\n","Train Epoch: 9 [122880/151166 (81%)]\tLoss: 0.001056\n","Train Epoch: 9 [123520/151166 (82%)]\tLoss: 0.000480\n","Train Epoch: 9 [124160/151166 (82%)]\tLoss: 0.001023\n","Train Epoch: 9 [124800/151166 (83%)]\tLoss: 0.000909\n","Train Epoch: 9 [125440/151166 (83%)]\tLoss: 0.001629\n","Train Epoch: 9 [126080/151166 (83%)]\tLoss: 0.000803\n","Train Epoch: 9 [126720/151166 (84%)]\tLoss: 0.000622\n","Train Epoch: 9 [127360/151166 (84%)]\tLoss: 0.000661\n","Train Epoch: 9 [128000/151166 (85%)]\tLoss: 0.000643\n","Train Epoch: 9 [128640/151166 (85%)]\tLoss: 0.000159\n","Train Epoch: 9 [129280/151166 (86%)]\tLoss: 0.000180\n","Train Epoch: 9 [129920/151166 (86%)]\tLoss: 0.000341\n","Train Epoch: 9 [130560/151166 (86%)]\tLoss: 0.000482\n","Train Epoch: 9 [131200/151166 (87%)]\tLoss: 0.000743\n","Train Epoch: 9 [131840/151166 (87%)]\tLoss: 0.001592\n","Train Epoch: 9 [132480/151166 (88%)]\tLoss: 0.002142\n","Train Epoch: 9 [133120/151166 (88%)]\tLoss: 0.000666\n","Train Epoch: 9 [133760/151166 (88%)]\tLoss: 0.000486\n","Train Epoch: 9 [134400/151166 (89%)]\tLoss: 0.000665\n","Train Epoch: 9 [135040/151166 (89%)]\tLoss: 0.000589\n","Train Epoch: 9 [135680/151166 (90%)]\tLoss: 0.000440\n","Train Epoch: 9 [136320/151166 (90%)]\tLoss: 0.000932\n","Train Epoch: 9 [136960/151166 (91%)]\tLoss: 0.000754\n","Train Epoch: 9 [137600/151166 (91%)]\tLoss: 0.000284\n","Train Epoch: 9 [138240/151166 (91%)]\tLoss: 0.003434\n","Train Epoch: 9 [138880/151166 (92%)]\tLoss: 0.000828\n","Train Epoch: 9 [139520/151166 (92%)]\tLoss: 0.000670\n","Train Epoch: 9 [140160/151166 (93%)]\tLoss: 0.002201\n","Train Epoch: 9 [140800/151166 (93%)]\tLoss: 0.000184\n","Train Epoch: 9 [141440/151166 (94%)]\tLoss: 0.000553\n","Train Epoch: 9 [142080/151166 (94%)]\tLoss: 0.001836\n","Train Epoch: 9 [142720/151166 (94%)]\tLoss: 0.000631\n","Train Epoch: 9 [143360/151166 (95%)]\tLoss: 0.000818\n","Train Epoch: 9 [144000/151166 (95%)]\tLoss: 0.000571\n","Train Epoch: 9 [144640/151166 (96%)]\tLoss: 0.000455\n","Train Epoch: 9 [145280/151166 (96%)]\tLoss: 0.001741\n","Train Epoch: 9 [145920/151166 (97%)]\tLoss: 0.000657\n","Train Epoch: 9 [146560/151166 (97%)]\tLoss: 0.000572\n","Train Epoch: 9 [147200/151166 (97%)]\tLoss: 0.001040\n","Train Epoch: 9 [147840/151166 (98%)]\tLoss: 0.000321\n","Train Epoch: 9 [148480/151166 (98%)]\tLoss: 0.000236\n","Train Epoch: 9 [149120/151166 (99%)]\tLoss: 0.000483\n","Train Epoch: 9 [149760/151166 (99%)]\tLoss: 0.000577\n","Train Epoch: 9 [150400/151166 (99%)]\tLoss: 0.001042\n","Train Epoch: 9 [151040/151166 (100%)]\tLoss: 0.000508\n","Sample outputs (log probs): tensor([[-2.7617e+01, -2.7170e+01, -3.2839e+01, -2.2295e+01, -3.7927e+01,\n","         -3.5406e+01, -2.3965e+01, -2.0892e+01, -3.1412e+01, -2.7588e+01,\n","         -3.2731e+01, -2.8983e+01, -2.6183e+01, -1.5250e+01, -3.0065e+01,\n","         -2.8585e+01, -1.7640e+01, -3.1763e+01, -3.0219e+01, -3.4896e+01,\n","         -1.4334e+01, -2.3470e+01, -8.3446e-07, -3.0267e+01, -3.0924e+01,\n","         -3.9916e+01],\n","        [-2.0325e+01, -1.1267e+01, -1.1601e+01, -2.2042e+01, -4.9289e-03,\n","         -7.1732e+00, -5.5491e+00, -2.2127e+01, -1.7759e+01, -1.5180e+01,\n","         -1.5589e+01, -1.9699e+01, -2.8362e+01, -2.7959e+01, -1.9154e+01,\n","         -1.9437e+01, -1.8389e+01, -2.0537e+01, -8.3494e+00, -1.9888e+01,\n","         -2.2772e+01, -2.1175e+01, -2.3560e+01, -2.3354e+01, -1.8391e+01,\n","         -1.6199e+01],\n","        [-2.0749e+01, -1.6039e+01, -7.8574e+00, -5.3308e+00, -2.0651e+01,\n","         -1.9018e+01, -1.4093e+01, -2.5888e+01, -1.5088e+01, -1.4278e+01,\n","         -2.7533e+01, -1.9176e+01, -2.0193e+01, -1.5388e+01, -5.9370e-03,\n","         -1.3271e+01, -7.3267e+00, -2.2776e+01, -1.2682e+01, -1.6438e+01,\n","         -1.0498e+01, -1.9142e+01, -1.5331e+01, -3.0259e+01, -1.6624e+01,\n","         -2.2539e+01],\n","        [-2.3128e+01, -2.2758e+01, -2.5572e+01, -2.2481e+01, -2.4678e+01,\n","         -2.9572e+01, -1.8820e+01, -1.4822e+01, -2.2181e+01, -2.3497e+01,\n","         -1.6842e+01, -2.2715e+01, -1.3079e+01, -1.1152e+01, -2.4697e+01,\n","         -2.2844e+01, -1.9501e+01, -2.2415e+01, -2.6579e+01, -2.3682e+01,\n","         -1.1326e+01, -1.1687e+01, -3.7312e-05, -1.9160e+01, -1.8484e+01,\n","         -3.0069e+01],\n","        [-2.4450e+01, -1.9899e+01, -1.6357e+01, -1.1680e+01, -2.2298e+01,\n","         -1.9561e+01, -1.9168e+01, -1.3590e+01, -1.1823e+01, -1.0857e+01,\n","         -2.0553e+01, -1.4767e+01, -1.2540e+01, -7.3617e+00, -1.3614e+01,\n","         -1.3642e+01, -1.6924e+01, -2.4256e+01, -1.6797e+01, -1.5220e+01,\n","         -3.7532e-01, -1.1644e+00, -9.6694e+00, -1.6615e+01, -9.5533e+00,\n","         -2.1119e+01]], device='cuda:0')\n","Predicted classes: tensor([22,  4, 14, 22, 20], device='cuda:0')\n","Target classes: tensor([22,  4, 14, 22, 20], device='cuda:0')\n","\n","Test set: Average loss: 0.001740, Total sum loss: 0.515169, Accuracy: 36793/37792 (97%)\n","\n","Class A: 1218/1247 (98%)\n","Class B: 804/816 (99%)\n","Class C: 1918/1965 (98%)\n","Class D: 828/868 (95%)\n","Class E: 1013/1024 (99%)\n","Class F: 1816/1869 (97%)\n","Class G: 505/519 (97%)\n","Class H: 604/621 (97%)\n","Class I: 2375/2410 (99%)\n","Class J: 730/754 (97%)\n","Class K: 489/502 (97%)\n","Class L: 966/987 (98%)\n","Class M: 1737/1774 (98%)\n","Class N: 1581/1622 (97%)\n","Class O: 4840/5064 (96%)\n","Class P: 1579/1615 (98%)\n","Class Q: 510/536 (95%)\n","Class R: 960/992 (97%)\n","Class S: 4188/4228 (99%)\n","Class T: 1909/1932 (99%)\n","Class U: 2491/2598 (96%)\n","Class V: 867/904 (96%)\n","Class W: 917/938 (98%)\n","Class X: 544/560 (97%)\n","Class Y: 892/924 (97%)\n","Class Z: 512/523 (98%)\n","Model saved with new best test loss: 0.0017 \n","\n","Train Epoch: 10 [0/151166 (0%)]\tLoss: 0.000215\n","Train Epoch: 10 [640/151166 (0%)]\tLoss: 0.000614\n","Train Epoch: 10 [1280/151166 (1%)]\tLoss: 0.000346\n","Train Epoch: 10 [1920/151166 (1%)]\tLoss: 0.000508\n","Train Epoch: 10 [2560/151166 (2%)]\tLoss: 0.000613\n","Train Epoch: 10 [3200/151166 (2%)]\tLoss: 0.000272\n","Train Epoch: 10 [3840/151166 (3%)]\tLoss: 0.002631\n","Train Epoch: 10 [4480/151166 (3%)]\tLoss: 0.001868\n","Train Epoch: 10 [5120/151166 (3%)]\tLoss: 0.000121\n","Train Epoch: 10 [5760/151166 (4%)]\tLoss: 0.001128\n","Train Epoch: 10 [6400/151166 (4%)]\tLoss: 0.000299\n","Train Epoch: 10 [7040/151166 (5%)]\tLoss: 0.001025\n","Train Epoch: 10 [7680/151166 (5%)]\tLoss: 0.000272\n","Train Epoch: 10 [8320/151166 (6%)]\tLoss: 0.000488\n","Train Epoch: 10 [8960/151166 (6%)]\tLoss: 0.000714\n","Train Epoch: 10 [9600/151166 (6%)]\tLoss: 0.001701\n","Train Epoch: 10 [10240/151166 (7%)]\tLoss: 0.000144\n","Train Epoch: 10 [10880/151166 (7%)]\tLoss: 0.000521\n","Train Epoch: 10 [11520/151166 (8%)]\tLoss: 0.002017\n","Train Epoch: 10 [12160/151166 (8%)]\tLoss: 0.000239\n","Train Epoch: 10 [12800/151166 (8%)]\tLoss: 0.001760\n","Train Epoch: 10 [13440/151166 (9%)]\tLoss: 0.000797\n","Train Epoch: 10 [14080/151166 (9%)]\tLoss: 0.001936\n","Train Epoch: 10 [14720/151166 (10%)]\tLoss: 0.000285\n","Train Epoch: 10 [15360/151166 (10%)]\tLoss: 0.001705\n","Train Epoch: 10 [16000/151166 (11%)]\tLoss: 0.001078\n","Train Epoch: 10 [16640/151166 (11%)]\tLoss: 0.000288\n","Train Epoch: 10 [17280/151166 (11%)]\tLoss: 0.001032\n","Train Epoch: 10 [17920/151166 (12%)]\tLoss: 0.002604\n","Train Epoch: 10 [18560/151166 (12%)]\tLoss: 0.001573\n","Train Epoch: 10 [19200/151166 (13%)]\tLoss: 0.000646\n","Train Epoch: 10 [19840/151166 (13%)]\tLoss: 0.001122\n","Train Epoch: 10 [20480/151166 (14%)]\tLoss: 0.000421\n","Train Epoch: 10 [21120/151166 (14%)]\tLoss: 0.000766\n","Train Epoch: 10 [21760/151166 (14%)]\tLoss: 0.000310\n","Train Epoch: 10 [22400/151166 (15%)]\tLoss: 0.000437\n","Train Epoch: 10 [23040/151166 (15%)]\tLoss: 0.000934\n","Train Epoch: 10 [23680/151166 (16%)]\tLoss: 0.000510\n","Train Epoch: 10 [24320/151166 (16%)]\tLoss: 0.001471\n","Train Epoch: 10 [24960/151166 (17%)]\tLoss: 0.000861\n","Train Epoch: 10 [25600/151166 (17%)]\tLoss: 0.000721\n","Train Epoch: 10 [26240/151166 (17%)]\tLoss: 0.000828\n","Train Epoch: 10 [26880/151166 (18%)]\tLoss: 0.001311\n","Train Epoch: 10 [27520/151166 (18%)]\tLoss: 0.000500\n","Train Epoch: 10 [28160/151166 (19%)]\tLoss: 0.001399\n","Train Epoch: 10 [28800/151166 (19%)]\tLoss: 0.001543\n","Train Epoch: 10 [29440/151166 (19%)]\tLoss: 0.000361\n","Train Epoch: 10 [30080/151166 (20%)]\tLoss: 0.000860\n","Train Epoch: 10 [30720/151166 (20%)]\tLoss: 0.000256\n","Train Epoch: 10 [31360/151166 (21%)]\tLoss: 0.000905\n","Train Epoch: 10 [32000/151166 (21%)]\tLoss: 0.000218\n","Train Epoch: 10 [32640/151166 (22%)]\tLoss: 0.000309\n","Train Epoch: 10 [33280/151166 (22%)]\tLoss: 0.001631\n","Train Epoch: 10 [33920/151166 (22%)]\tLoss: 0.000269\n","Train Epoch: 10 [34560/151166 (23%)]\tLoss: 0.002439\n","Train Epoch: 10 [35200/151166 (23%)]\tLoss: 0.000523\n","Train Epoch: 10 [35840/151166 (24%)]\tLoss: 0.000275\n","Train Epoch: 10 [36480/151166 (24%)]\tLoss: 0.001777\n","Train Epoch: 10 [37120/151166 (25%)]\tLoss: 0.000266\n","Train Epoch: 10 [37760/151166 (25%)]\tLoss: 0.000827\n","Train Epoch: 10 [38400/151166 (25%)]\tLoss: 0.001839\n","Train Epoch: 10 [39040/151166 (26%)]\tLoss: 0.001057\n","Train Epoch: 10 [39680/151166 (26%)]\tLoss: 0.001077\n","Train Epoch: 10 [40320/151166 (27%)]\tLoss: 0.001503\n","Train Epoch: 10 [40960/151166 (27%)]\tLoss: 0.000913\n","Train Epoch: 10 [41600/151166 (28%)]\tLoss: 0.000264\n","Train Epoch: 10 [42240/151166 (28%)]\tLoss: 0.001502\n","Train Epoch: 10 [42880/151166 (28%)]\tLoss: 0.000541\n","Train Epoch: 10 [43520/151166 (29%)]\tLoss: 0.000389\n","Train Epoch: 10 [44160/151166 (29%)]\tLoss: 0.000454\n","Train Epoch: 10 [44800/151166 (30%)]\tLoss: 0.000280\n","Train Epoch: 10 [45440/151166 (30%)]\tLoss: 0.000883\n","Train Epoch: 10 [46080/151166 (30%)]\tLoss: 0.000399\n","Train Epoch: 10 [46720/151166 (31%)]\tLoss: 0.001654\n","Train Epoch: 10 [47360/151166 (31%)]\tLoss: 0.001137\n","Train Epoch: 10 [48000/151166 (32%)]\tLoss: 0.002232\n","Train Epoch: 10 [48640/151166 (32%)]\tLoss: 0.000276\n","Train Epoch: 10 [49280/151166 (33%)]\tLoss: 0.000712\n","Train Epoch: 10 [49920/151166 (33%)]\tLoss: 0.001055\n","Train Epoch: 10 [50560/151166 (33%)]\tLoss: 0.000134\n","Train Epoch: 10 [51200/151166 (34%)]\tLoss: 0.000822\n","Train Epoch: 10 [51840/151166 (34%)]\tLoss: 0.001059\n","Train Epoch: 10 [52480/151166 (35%)]\tLoss: 0.001828\n","Train Epoch: 10 [53120/151166 (35%)]\tLoss: 0.000335\n","Train Epoch: 10 [53760/151166 (36%)]\tLoss: 0.000140\n","Train Epoch: 10 [54400/151166 (36%)]\tLoss: 0.000828\n","Train Epoch: 10 [55040/151166 (36%)]\tLoss: 0.000479\n","Train Epoch: 10 [55680/151166 (37%)]\tLoss: 0.000164\n","Train Epoch: 10 [56320/151166 (37%)]\tLoss: 0.001862\n","Train Epoch: 10 [56960/151166 (38%)]\tLoss: 0.000536\n","Train Epoch: 10 [57600/151166 (38%)]\tLoss: 0.000295\n","Train Epoch: 10 [58240/151166 (39%)]\tLoss: 0.000730\n","Train Epoch: 10 [58880/151166 (39%)]\tLoss: 0.000376\n","Train Epoch: 10 [59520/151166 (39%)]\tLoss: 0.000402\n","Train Epoch: 10 [60160/151166 (40%)]\tLoss: 0.000133\n","Train Epoch: 10 [60800/151166 (40%)]\tLoss: 0.001746\n","Train Epoch: 10 [61440/151166 (41%)]\tLoss: 0.000355\n","Train Epoch: 10 [62080/151166 (41%)]\tLoss: 0.001331\n","Train Epoch: 10 [62720/151166 (41%)]\tLoss: 0.001947\n","Train Epoch: 10 [63360/151166 (42%)]\tLoss: 0.003360\n","Train Epoch: 10 [64000/151166 (42%)]\tLoss: 0.002598\n","Train Epoch: 10 [64640/151166 (43%)]\tLoss: 0.001090\n","Train Epoch: 10 [65280/151166 (43%)]\tLoss: 0.000293\n","Train Epoch: 10 [65920/151166 (44%)]\tLoss: 0.001070\n","Train Epoch: 10 [66560/151166 (44%)]\tLoss: 0.000351\n","Train Epoch: 10 [67200/151166 (44%)]\tLoss: 0.000691\n","Train Epoch: 10 [67840/151166 (45%)]\tLoss: 0.000527\n","Train Epoch: 10 [68480/151166 (45%)]\tLoss: 0.000835\n","Train Epoch: 10 [69120/151166 (46%)]\tLoss: 0.000186\n","Train Epoch: 10 [69760/151166 (46%)]\tLoss: 0.002589\n","Train Epoch: 10 [70400/151166 (47%)]\tLoss: 0.000390\n","Train Epoch: 10 [71040/151166 (47%)]\tLoss: 0.001780\n","Train Epoch: 10 [71680/151166 (47%)]\tLoss: 0.001035\n","Train Epoch: 10 [72320/151166 (48%)]\tLoss: 0.000167\n","Train Epoch: 10 [72960/151166 (48%)]\tLoss: 0.000601\n","Train Epoch: 10 [73600/151166 (49%)]\tLoss: 0.000406\n","Train Epoch: 10 [74240/151166 (49%)]\tLoss: 0.000504\n","Train Epoch: 10 [74880/151166 (50%)]\tLoss: 0.001789\n","Train Epoch: 10 [75520/151166 (50%)]\tLoss: 0.001047\n","Train Epoch: 10 [76160/151166 (50%)]\tLoss: 0.000429\n","Train Epoch: 10 [76800/151166 (51%)]\tLoss: 0.000663\n","Train Epoch: 10 [77440/151166 (51%)]\tLoss: 0.001646\n","Train Epoch: 10 [78080/151166 (52%)]\tLoss: 0.000302\n","Train Epoch: 10 [78720/151166 (52%)]\tLoss: 0.000563\n","Train Epoch: 10 [79360/151166 (52%)]\tLoss: 0.001146\n","Train Epoch: 10 [80000/151166 (53%)]\tLoss: 0.000719\n","Train Epoch: 10 [80640/151166 (53%)]\tLoss: 0.000544\n","Train Epoch: 10 [81280/151166 (54%)]\tLoss: 0.001911\n","Train Epoch: 10 [81920/151166 (54%)]\tLoss: 0.001402\n","Train Epoch: 10 [82560/151166 (55%)]\tLoss: 0.000499\n","Train Epoch: 10 [83200/151166 (55%)]\tLoss: 0.001952\n","Train Epoch: 10 [83840/151166 (55%)]\tLoss: 0.000204\n","Train Epoch: 10 [84480/151166 (56%)]\tLoss: 0.001330\n","Train Epoch: 10 [85120/151166 (56%)]\tLoss: 0.000075\n","Train Epoch: 10 [85760/151166 (57%)]\tLoss: 0.001117\n","Train Epoch: 10 [86400/151166 (57%)]\tLoss: 0.000390\n","Train Epoch: 10 [87040/151166 (58%)]\tLoss: 0.001071\n","Train Epoch: 10 [87680/151166 (58%)]\tLoss: 0.000708\n","Train Epoch: 10 [88320/151166 (58%)]\tLoss: 0.002321\n","Train Epoch: 10 [88960/151166 (59%)]\tLoss: 0.001511\n","Train Epoch: 10 [89600/151166 (59%)]\tLoss: 0.000965\n","Train Epoch: 10 [90240/151166 (60%)]\tLoss: 0.001662\n","Train Epoch: 10 [90880/151166 (60%)]\tLoss: 0.001494\n","Train Epoch: 10 [91520/151166 (61%)]\tLoss: 0.000534\n","Train Epoch: 10 [92160/151166 (61%)]\tLoss: 0.002058\n","Train Epoch: 10 [92800/151166 (61%)]\tLoss: 0.001959\n","Train Epoch: 10 [93440/151166 (62%)]\tLoss: 0.000300\n","Train Epoch: 10 [94080/151166 (62%)]\tLoss: 0.000059\n","Train Epoch: 10 [94720/151166 (63%)]\tLoss: 0.005119\n","Train Epoch: 10 [95360/151166 (63%)]\tLoss: 0.000846\n","Train Epoch: 10 [96000/151166 (64%)]\tLoss: 0.000938\n","Train Epoch: 10 [96640/151166 (64%)]\tLoss: 0.000598\n","Train Epoch: 10 [97280/151166 (64%)]\tLoss: 0.000704\n","Train Epoch: 10 [97920/151166 (65%)]\tLoss: 0.001663\n","Train Epoch: 10 [98560/151166 (65%)]\tLoss: 0.000472\n","Train Epoch: 10 [99200/151166 (66%)]\tLoss: 0.001200\n","Train Epoch: 10 [99840/151166 (66%)]\tLoss: 0.000522\n","Train Epoch: 10 [100480/151166 (66%)]\tLoss: 0.000484\n","Train Epoch: 10 [101120/151166 (67%)]\tLoss: 0.001463\n","Train Epoch: 10 [101760/151166 (67%)]\tLoss: 0.000113\n","Train Epoch: 10 [102400/151166 (68%)]\tLoss: 0.003680\n","Train Epoch: 10 [103040/151166 (68%)]\tLoss: 0.000374\n","Train Epoch: 10 [103680/151166 (69%)]\tLoss: 0.000334\n","Train Epoch: 10 [104320/151166 (69%)]\tLoss: 0.002404\n","Train Epoch: 10 [104960/151166 (69%)]\tLoss: 0.001684\n","Train Epoch: 10 [105600/151166 (70%)]\tLoss: 0.002808\n","Train Epoch: 10 [106240/151166 (70%)]\tLoss: 0.000788\n","Train Epoch: 10 [106880/151166 (71%)]\tLoss: 0.000458\n","Train Epoch: 10 [107520/151166 (71%)]\tLoss: 0.000389\n","Train Epoch: 10 [108160/151166 (72%)]\tLoss: 0.000481\n","Train Epoch: 10 [108800/151166 (72%)]\tLoss: 0.001065\n","Train Epoch: 10 [109440/151166 (72%)]\tLoss: 0.003193\n","Train Epoch: 10 [110080/151166 (73%)]\tLoss: 0.000671\n","Train Epoch: 10 [110720/151166 (73%)]\tLoss: 0.000525\n","Train Epoch: 10 [111360/151166 (74%)]\tLoss: 0.000570\n","Train Epoch: 10 [112000/151166 (74%)]\tLoss: 0.000712\n","Train Epoch: 10 [112640/151166 (75%)]\tLoss: 0.000701\n","Train Epoch: 10 [113280/151166 (75%)]\tLoss: 0.000217\n","Train Epoch: 10 [113920/151166 (75%)]\tLoss: 0.000503\n","Train Epoch: 10 [114560/151166 (76%)]\tLoss: 0.000586\n","Train Epoch: 10 [115200/151166 (76%)]\tLoss: 0.001227\n","Train Epoch: 10 [115840/151166 (77%)]\tLoss: 0.001119\n","Train Epoch: 10 [116480/151166 (77%)]\tLoss: 0.000445\n","Train Epoch: 10 [117120/151166 (77%)]\tLoss: 0.000914\n","Train Epoch: 10 [117760/151166 (78%)]\tLoss: 0.000522\n","Train Epoch: 10 [118400/151166 (78%)]\tLoss: 0.001104\n","Train Epoch: 10 [119040/151166 (79%)]\tLoss: 0.000791\n","Train Epoch: 10 [119680/151166 (79%)]\tLoss: 0.001349\n","Train Epoch: 10 [120320/151166 (80%)]\tLoss: 0.001284\n","Train Epoch: 10 [120960/151166 (80%)]\tLoss: 0.000569\n","Train Epoch: 10 [121600/151166 (80%)]\tLoss: 0.000634\n","Train Epoch: 10 [122240/151166 (81%)]\tLoss: 0.001225\n","Train Epoch: 10 [122880/151166 (81%)]\tLoss: 0.000214\n","Train Epoch: 10 [123520/151166 (82%)]\tLoss: 0.000901\n","Train Epoch: 10 [124160/151166 (82%)]\tLoss: 0.001740\n","Train Epoch: 10 [124800/151166 (83%)]\tLoss: 0.000654\n","Train Epoch: 10 [125440/151166 (83%)]\tLoss: 0.001087\n","Train Epoch: 10 [126080/151166 (83%)]\tLoss: 0.000635\n","Train Epoch: 10 [126720/151166 (84%)]\tLoss: 0.000205\n","Train Epoch: 10 [127360/151166 (84%)]\tLoss: 0.000583\n","Train Epoch: 10 [128000/151166 (85%)]\tLoss: 0.001108\n","Train Epoch: 10 [128640/151166 (85%)]\tLoss: 0.001084\n","Train Epoch: 10 [129280/151166 (86%)]\tLoss: 0.001760\n","Train Epoch: 10 [129920/151166 (86%)]\tLoss: 0.001314\n","Train Epoch: 10 [130560/151166 (86%)]\tLoss: 0.000519\n","Train Epoch: 10 [131200/151166 (87%)]\tLoss: 0.001375\n","Train Epoch: 10 [131840/151166 (87%)]\tLoss: 0.000158\n","Train Epoch: 10 [132480/151166 (88%)]\tLoss: 0.001516\n","Train Epoch: 10 [133120/151166 (88%)]\tLoss: 0.000322\n","Train Epoch: 10 [133760/151166 (88%)]\tLoss: 0.000526\n","Train Epoch: 10 [134400/151166 (89%)]\tLoss: 0.000461\n","Train Epoch: 10 [135040/151166 (89%)]\tLoss: 0.001281\n","Train Epoch: 10 [135680/151166 (90%)]\tLoss: 0.000353\n","Train Epoch: 10 [136320/151166 (90%)]\tLoss: 0.000403\n","Train Epoch: 10 [136960/151166 (91%)]\tLoss: 0.000229\n","Train Epoch: 10 [137600/151166 (91%)]\tLoss: 0.000784\n","Train Epoch: 10 [138240/151166 (91%)]\tLoss: 0.000357\n","Train Epoch: 10 [138880/151166 (92%)]\tLoss: 0.002211\n","Train Epoch: 10 [139520/151166 (92%)]\tLoss: 0.000374\n","Train Epoch: 10 [140160/151166 (93%)]\tLoss: 0.000499\n","Train Epoch: 10 [140800/151166 (93%)]\tLoss: 0.000503\n","Train Epoch: 10 [141440/151166 (94%)]\tLoss: 0.000965\n","Train Epoch: 10 [142080/151166 (94%)]\tLoss: 0.002189\n","Train Epoch: 10 [142720/151166 (94%)]\tLoss: 0.000594\n","Train Epoch: 10 [143360/151166 (95%)]\tLoss: 0.000242\n","Train Epoch: 10 [144000/151166 (95%)]\tLoss: 0.000285\n","Train Epoch: 10 [144640/151166 (96%)]\tLoss: 0.000724\n","Train Epoch: 10 [145280/151166 (96%)]\tLoss: 0.000225\n","Train Epoch: 10 [145920/151166 (97%)]\tLoss: 0.001031\n","Train Epoch: 10 [146560/151166 (97%)]\tLoss: 0.001255\n","Train Epoch: 10 [147200/151166 (97%)]\tLoss: 0.000651\n","Train Epoch: 10 [147840/151166 (98%)]\tLoss: 0.000340\n","Train Epoch: 10 [148480/151166 (98%)]\tLoss: 0.000767\n","Train Epoch: 10 [149120/151166 (99%)]\tLoss: 0.000388\n","Train Epoch: 10 [149760/151166 (99%)]\tLoss: 0.000950\n","Train Epoch: 10 [150400/151166 (99%)]\tLoss: 0.000153\n","Train Epoch: 10 [151040/151166 (100%)]\tLoss: 0.000842\n","Sample outputs (log probs): tensor([[-3.1513e+01, -2.4641e+01, -1.8840e+01, -1.4270e+01, -2.4669e+01,\n","         -1.6184e+01, -2.1536e+01, -3.5536e+01, -1.0603e+01, -2.9206e-05,\n","         -3.5852e+01, -2.6099e+01, -3.3100e+01, -2.8731e+01, -1.8997e+01,\n","         -2.5025e+01, -2.1697e+01, -4.0010e+01, -1.2757e+01, -1.4188e+01,\n","         -2.2576e+01, -2.2953e+01, -2.7528e+01, -2.9065e+01, -1.8286e+01,\n","         -2.4853e+01],\n","        [-9.2190e+00, -5.2176e+00, -1.2539e+01, -5.5618e+00, -1.8230e+01,\n","         -1.9289e+01, -2.8283e+00, -5.5036e+00, -1.5576e+01, -1.2529e+01,\n","         -8.3414e+00, -4.6239e+00, -7.0544e+00, -6.2864e+00, -1.1619e+01,\n","         -1.4377e+01, -6.7980e+00, -1.4191e+01, -1.4330e+01, -1.5993e+01,\n","         -3.4339e+00, -1.1685e+01, -1.2639e-01, -1.3221e+01, -1.2749e+01,\n","         -1.8499e+01],\n","        [-9.3225e+00, -1.2205e+01, -1.0872e+01, -1.2026e+01, -9.8645e+00,\n","         -6.8752e-02, -1.0436e+01, -9.1684e+00, -4.6336e+00, -8.9846e+00,\n","         -7.8088e+00, -7.3646e+00, -1.2761e+01, -1.1674e+01, -1.4612e+01,\n","         -5.9713e+00, -1.0381e+01, -1.0206e+01, -7.9676e+00, -3.0311e+00,\n","         -1.1822e+01, -9.5379e+00, -1.4510e+01, -7.1447e+00, -5.7684e+00,\n","         -1.0758e+01],\n","        [-9.4002e+00, -6.8816e+00, -5.4785e+00, -5.3167e+00, -1.0237e+01,\n","         -1.0847e+01, -7.5492e+00, -1.3331e+01, -1.0018e+01, -8.9007e+00,\n","         -1.5588e+01, -1.3543e+01, -1.1189e+01, -1.0637e+01, -5.3964e-02,\n","         -7.8351e+00, -3.2868e+00, -9.5254e+00, -1.0210e+01, -9.8801e+00,\n","         -5.6827e+00, -8.8166e+00, -1.0120e+01, -1.6900e+01, -1.1698e+01,\n","         -1.2090e+01],\n","        [-1.5140e+01, -1.0461e+01, -9.0680e+00, -1.0177e+01, -1.5490e+01,\n","         -1.9342e+01, -1.5280e+01, -1.9871e+01, -1.5132e+01, -1.3561e+01,\n","         -2.3028e+01, -1.9116e+01, -1.7440e+01, -1.8077e+01, -1.9191e-04,\n","         -1.4681e+01, -1.3442e+01, -1.7673e+01, -1.3721e+01, -1.8990e+01,\n","         -1.2302e+01, -1.8346e+01, -2.2344e+01, -2.6916e+01, -1.7387e+01,\n","         -1.9071e+01]], device='cuda:0')\n","Predicted classes: tensor([ 9, 22,  5, 14, 14], device='cuda:0')\n","Target classes: tensor([ 9, 22,  5, 14, 14], device='cuda:0')\n","\n","Test set: Average loss: 0.001680, Total sum loss: 0.497313, Accuracy: 36844/37792 (97%)\n","\n","Class A: 1225/1247 (98%)\n","Class B: 804/816 (99%)\n","Class C: 1915/1965 (97%)\n","Class D: 818/868 (94%)\n","Class E: 1009/1024 (99%)\n","Class F: 1825/1869 (98%)\n","Class G: 505/519 (97%)\n","Class H: 603/621 (97%)\n","Class I: 2374/2410 (99%)\n","Class J: 728/754 (97%)\n","Class K: 488/502 (97%)\n","Class L: 966/987 (98%)\n","Class M: 1747/1774 (98%)\n","Class N: 1576/1622 (97%)\n","Class O: 4881/5064 (96%)\n","Class P: 1584/1615 (98%)\n","Class Q: 513/536 (96%)\n","Class R: 972/992 (98%)\n","Class S: 4178/4228 (99%)\n","Class T: 1915/1932 (99%)\n","Class U: 2478/2598 (95%)\n","Class V: 867/904 (96%)\n","Class W: 917/938 (98%)\n","Class X: 545/560 (97%)\n","Class Y: 899/924 (97%)\n","Class Z: 512/523 (98%)\n","Model saved with new best test loss: 0.0017 \n","\n","Train Epoch: 11 [0/151166 (0%)]\tLoss: 0.000578\n","Train Epoch: 11 [640/151166 (0%)]\tLoss: 0.000511\n","Train Epoch: 11 [1280/151166 (1%)]\tLoss: 0.000549\n","Train Epoch: 11 [1920/151166 (1%)]\tLoss: 0.000626\n","Train Epoch: 11 [2560/151166 (2%)]\tLoss: 0.000407\n","Train Epoch: 11 [3200/151166 (2%)]\tLoss: 0.000801\n","Train Epoch: 11 [3840/151166 (3%)]\tLoss: 0.000780\n","Train Epoch: 11 [4480/151166 (3%)]\tLoss: 0.000526\n","Train Epoch: 11 [5120/151166 (3%)]\tLoss: 0.000517\n","Train Epoch: 11 [5760/151166 (4%)]\tLoss: 0.000937\n","Train Epoch: 11 [6400/151166 (4%)]\tLoss: 0.000921\n","Train Epoch: 11 [7040/151166 (5%)]\tLoss: 0.000401\n","Train Epoch: 11 [7680/151166 (5%)]\tLoss: 0.002468\n","Train Epoch: 11 [8320/151166 (6%)]\tLoss: 0.000522\n","Train Epoch: 11 [8960/151166 (6%)]\tLoss: 0.000527\n","Train Epoch: 11 [9600/151166 (6%)]\tLoss: 0.000408\n","Train Epoch: 11 [10240/151166 (7%)]\tLoss: 0.000306\n","Train Epoch: 11 [10880/151166 (7%)]\tLoss: 0.001412\n","Train Epoch: 11 [11520/151166 (8%)]\tLoss: 0.001596\n","Train Epoch: 11 [12160/151166 (8%)]\tLoss: 0.001025\n","Train Epoch: 11 [12800/151166 (8%)]\tLoss: 0.002781\n","Train Epoch: 11 [13440/151166 (9%)]\tLoss: 0.001524\n","Train Epoch: 11 [14080/151166 (9%)]\tLoss: 0.001700\n","Train Epoch: 11 [14720/151166 (10%)]\tLoss: 0.000761\n","Train Epoch: 11 [15360/151166 (10%)]\tLoss: 0.002408\n","Train Epoch: 11 [16000/151166 (11%)]\tLoss: 0.001273\n","Train Epoch: 11 [16640/151166 (11%)]\tLoss: 0.000890\n","Train Epoch: 11 [17280/151166 (11%)]\tLoss: 0.001512\n","Train Epoch: 11 [17920/151166 (12%)]\tLoss: 0.000388\n","Train Epoch: 11 [18560/151166 (12%)]\tLoss: 0.001376\n","Train Epoch: 11 [19200/151166 (13%)]\tLoss: 0.001196\n","Train Epoch: 11 [19840/151166 (13%)]\tLoss: 0.000674\n","Train Epoch: 11 [20480/151166 (14%)]\tLoss: 0.000372\n","Train Epoch: 11 [21120/151166 (14%)]\tLoss: 0.000475\n","Train Epoch: 11 [21760/151166 (14%)]\tLoss: 0.000352\n","Train Epoch: 11 [22400/151166 (15%)]\tLoss: 0.000543\n","Train Epoch: 11 [23040/151166 (15%)]\tLoss: 0.000778\n","Train Epoch: 11 [23680/151166 (16%)]\tLoss: 0.001534\n","Train Epoch: 11 [24320/151166 (16%)]\tLoss: 0.001253\n","Train Epoch: 11 [24960/151166 (17%)]\tLoss: 0.000467\n","Train Epoch: 11 [25600/151166 (17%)]\tLoss: 0.000864\n","Train Epoch: 11 [26240/151166 (17%)]\tLoss: 0.000708\n","Train Epoch: 11 [26880/151166 (18%)]\tLoss: 0.001104\n","Train Epoch: 11 [27520/151166 (18%)]\tLoss: 0.000840\n","Train Epoch: 11 [28160/151166 (19%)]\tLoss: 0.000307\n","Train Epoch: 11 [28800/151166 (19%)]\tLoss: 0.001100\n","Train Epoch: 11 [29440/151166 (19%)]\tLoss: 0.000818\n","Train Epoch: 11 [30080/151166 (20%)]\tLoss: 0.000959\n","Train Epoch: 11 [30720/151166 (20%)]\tLoss: 0.001219\n","Train Epoch: 11 [31360/151166 (21%)]\tLoss: 0.001376\n","Train Epoch: 11 [32000/151166 (21%)]\tLoss: 0.000922\n","Train Epoch: 11 [32640/151166 (22%)]\tLoss: 0.000951\n","Train Epoch: 11 [33280/151166 (22%)]\tLoss: 0.000352\n","Train Epoch: 11 [33920/151166 (22%)]\tLoss: 0.000216\n","Train Epoch: 11 [34560/151166 (23%)]\tLoss: 0.000336\n","Train Epoch: 11 [35200/151166 (23%)]\tLoss: 0.002629\n","Train Epoch: 11 [35840/151166 (24%)]\tLoss: 0.000236\n","Train Epoch: 11 [36480/151166 (24%)]\tLoss: 0.000834\n","Train Epoch: 11 [37120/151166 (25%)]\tLoss: 0.001143\n","Train Epoch: 11 [37760/151166 (25%)]\tLoss: 0.000397\n","Train Epoch: 11 [38400/151166 (25%)]\tLoss: 0.000885\n","Train Epoch: 11 [39040/151166 (26%)]\tLoss: 0.000904\n","Train Epoch: 11 [39680/151166 (26%)]\tLoss: 0.002506\n","Train Epoch: 11 [40320/151166 (27%)]\tLoss: 0.000803\n","Train Epoch: 11 [40960/151166 (27%)]\tLoss: 0.001128\n","Train Epoch: 11 [41600/151166 (28%)]\tLoss: 0.000483\n","Train Epoch: 11 [42240/151166 (28%)]\tLoss: 0.001104\n","Train Epoch: 11 [42880/151166 (28%)]\tLoss: 0.000363\n","Train Epoch: 11 [43520/151166 (29%)]\tLoss: 0.000182\n","Train Epoch: 11 [44160/151166 (29%)]\tLoss: 0.001007\n","Train Epoch: 11 [44800/151166 (30%)]\tLoss: 0.000887\n","Train Epoch: 11 [45440/151166 (30%)]\tLoss: 0.000661\n","Train Epoch: 11 [46080/151166 (30%)]\tLoss: 0.000193\n","Train Epoch: 11 [46720/151166 (31%)]\tLoss: 0.001459\n","Train Epoch: 11 [47360/151166 (31%)]\tLoss: 0.000604\n","Train Epoch: 11 [48000/151166 (32%)]\tLoss: 0.000650\n","Train Epoch: 11 [48640/151166 (32%)]\tLoss: 0.000274\n","Train Epoch: 11 [49280/151166 (33%)]\tLoss: 0.001021\n","Train Epoch: 11 [49920/151166 (33%)]\tLoss: 0.000547\n","Train Epoch: 11 [50560/151166 (33%)]\tLoss: 0.001469\n","Train Epoch: 11 [51200/151166 (34%)]\tLoss: 0.000496\n","Train Epoch: 11 [51840/151166 (34%)]\tLoss: 0.000446\n","Train Epoch: 11 [52480/151166 (35%)]\tLoss: 0.001426\n","Train Epoch: 11 [53120/151166 (35%)]\tLoss: 0.000219\n","Train Epoch: 11 [53760/151166 (36%)]\tLoss: 0.000176\n","Train Epoch: 11 [54400/151166 (36%)]\tLoss: 0.000447\n","Train Epoch: 11 [55040/151166 (36%)]\tLoss: 0.001762\n","Train Epoch: 11 [55680/151166 (37%)]\tLoss: 0.000979\n","Train Epoch: 11 [56320/151166 (37%)]\tLoss: 0.000232\n","Train Epoch: 11 [56960/151166 (38%)]\tLoss: 0.002451\n","Train Epoch: 11 [57600/151166 (38%)]\tLoss: 0.001179\n","Train Epoch: 11 [58240/151166 (39%)]\tLoss: 0.000449\n","Train Epoch: 11 [58880/151166 (39%)]\tLoss: 0.000422\n","Train Epoch: 11 [59520/151166 (39%)]\tLoss: 0.002321\n","Train Epoch: 11 [60160/151166 (40%)]\tLoss: 0.000160\n","Train Epoch: 11 [60800/151166 (40%)]\tLoss: 0.000989\n","Train Epoch: 11 [61440/151166 (41%)]\tLoss: 0.002372\n","Train Epoch: 11 [62080/151166 (41%)]\tLoss: 0.000517\n","Train Epoch: 11 [62720/151166 (41%)]\tLoss: 0.003603\n","Train Epoch: 11 [63360/151166 (42%)]\tLoss: 0.000500\n","Train Epoch: 11 [64000/151166 (42%)]\tLoss: 0.000398\n","Train Epoch: 11 [64640/151166 (43%)]\tLoss: 0.000354\n","Train Epoch: 11 [65280/151166 (43%)]\tLoss: 0.000339\n","Train Epoch: 11 [65920/151166 (44%)]\tLoss: 0.000466\n","Train Epoch: 11 [66560/151166 (44%)]\tLoss: 0.000337\n","Train Epoch: 11 [67200/151166 (44%)]\tLoss: 0.001967\n","Train Epoch: 11 [67840/151166 (45%)]\tLoss: 0.000723\n","Train Epoch: 11 [68480/151166 (45%)]\tLoss: 0.001178\n","Train Epoch: 11 [69120/151166 (46%)]\tLoss: 0.000977\n","Train Epoch: 11 [69760/151166 (46%)]\tLoss: 0.000625\n","Train Epoch: 11 [70400/151166 (47%)]\tLoss: 0.000596\n","Train Epoch: 11 [71040/151166 (47%)]\tLoss: 0.000253\n","Train Epoch: 11 [71680/151166 (47%)]\tLoss: 0.000528\n","Train Epoch: 11 [72320/151166 (48%)]\tLoss: 0.000315\n","Train Epoch: 11 [72960/151166 (48%)]\tLoss: 0.000214\n","Train Epoch: 11 [73600/151166 (49%)]\tLoss: 0.001307\n","Train Epoch: 11 [74240/151166 (49%)]\tLoss: 0.000233\n","Train Epoch: 11 [74880/151166 (50%)]\tLoss: 0.001641\n","Train Epoch: 11 [75520/151166 (50%)]\tLoss: 0.001292\n","Train Epoch: 11 [76160/151166 (50%)]\tLoss: 0.000366\n","Train Epoch: 11 [76800/151166 (51%)]\tLoss: 0.000689\n","Train Epoch: 11 [77440/151166 (51%)]\tLoss: 0.000339\n","Train Epoch: 11 [78080/151166 (52%)]\tLoss: 0.000739\n","Train Epoch: 11 [78720/151166 (52%)]\tLoss: 0.001322\n","Train Epoch: 11 [79360/151166 (52%)]\tLoss: 0.000327\n","Train Epoch: 11 [80000/151166 (53%)]\tLoss: 0.000744\n","Train Epoch: 11 [80640/151166 (53%)]\tLoss: 0.002601\n","Train Epoch: 11 [81280/151166 (54%)]\tLoss: 0.000782\n","Train Epoch: 11 [81920/151166 (54%)]\tLoss: 0.000767\n","Train Epoch: 11 [82560/151166 (55%)]\tLoss: 0.000481\n","Train Epoch: 11 [83200/151166 (55%)]\tLoss: 0.001151\n","Train Epoch: 11 [83840/151166 (55%)]\tLoss: 0.000789\n","Train Epoch: 11 [84480/151166 (56%)]\tLoss: 0.000664\n","Train Epoch: 11 [85120/151166 (56%)]\tLoss: 0.000359\n","Train Epoch: 11 [85760/151166 (57%)]\tLoss: 0.001660\n","Train Epoch: 11 [86400/151166 (57%)]\tLoss: 0.002700\n","Train Epoch: 11 [87040/151166 (58%)]\tLoss: 0.000581\n","Train Epoch: 11 [87680/151166 (58%)]\tLoss: 0.000980\n","Train Epoch: 11 [88320/151166 (58%)]\tLoss: 0.000332\n","Train Epoch: 11 [88960/151166 (59%)]\tLoss: 0.000491\n","Train Epoch: 11 [89600/151166 (59%)]\tLoss: 0.001899\n","Train Epoch: 11 [90240/151166 (60%)]\tLoss: 0.001545\n","Train Epoch: 11 [90880/151166 (60%)]\tLoss: 0.000629\n","Train Epoch: 11 [91520/151166 (61%)]\tLoss: 0.001153\n","Train Epoch: 11 [92160/151166 (61%)]\tLoss: 0.000695\n","Train Epoch: 11 [92800/151166 (61%)]\tLoss: 0.000878\n","Train Epoch: 11 [93440/151166 (62%)]\tLoss: 0.001000\n","Train Epoch: 11 [94080/151166 (62%)]\tLoss: 0.000789\n","Train Epoch: 11 [94720/151166 (63%)]\tLoss: 0.000301\n","Train Epoch: 11 [95360/151166 (63%)]\tLoss: 0.000691\n","Train Epoch: 11 [96000/151166 (64%)]\tLoss: 0.000220\n","Train Epoch: 11 [96640/151166 (64%)]\tLoss: 0.000185\n","Train Epoch: 11 [97280/151166 (64%)]\tLoss: 0.001026\n","Train Epoch: 11 [97920/151166 (65%)]\tLoss: 0.000102\n","Train Epoch: 11 [98560/151166 (65%)]\tLoss: 0.000399\n","Train Epoch: 11 [99200/151166 (66%)]\tLoss: 0.000286\n","Train Epoch: 11 [99840/151166 (66%)]\tLoss: 0.001654\n","Train Epoch: 11 [100480/151166 (66%)]\tLoss: 0.000271\n","Train Epoch: 11 [101120/151166 (67%)]\tLoss: 0.000574\n","Train Epoch: 11 [101760/151166 (67%)]\tLoss: 0.000539\n","Train Epoch: 11 [102400/151166 (68%)]\tLoss: 0.000409\n","Train Epoch: 11 [103040/151166 (68%)]\tLoss: 0.000777\n","Train Epoch: 11 [103680/151166 (69%)]\tLoss: 0.000363\n","Train Epoch: 11 [104320/151166 (69%)]\tLoss: 0.000296\n","Train Epoch: 11 [104960/151166 (69%)]\tLoss: 0.000976\n","Train Epoch: 11 [105600/151166 (70%)]\tLoss: 0.001275\n","Train Epoch: 11 [106240/151166 (70%)]\tLoss: 0.001584\n","Train Epoch: 11 [106880/151166 (71%)]\tLoss: 0.000469\n","Train Epoch: 11 [107520/151166 (71%)]\tLoss: 0.000290\n","Train Epoch: 11 [108160/151166 (72%)]\tLoss: 0.000662\n","Train Epoch: 11 [108800/151166 (72%)]\tLoss: 0.000892\n","Train Epoch: 11 [109440/151166 (72%)]\tLoss: 0.000795\n","Train Epoch: 11 [110080/151166 (73%)]\tLoss: 0.000645\n","Train Epoch: 11 [110720/151166 (73%)]\tLoss: 0.000593\n","Train Epoch: 11 [111360/151166 (74%)]\tLoss: 0.001311\n","Train Epoch: 11 [112000/151166 (74%)]\tLoss: 0.002862\n","Train Epoch: 11 [112640/151166 (75%)]\tLoss: 0.000584\n","Train Epoch: 11 [113280/151166 (75%)]\tLoss: 0.000471\n","Train Epoch: 11 [113920/151166 (75%)]\tLoss: 0.000668\n","Train Epoch: 11 [114560/151166 (76%)]\tLoss: 0.001111\n","Train Epoch: 11 [115200/151166 (76%)]\tLoss: 0.000893\n","Train Epoch: 11 [115840/151166 (77%)]\tLoss: 0.000781\n","Train Epoch: 11 [116480/151166 (77%)]\tLoss: 0.000199\n","Train Epoch: 11 [117120/151166 (77%)]\tLoss: 0.002121\n","Train Epoch: 11 [117760/151166 (78%)]\tLoss: 0.000534\n","Train Epoch: 11 [118400/151166 (78%)]\tLoss: 0.000409\n","Train Epoch: 11 [119040/151166 (79%)]\tLoss: 0.000684\n","Train Epoch: 11 [119680/151166 (79%)]\tLoss: 0.001478\n","Train Epoch: 11 [120320/151166 (80%)]\tLoss: 0.001063\n","Train Epoch: 11 [120960/151166 (80%)]\tLoss: 0.000524\n","Train Epoch: 11 [121600/151166 (80%)]\tLoss: 0.000404\n","Train Epoch: 11 [122240/151166 (81%)]\tLoss: 0.000243\n","Train Epoch: 11 [122880/151166 (81%)]\tLoss: 0.000732\n","Train Epoch: 11 [123520/151166 (82%)]\tLoss: 0.000278\n","Train Epoch: 11 [124160/151166 (82%)]\tLoss: 0.001453\n","Train Epoch: 11 [124800/151166 (83%)]\tLoss: 0.000619\n","Train Epoch: 11 [125440/151166 (83%)]\tLoss: 0.001182\n","Train Epoch: 11 [126080/151166 (83%)]\tLoss: 0.001047\n","Train Epoch: 11 [126720/151166 (84%)]\tLoss: 0.000995\n","Train Epoch: 11 [127360/151166 (84%)]\tLoss: 0.000804\n","Train Epoch: 11 [128000/151166 (85%)]\tLoss: 0.000395\n","Train Epoch: 11 [128640/151166 (85%)]\tLoss: 0.001031\n","Train Epoch: 11 [129280/151166 (86%)]\tLoss: 0.000248\n","Train Epoch: 11 [129920/151166 (86%)]\tLoss: 0.001967\n","Train Epoch: 11 [130560/151166 (86%)]\tLoss: 0.002384\n","Train Epoch: 11 [131200/151166 (87%)]\tLoss: 0.000289\n","Train Epoch: 11 [131840/151166 (87%)]\tLoss: 0.000205\n","Train Epoch: 11 [132480/151166 (88%)]\tLoss: 0.002410\n","Train Epoch: 11 [133120/151166 (88%)]\tLoss: 0.000985\n","Train Epoch: 11 [133760/151166 (88%)]\tLoss: 0.000489\n","Train Epoch: 11 [134400/151166 (89%)]\tLoss: 0.002719\n","Train Epoch: 11 [135040/151166 (89%)]\tLoss: 0.000272\n","Train Epoch: 11 [135680/151166 (90%)]\tLoss: 0.000189\n","Train Epoch: 11 [136320/151166 (90%)]\tLoss: 0.000195\n","Train Epoch: 11 [136960/151166 (91%)]\tLoss: 0.000229\n","Train Epoch: 11 [137600/151166 (91%)]\tLoss: 0.002194\n","Train Epoch: 11 [138240/151166 (91%)]\tLoss: 0.001375\n","Train Epoch: 11 [138880/151166 (92%)]\tLoss: 0.000500\n","Train Epoch: 11 [139520/151166 (92%)]\tLoss: 0.003014\n","Train Epoch: 11 [140160/151166 (93%)]\tLoss: 0.001092\n","Train Epoch: 11 [140800/151166 (93%)]\tLoss: 0.000849\n","Train Epoch: 11 [141440/151166 (94%)]\tLoss: 0.000312\n","Train Epoch: 11 [142080/151166 (94%)]\tLoss: 0.001055\n","Train Epoch: 11 [142720/151166 (94%)]\tLoss: 0.000898\n","Train Epoch: 11 [143360/151166 (95%)]\tLoss: 0.001681\n","Train Epoch: 11 [144000/151166 (95%)]\tLoss: 0.000533\n","Train Epoch: 11 [144640/151166 (96%)]\tLoss: 0.005458\n","Train Epoch: 11 [145280/151166 (96%)]\tLoss: 0.000471\n","Train Epoch: 11 [145920/151166 (97%)]\tLoss: 0.002018\n","Train Epoch: 11 [146560/151166 (97%)]\tLoss: 0.000985\n","Train Epoch: 11 [147200/151166 (97%)]\tLoss: 0.000694\n","Train Epoch: 11 [147840/151166 (98%)]\tLoss: 0.000501\n","Train Epoch: 11 [148480/151166 (98%)]\tLoss: 0.000754\n","Train Epoch: 11 [149120/151166 (99%)]\tLoss: 0.000999\n","Train Epoch: 11 [149760/151166 (99%)]\tLoss: 0.000617\n","Train Epoch: 11 [150400/151166 (99%)]\tLoss: 0.001871\n","Train Epoch: 11 [151040/151166 (100%)]\tLoss: 0.000529\n","Sample outputs (log probs): tensor([[-1.6730e+01, -1.6672e+01, -2.0610e+01, -2.2733e+01, -1.8379e+01,\n","         -2.0577e+01, -1.9000e+01, -1.2261e+01, -1.9396e+01, -2.2937e+01,\n","         -9.8514e-04, -1.3936e+01, -1.1977e+01, -8.6505e+00, -2.6374e+01,\n","         -1.6474e+01, -2.1199e+01, -9.4378e+00, -2.0670e+01, -1.8155e+01,\n","         -1.5360e+01, -1.4980e+01, -1.1535e+01, -7.2584e+00, -1.2601e+01,\n","         -2.2840e+01],\n","        [-6.8781e-05, -1.8283e+01, -2.5674e+01, -1.7469e+01, -2.6804e+01,\n","         -1.5998e+01, -2.1096e+01, -9.7501e+00, -2.1086e+01, -2.4001e+01,\n","         -1.9119e+01, -2.3495e+01, -1.5009e+01, -1.3249e+01, -2.3022e+01,\n","         -1.2402e+01, -2.0204e+01, -1.2415e+01, -2.3838e+01, -1.9182e+01,\n","         -2.4836e+01, -2.5538e+01, -2.1508e+01, -1.9550e+01, -2.2134e+01,\n","         -2.2797e+01],\n","        [-3.1764e+01, -2.1151e+01, -1.9201e+01, -1.9854e+01, -1.6724e+01,\n","         -1.1882e+01, -1.6383e+01, -3.7036e+01, -1.7738e+01, -1.0695e+01,\n","         -3.0152e+01, -2.5941e+01, -3.6534e+01, -3.1678e+01, -1.9889e+01,\n","         -2.6164e+01, -2.1991e+01, -4.1595e+01, -2.9802e-05, -2.2690e+01,\n","         -3.2163e+01, -2.9847e+01, -3.1118e+01, -3.2520e+01, -1.9508e+01,\n","         -3.0977e+01],\n","        [-2.4711e+01, -1.8821e+01, -1.1185e+01, -8.5795e+00, -2.4101e+01,\n","         -2.3946e+01, -1.6596e+01, -1.8903e+01, -1.6363e+01, -1.4337e+01,\n","         -2.4511e+01, -1.3147e+01, -1.5843e+01, -9.3762e+00, -1.0731e+01,\n","         -1.5255e+01, -1.1095e+01, -2.3301e+01, -2.0885e+01, -1.7830e+01,\n","         -3.3897e-03, -6.0431e+00, -7.2891e+00, -2.2557e+01, -1.5414e+01,\n","         -2.2716e+01],\n","        [-2.8796e+01, -2.5895e+01, -2.3220e+01, -1.7686e+01, -2.7319e+01,\n","         -2.2933e+01, -2.2589e+01, -1.6297e+01, -1.2985e+01, -1.7083e+01,\n","         -2.0076e+01, -1.7129e+01, -1.5279e+01, -8.9643e+00, -2.0614e+01,\n","         -1.4903e+01, -2.0236e+01, -2.7749e+01, -2.0114e+01, -1.7085e+01,\n","         -9.1465e+00, -9.7621e-04, -7.4368e+00, -1.4471e+01, -8.8153e+00,\n","         -2.6248e+01]], device='cuda:0')\n","Predicted classes: tensor([10,  0, 18, 20, 21], device='cuda:0')\n","Target classes: tensor([10,  0, 18, 20, 21], device='cuda:0')\n","\n","Test set: Average loss: 0.001670, Total sum loss: 0.494336, Accuracy: 36846/37792 (97%)\n","\n","Class A: 1220/1247 (98%)\n","Class B: 799/816 (98%)\n","Class C: 1917/1965 (98%)\n","Class D: 827/868 (95%)\n","Class E: 1006/1024 (98%)\n","Class F: 1812/1869 (97%)\n","Class G: 501/519 (97%)\n","Class H: 600/621 (97%)\n","Class I: 2383/2410 (99%)\n","Class J: 723/754 (96%)\n","Class K: 489/502 (97%)\n","Class L: 966/987 (98%)\n","Class M: 1750/1774 (99%)\n","Class N: 1589/1622 (98%)\n","Class O: 4861/5064 (96%)\n","Class P: 1587/1615 (98%)\n","Class Q: 521/536 (97%)\n","Class R: 973/992 (98%)\n","Class S: 4178/4228 (99%)\n","Class T: 1915/1932 (99%)\n","Class U: 2512/2598 (97%)\n","Class V: 858/904 (95%)\n","Class W: 913/938 (97%)\n","Class X: 541/560 (97%)\n","Class Y: 888/924 (96%)\n","Class Z: 517/523 (99%)\n","Model saved with new best test loss: 0.0017 \n","\n","Train Epoch: 12 [0/151166 (0%)]\tLoss: 0.000212\n","Train Epoch: 12 [640/151166 (0%)]\tLoss: 0.000356\n","Train Epoch: 12 [1280/151166 (1%)]\tLoss: 0.000220\n","Train Epoch: 12 [1920/151166 (1%)]\tLoss: 0.000402\n","Train Epoch: 12 [2560/151166 (2%)]\tLoss: 0.000213\n","Train Epoch: 12 [3200/151166 (2%)]\tLoss: 0.000364\n","Train Epoch: 12 [3840/151166 (3%)]\tLoss: 0.002412\n","Train Epoch: 12 [4480/151166 (3%)]\tLoss: 0.000279\n","Train Epoch: 12 [5120/151166 (3%)]\tLoss: 0.000363\n","Train Epoch: 12 [5760/151166 (4%)]\tLoss: 0.001600\n","Train Epoch: 12 [6400/151166 (4%)]\tLoss: 0.000199\n","Train Epoch: 12 [7040/151166 (5%)]\tLoss: 0.002092\n","Train Epoch: 12 [7680/151166 (5%)]\tLoss: 0.000409\n","Train Epoch: 12 [8320/151166 (6%)]\tLoss: 0.000711\n","Train Epoch: 12 [8960/151166 (6%)]\tLoss: 0.000559\n","Train Epoch: 12 [9600/151166 (6%)]\tLoss: 0.001529\n","Train Epoch: 12 [10240/151166 (7%)]\tLoss: 0.001385\n","Train Epoch: 12 [10880/151166 (7%)]\tLoss: 0.000131\n","Train Epoch: 12 [11520/151166 (8%)]\tLoss: 0.001549\n","Train Epoch: 12 [12160/151166 (8%)]\tLoss: 0.000760\n","Train Epoch: 12 [12800/151166 (8%)]\tLoss: 0.000878\n","Train Epoch: 12 [13440/151166 (9%)]\tLoss: 0.000380\n","Train Epoch: 12 [14080/151166 (9%)]\tLoss: 0.000517\n","Train Epoch: 12 [14720/151166 (10%)]\tLoss: 0.000271\n","Train Epoch: 12 [15360/151166 (10%)]\tLoss: 0.000314\n","Train Epoch: 12 [16000/151166 (11%)]\tLoss: 0.000932\n","Train Epoch: 12 [16640/151166 (11%)]\tLoss: 0.000359\n","Train Epoch: 12 [17280/151166 (11%)]\tLoss: 0.000443\n","Train Epoch: 12 [17920/151166 (12%)]\tLoss: 0.000307\n","Train Epoch: 12 [18560/151166 (12%)]\tLoss: 0.000271\n","Train Epoch: 12 [19200/151166 (13%)]\tLoss: 0.000355\n","Train Epoch: 12 [19840/151166 (13%)]\tLoss: 0.000735\n","Train Epoch: 12 [20480/151166 (14%)]\tLoss: 0.000112\n","Train Epoch: 12 [21120/151166 (14%)]\tLoss: 0.001502\n","Train Epoch: 12 [21760/151166 (14%)]\tLoss: 0.000218\n","Train Epoch: 12 [22400/151166 (15%)]\tLoss: 0.000791\n","Train Epoch: 12 [23040/151166 (15%)]\tLoss: 0.000542\n","Train Epoch: 12 [23680/151166 (16%)]\tLoss: 0.006454\n","Train Epoch: 12 [24320/151166 (16%)]\tLoss: 0.001497\n","Train Epoch: 12 [24960/151166 (17%)]\tLoss: 0.001551\n","Train Epoch: 12 [25600/151166 (17%)]\tLoss: 0.000208\n","Train Epoch: 12 [26240/151166 (17%)]\tLoss: 0.000413\n","Train Epoch: 12 [26880/151166 (18%)]\tLoss: 0.001620\n","Train Epoch: 12 [27520/151166 (18%)]\tLoss: 0.000433\n","Train Epoch: 12 [28160/151166 (19%)]\tLoss: 0.000161\n","Train Epoch: 12 [28800/151166 (19%)]\tLoss: 0.000526\n","Train Epoch: 12 [29440/151166 (19%)]\tLoss: 0.000692\n","Train Epoch: 12 [30080/151166 (20%)]\tLoss: 0.000548\n","Train Epoch: 12 [30720/151166 (20%)]\tLoss: 0.000313\n","Train Epoch: 12 [31360/151166 (21%)]\tLoss: 0.000698\n","Train Epoch: 12 [32000/151166 (21%)]\tLoss: 0.000497\n","Train Epoch: 12 [32640/151166 (22%)]\tLoss: 0.000654\n","Train Epoch: 12 [33280/151166 (22%)]\tLoss: 0.000262\n","Train Epoch: 12 [33920/151166 (22%)]\tLoss: 0.000141\n","Train Epoch: 12 [34560/151166 (23%)]\tLoss: 0.001078\n","Train Epoch: 12 [35200/151166 (23%)]\tLoss: 0.000293\n","Train Epoch: 12 [35840/151166 (24%)]\tLoss: 0.001857\n","Train Epoch: 12 [36480/151166 (24%)]\tLoss: 0.000359\n","Train Epoch: 12 [37120/151166 (25%)]\tLoss: 0.000680\n","Train Epoch: 12 [37760/151166 (25%)]\tLoss: 0.002465\n","Train Epoch: 12 [38400/151166 (25%)]\tLoss: 0.001140\n","Train Epoch: 12 [39040/151166 (26%)]\tLoss: 0.000254\n","Train Epoch: 12 [39680/151166 (26%)]\tLoss: 0.000188\n","Train Epoch: 12 [40320/151166 (27%)]\tLoss: 0.000208\n","Train Epoch: 12 [40960/151166 (27%)]\tLoss: 0.001163\n","Train Epoch: 12 [41600/151166 (28%)]\tLoss: 0.001448\n","Train Epoch: 12 [42240/151166 (28%)]\tLoss: 0.000457\n","Train Epoch: 12 [42880/151166 (28%)]\tLoss: 0.000894\n","Train Epoch: 12 [43520/151166 (29%)]\tLoss: 0.000184\n","Train Epoch: 12 [44160/151166 (29%)]\tLoss: 0.000146\n","Train Epoch: 12 [44800/151166 (30%)]\tLoss: 0.000362\n","Train Epoch: 12 [45440/151166 (30%)]\tLoss: 0.000195\n","Train Epoch: 12 [46080/151166 (30%)]\tLoss: 0.000292\n","Train Epoch: 12 [46720/151166 (31%)]\tLoss: 0.000237\n","Train Epoch: 12 [47360/151166 (31%)]\tLoss: 0.000165\n","Train Epoch: 12 [48000/151166 (32%)]\tLoss: 0.000880\n","Train Epoch: 12 [48640/151166 (32%)]\tLoss: 0.000718\n","Train Epoch: 12 [49280/151166 (33%)]\tLoss: 0.000146\n","Train Epoch: 12 [49920/151166 (33%)]\tLoss: 0.000248\n","Train Epoch: 12 [50560/151166 (33%)]\tLoss: 0.000976\n","Train Epoch: 12 [51200/151166 (34%)]\tLoss: 0.000523\n","Train Epoch: 12 [51840/151166 (34%)]\tLoss: 0.000579\n","Train Epoch: 12 [52480/151166 (35%)]\tLoss: 0.001069\n","Train Epoch: 12 [53120/151166 (35%)]\tLoss: 0.001378\n","Train Epoch: 12 [53760/151166 (36%)]\tLoss: 0.000364\n","Train Epoch: 12 [54400/151166 (36%)]\tLoss: 0.000442\n","Train Epoch: 12 [55040/151166 (36%)]\tLoss: 0.001001\n","Train Epoch: 12 [55680/151166 (37%)]\tLoss: 0.000585\n","Train Epoch: 12 [56320/151166 (37%)]\tLoss: 0.000249\n","Train Epoch: 12 [56960/151166 (38%)]\tLoss: 0.001004\n","Train Epoch: 12 [57600/151166 (38%)]\tLoss: 0.000180\n","Train Epoch: 12 [58240/151166 (39%)]\tLoss: 0.001129\n","Train Epoch: 12 [58880/151166 (39%)]\tLoss: 0.000671\n","Train Epoch: 12 [59520/151166 (39%)]\tLoss: 0.000356\n","Train Epoch: 12 [60160/151166 (40%)]\tLoss: 0.000560\n","Train Epoch: 12 [60800/151166 (40%)]\tLoss: 0.000580\n","Train Epoch: 12 [61440/151166 (41%)]\tLoss: 0.000261\n","Train Epoch: 12 [62080/151166 (41%)]\tLoss: 0.000776\n","Train Epoch: 12 [62720/151166 (41%)]\tLoss: 0.000897\n","Train Epoch: 12 [63360/151166 (42%)]\tLoss: 0.000736\n","Train Epoch: 12 [64000/151166 (42%)]\tLoss: 0.000207\n","Train Epoch: 12 [64640/151166 (43%)]\tLoss: 0.000631\n","Train Epoch: 12 [65280/151166 (43%)]\tLoss: 0.000365\n","Train Epoch: 12 [65920/151166 (44%)]\tLoss: 0.000833\n","Train Epoch: 12 [66560/151166 (44%)]\tLoss: 0.001078\n","Train Epoch: 12 [67200/151166 (44%)]\tLoss: 0.000577\n","Train Epoch: 12 [67840/151166 (45%)]\tLoss: 0.000766\n","Train Epoch: 12 [68480/151166 (45%)]\tLoss: 0.001789\n","Train Epoch: 12 [69120/151166 (46%)]\tLoss: 0.000350\n","Train Epoch: 12 [69760/151166 (46%)]\tLoss: 0.000636\n","Train Epoch: 12 [70400/151166 (47%)]\tLoss: 0.000137\n","Train Epoch: 12 [71040/151166 (47%)]\tLoss: 0.000383\n","Train Epoch: 12 [71680/151166 (47%)]\tLoss: 0.000475\n","Train Epoch: 12 [72320/151166 (48%)]\tLoss: 0.000482\n","Train Epoch: 12 [72960/151166 (48%)]\tLoss: 0.000780\n","Train Epoch: 12 [73600/151166 (49%)]\tLoss: 0.000239\n","Train Epoch: 12 [74240/151166 (49%)]\tLoss: 0.000249\n","Train Epoch: 12 [74880/151166 (50%)]\tLoss: 0.003360\n","Train Epoch: 12 [75520/151166 (50%)]\tLoss: 0.000356\n","Train Epoch: 12 [76160/151166 (50%)]\tLoss: 0.000505\n","Train Epoch: 12 [76800/151166 (51%)]\tLoss: 0.000517\n","Train Epoch: 12 [77440/151166 (51%)]\tLoss: 0.000235\n","Train Epoch: 12 [78080/151166 (52%)]\tLoss: 0.000484\n","Train Epoch: 12 [78720/151166 (52%)]\tLoss: 0.000327\n","Train Epoch: 12 [79360/151166 (52%)]\tLoss: 0.002343\n","Train Epoch: 12 [80000/151166 (53%)]\tLoss: 0.000989\n","Train Epoch: 12 [80640/151166 (53%)]\tLoss: 0.000279\n","Train Epoch: 12 [81280/151166 (54%)]\tLoss: 0.001028\n","Train Epoch: 12 [81920/151166 (54%)]\tLoss: 0.000872\n","Train Epoch: 12 [82560/151166 (55%)]\tLoss: 0.000634\n","Train Epoch: 12 [83200/151166 (55%)]\tLoss: 0.000205\n","Train Epoch: 12 [83840/151166 (55%)]\tLoss: 0.001477\n","Train Epoch: 12 [84480/151166 (56%)]\tLoss: 0.000296\n","Train Epoch: 12 [85120/151166 (56%)]\tLoss: 0.000957\n","Train Epoch: 12 [85760/151166 (57%)]\tLoss: 0.000505\n","Train Epoch: 12 [86400/151166 (57%)]\tLoss: 0.000126\n","Train Epoch: 12 [87040/151166 (58%)]\tLoss: 0.000438\n","Train Epoch: 12 [87680/151166 (58%)]\tLoss: 0.000590\n","Train Epoch: 12 [88320/151166 (58%)]\tLoss: 0.000921\n","Train Epoch: 12 [88960/151166 (59%)]\tLoss: 0.000703\n","Train Epoch: 12 [89600/151166 (59%)]\tLoss: 0.001079\n","Train Epoch: 12 [90240/151166 (60%)]\tLoss: 0.000220\n","Train Epoch: 12 [90880/151166 (60%)]\tLoss: 0.000824\n","Train Epoch: 12 [91520/151166 (61%)]\tLoss: 0.001129\n","Train Epoch: 12 [92160/151166 (61%)]\tLoss: 0.001488\n","Train Epoch: 12 [92800/151166 (61%)]\tLoss: 0.000488\n","Train Epoch: 12 [93440/151166 (62%)]\tLoss: 0.000638\n","Train Epoch: 12 [94080/151166 (62%)]\tLoss: 0.000575\n","Train Epoch: 12 [94720/151166 (63%)]\tLoss: 0.000324\n","Train Epoch: 12 [95360/151166 (63%)]\tLoss: 0.000333\n","Train Epoch: 12 [96000/151166 (64%)]\tLoss: 0.000611\n","Train Epoch: 12 [96640/151166 (64%)]\tLoss: 0.000215\n","Train Epoch: 12 [97280/151166 (64%)]\tLoss: 0.001166\n","Train Epoch: 12 [97920/151166 (65%)]\tLoss: 0.000805\n","Train Epoch: 12 [98560/151166 (65%)]\tLoss: 0.000504\n","Train Epoch: 12 [99200/151166 (66%)]\tLoss: 0.001354\n","Train Epoch: 12 [99840/151166 (66%)]\tLoss: 0.000055\n","Train Epoch: 12 [100480/151166 (66%)]\tLoss: 0.000674\n","Train Epoch: 12 [101120/151166 (67%)]\tLoss: 0.002372\n","Train Epoch: 12 [101760/151166 (67%)]\tLoss: 0.000582\n","Train Epoch: 12 [102400/151166 (68%)]\tLoss: 0.000969\n","Train Epoch: 12 [103040/151166 (68%)]\tLoss: 0.000343\n","Train Epoch: 12 [103680/151166 (69%)]\tLoss: 0.000187\n","Train Epoch: 12 [104320/151166 (69%)]\tLoss: 0.000211\n","Train Epoch: 12 [104960/151166 (69%)]\tLoss: 0.001319\n","Train Epoch: 12 [105600/151166 (70%)]\tLoss: 0.000498\n","Train Epoch: 12 [106240/151166 (70%)]\tLoss: 0.000978\n","Train Epoch: 12 [106880/151166 (71%)]\tLoss: 0.000368\n","Train Epoch: 12 [107520/151166 (71%)]\tLoss: 0.000651\n","Train Epoch: 12 [108160/151166 (72%)]\tLoss: 0.001546\n","Train Epoch: 12 [108800/151166 (72%)]\tLoss: 0.000760\n","Train Epoch: 12 [109440/151166 (72%)]\tLoss: 0.000312\n","Train Epoch: 12 [110080/151166 (73%)]\tLoss: 0.000466\n","Train Epoch: 12 [110720/151166 (73%)]\tLoss: 0.000488\n","Train Epoch: 12 [111360/151166 (74%)]\tLoss: 0.002136\n","Train Epoch: 12 [112000/151166 (74%)]\tLoss: 0.000317\n","Train Epoch: 12 [112640/151166 (75%)]\tLoss: 0.001244\n","Train Epoch: 12 [113280/151166 (75%)]\tLoss: 0.000991\n","Train Epoch: 12 [113920/151166 (75%)]\tLoss: 0.000493\n","Train Epoch: 12 [114560/151166 (76%)]\tLoss: 0.001357\n","Train Epoch: 12 [115200/151166 (76%)]\tLoss: 0.000691\n","Train Epoch: 12 [115840/151166 (77%)]\tLoss: 0.000547\n","Train Epoch: 12 [116480/151166 (77%)]\tLoss: 0.000735\n","Train Epoch: 12 [117120/151166 (77%)]\tLoss: 0.000238\n","Train Epoch: 12 [117760/151166 (78%)]\tLoss: 0.000584\n","Train Epoch: 12 [118400/151166 (78%)]\tLoss: 0.000648\n","Train Epoch: 12 [119040/151166 (79%)]\tLoss: 0.000225\n","Train Epoch: 12 [119680/151166 (79%)]\tLoss: 0.000410\n","Train Epoch: 12 [120320/151166 (80%)]\tLoss: 0.001916\n","Train Epoch: 12 [120960/151166 (80%)]\tLoss: 0.001131\n","Train Epoch: 12 [121600/151166 (80%)]\tLoss: 0.000402\n","Train Epoch: 12 [122240/151166 (81%)]\tLoss: 0.001155\n","Train Epoch: 12 [122880/151166 (81%)]\tLoss: 0.000678\n","Train Epoch: 12 [123520/151166 (82%)]\tLoss: 0.000680\n","Train Epoch: 12 [124160/151166 (82%)]\tLoss: 0.000680\n","Train Epoch: 12 [124800/151166 (83%)]\tLoss: 0.001830\n","Train Epoch: 12 [125440/151166 (83%)]\tLoss: 0.001988\n","Train Epoch: 12 [126080/151166 (83%)]\tLoss: 0.000630\n","Train Epoch: 12 [126720/151166 (84%)]\tLoss: 0.000371\n","Train Epoch: 12 [127360/151166 (84%)]\tLoss: 0.000746\n","Train Epoch: 12 [128000/151166 (85%)]\tLoss: 0.000901\n","Train Epoch: 12 [128640/151166 (85%)]\tLoss: 0.000418\n","Train Epoch: 12 [129280/151166 (86%)]\tLoss: 0.000315\n","Train Epoch: 12 [129920/151166 (86%)]\tLoss: 0.001409\n","Train Epoch: 12 [130560/151166 (86%)]\tLoss: 0.001102\n","Train Epoch: 12 [131200/151166 (87%)]\tLoss: 0.001707\n","Train Epoch: 12 [131840/151166 (87%)]\tLoss: 0.001324\n","Train Epoch: 12 [132480/151166 (88%)]\tLoss: 0.000252\n","Train Epoch: 12 [133120/151166 (88%)]\tLoss: 0.000700\n","Train Epoch: 12 [133760/151166 (88%)]\tLoss: 0.001827\n","Train Epoch: 12 [134400/151166 (89%)]\tLoss: 0.001415\n","Train Epoch: 12 [135040/151166 (89%)]\tLoss: 0.001574\n","Train Epoch: 12 [135680/151166 (90%)]\tLoss: 0.001131\n","Train Epoch: 12 [136320/151166 (90%)]\tLoss: 0.000694\n","Train Epoch: 12 [136960/151166 (91%)]\tLoss: 0.000870\n","Train Epoch: 12 [137600/151166 (91%)]\tLoss: 0.000187\n","Train Epoch: 12 [138240/151166 (91%)]\tLoss: 0.001475\n","Train Epoch: 12 [138880/151166 (92%)]\tLoss: 0.000240\n","Train Epoch: 12 [139520/151166 (92%)]\tLoss: 0.000839\n","Train Epoch: 12 [140160/151166 (93%)]\tLoss: 0.001162\n","Train Epoch: 12 [140800/151166 (93%)]\tLoss: 0.002855\n","Train Epoch: 12 [141440/151166 (94%)]\tLoss: 0.000408\n","Train Epoch: 12 [142080/151166 (94%)]\tLoss: 0.000399\n","Train Epoch: 12 [142720/151166 (94%)]\tLoss: 0.000996\n","Train Epoch: 12 [143360/151166 (95%)]\tLoss: 0.001816\n","Train Epoch: 12 [144000/151166 (95%)]\tLoss: 0.000689\n","Train Epoch: 12 [144640/151166 (96%)]\tLoss: 0.001086\n","Train Epoch: 12 [145280/151166 (96%)]\tLoss: 0.001839\n","Train Epoch: 12 [145920/151166 (97%)]\tLoss: 0.001923\n","Train Epoch: 12 [146560/151166 (97%)]\tLoss: 0.000306\n","Train Epoch: 12 [147200/151166 (97%)]\tLoss: 0.000676\n","Train Epoch: 12 [147840/151166 (98%)]\tLoss: 0.000504\n","Train Epoch: 12 [148480/151166 (98%)]\tLoss: 0.000670\n","Train Epoch: 12 [149120/151166 (99%)]\tLoss: 0.000572\n","Train Epoch: 12 [149760/151166 (99%)]\tLoss: 0.000748\n","Train Epoch: 12 [150400/151166 (99%)]\tLoss: 0.000736\n","Train Epoch: 12 [151040/151166 (100%)]\tLoss: 0.000199\n","Sample outputs (log probs): tensor([[-2.0326e-03, -1.1961e+01, -2.3990e+01, -1.7229e+01, -2.5757e+01,\n","         -1.8375e+01, -2.0088e+01, -1.4694e+01, -2.6786e+01, -2.8595e+01,\n","         -2.2700e+01, -3.1063e+01, -1.7075e+01, -1.9107e+01, -2.0205e+01,\n","         -9.8728e+00, -1.4942e+01, -6.2288e+00, -2.5833e+01, -2.1179e+01,\n","         -2.7874e+01, -2.7147e+01, -2.5255e+01, -2.7342e+01, -2.4806e+01,\n","         -2.2076e+01],\n","        [-1.3025e+01, -1.7681e+01, -1.3506e+01, -1.0011e+01, -1.8172e+01,\n","         -1.0620e+01, -1.6526e+01, -1.3277e+01, -3.0349e-03, -7.9619e+00,\n","         -1.2438e+01, -6.7645e+00, -1.5581e+01, -9.0933e+00, -1.4584e+01,\n","         -9.0885e+00, -1.2918e+01, -1.6609e+01, -1.2498e+01, -8.2046e+00,\n","         -1.0102e+01, -7.6225e+00, -1.2785e+01, -8.3155e+00, -8.7099e+00,\n","         -1.4213e+01],\n","        [-2.2315e+01, -1.5969e+01, -7.6422e+00, -7.7916e+00, -2.3682e+01,\n","         -2.2657e+01, -1.6670e+01, -2.6102e+01, -1.9264e+01, -1.6329e+01,\n","         -2.8361e+01, -2.2916e+01, -1.6465e+01, -1.3079e+01, -1.2329e-03,\n","         -1.2536e+01, -8.2518e+00, -2.2303e+01, -1.8581e+01, -1.6394e+01,\n","         -9.5388e+00, -1.7237e+01, -1.8592e+01, -3.0871e+01, -1.5941e+01,\n","         -2.4424e+01],\n","        [-2.8972e+01, -1.4680e+01, -2.0170e+01, -1.8121e+01, -1.4759e+01,\n","         -1.6572e+01, -1.7764e+01, -3.2871e+01, -1.6875e+01, -1.0868e+01,\n","         -2.9440e+01, -2.5589e+01, -3.0984e+01, -3.3266e+01, -1.6471e+01,\n","         -2.7333e+01, -2.3656e+01, -3.6531e+01, -2.0146e-05, -2.1991e+01,\n","         -2.9729e+01, -2.9889e+01, -3.0477e+01, -2.8968e+01, -1.7470e+01,\n","         -2.1541e+01],\n","        [-2.7046e+01, -1.3791e+01, -2.0605e+01, -1.7765e+01, -1.8459e+01,\n","         -1.2881e+01, -1.5905e+01, -3.0625e+01, -1.7398e+01, -1.0392e+01,\n","         -2.9961e+01, -2.3540e+01, -3.3902e+01, -3.0404e+01, -1.9150e+01,\n","         -2.2784e+01, -1.9494e+01, -3.4282e+01, -3.4451e-05, -2.2145e+01,\n","         -3.0527e+01, -2.8110e+01, -2.8031e+01, -2.9225e+01, -1.7977e+01,\n","         -2.4194e+01]], device='cuda:0')\n","Predicted classes: tensor([ 0,  8, 14, 18, 18], device='cuda:0')\n","Target classes: tensor([ 0,  8, 14, 18, 18], device='cuda:0')\n","\n","Test set: Average loss: 0.001620, Total sum loss: 0.479650, Accuracy: 36909/37792 (98%)\n","\n","Class A: 1223/1247 (98%)\n","Class B: 803/816 (98%)\n","Class C: 1920/1965 (98%)\n","Class D: 815/868 (94%)\n","Class E: 1005/1024 (98%)\n","Class F: 1819/1869 (97%)\n","Class G: 506/519 (97%)\n","Class H: 599/621 (96%)\n","Class I: 2371/2410 (98%)\n","Class J: 731/754 (97%)\n","Class K: 488/502 (97%)\n","Class L: 961/987 (97%)\n","Class M: 1750/1774 (99%)\n","Class N: 1596/1622 (98%)\n","Class O: 4909/5064 (97%)\n","Class P: 1585/1615 (98%)\n","Class Q: 520/536 (97%)\n","Class R: 974/992 (98%)\n","Class S: 4184/4228 (99%)\n","Class T: 1916/1932 (99%)\n","Class U: 2489/2598 (96%)\n","Class V: 866/904 (96%)\n","Class W: 920/938 (98%)\n","Class X: 546/560 (98%)\n","Class Y: 899/924 (97%)\n","Class Z: 514/523 (98%)\n","Model saved with new best test loss: 0.0016 \n","\n","Train Epoch: 13 [0/151166 (0%)]\tLoss: 0.000471\n","Train Epoch: 13 [640/151166 (0%)]\tLoss: 0.000799\n","Train Epoch: 13 [1280/151166 (1%)]\tLoss: 0.000689\n","Train Epoch: 13 [1920/151166 (1%)]\tLoss: 0.001134\n","Train Epoch: 13 [2560/151166 (2%)]\tLoss: 0.000637\n","Train Epoch: 13 [3200/151166 (2%)]\tLoss: 0.001154\n","Train Epoch: 13 [3840/151166 (3%)]\tLoss: 0.004112\n","Train Epoch: 13 [4480/151166 (3%)]\tLoss: 0.000293\n","Train Epoch: 13 [5120/151166 (3%)]\tLoss: 0.001522\n","Train Epoch: 13 [5760/151166 (4%)]\tLoss: 0.000662\n","Train Epoch: 13 [6400/151166 (4%)]\tLoss: 0.001579\n","Train Epoch: 13 [7040/151166 (5%)]\tLoss: 0.000459\n","Train Epoch: 13 [7680/151166 (5%)]\tLoss: 0.000622\n","Train Epoch: 13 [8320/151166 (6%)]\tLoss: 0.000559\n","Train Epoch: 13 [8960/151166 (6%)]\tLoss: 0.001120\n","Train Epoch: 13 [9600/151166 (6%)]\tLoss: 0.001767\n","Train Epoch: 13 [10240/151166 (7%)]\tLoss: 0.001090\n","Train Epoch: 13 [10880/151166 (7%)]\tLoss: 0.000700\n","Train Epoch: 13 [11520/151166 (8%)]\tLoss: 0.002360\n","Train Epoch: 13 [12160/151166 (8%)]\tLoss: 0.001058\n","Train Epoch: 13 [12800/151166 (8%)]\tLoss: 0.000334\n","Train Epoch: 13 [13440/151166 (9%)]\tLoss: 0.000116\n","Train Epoch: 13 [14080/151166 (9%)]\tLoss: 0.000382\n","Train Epoch: 13 [14720/151166 (10%)]\tLoss: 0.000145\n","Train Epoch: 13 [15360/151166 (10%)]\tLoss: 0.000153\n","Train Epoch: 13 [16000/151166 (11%)]\tLoss: 0.000441\n","Train Epoch: 13 [16640/151166 (11%)]\tLoss: 0.000726\n","Train Epoch: 13 [17280/151166 (11%)]\tLoss: 0.000265\n","Train Epoch: 13 [17920/151166 (12%)]\tLoss: 0.000836\n","Train Epoch: 13 [18560/151166 (12%)]\tLoss: 0.000260\n","Train Epoch: 13 [19200/151166 (13%)]\tLoss: 0.000376\n","Train Epoch: 13 [19840/151166 (13%)]\tLoss: 0.001205\n","Train Epoch: 13 [20480/151166 (14%)]\tLoss: 0.000356\n","Train Epoch: 13 [21120/151166 (14%)]\tLoss: 0.000501\n","Train Epoch: 13 [21760/151166 (14%)]\tLoss: 0.001251\n","Train Epoch: 13 [22400/151166 (15%)]\tLoss: 0.000369\n","Train Epoch: 13 [23040/151166 (15%)]\tLoss: 0.000222\n","Train Epoch: 13 [23680/151166 (16%)]\tLoss: 0.000539\n","Train Epoch: 13 [24320/151166 (16%)]\tLoss: 0.000648\n","Train Epoch: 13 [24960/151166 (17%)]\tLoss: 0.000226\n","Train Epoch: 13 [25600/151166 (17%)]\tLoss: 0.000186\n","Train Epoch: 13 [26240/151166 (17%)]\tLoss: 0.000476\n","Train Epoch: 13 [26880/151166 (18%)]\tLoss: 0.000550\n","Train Epoch: 13 [27520/151166 (18%)]\tLoss: 0.000685\n","Train Epoch: 13 [28160/151166 (19%)]\tLoss: 0.001397\n","Train Epoch: 13 [28800/151166 (19%)]\tLoss: 0.000273\n","Train Epoch: 13 [29440/151166 (19%)]\tLoss: 0.000329\n","Train Epoch: 13 [30080/151166 (20%)]\tLoss: 0.000314\n","Train Epoch: 13 [30720/151166 (20%)]\tLoss: 0.000368\n","Train Epoch: 13 [31360/151166 (21%)]\tLoss: 0.000643\n","Train Epoch: 13 [32000/151166 (21%)]\tLoss: 0.000189\n","Train Epoch: 13 [32640/151166 (22%)]\tLoss: 0.000438\n","Train Epoch: 13 [33280/151166 (22%)]\tLoss: 0.001355\n","Train Epoch: 13 [33920/151166 (22%)]\tLoss: 0.001519\n","Train Epoch: 13 [34560/151166 (23%)]\tLoss: 0.000522\n","Train Epoch: 13 [35200/151166 (23%)]\tLoss: 0.000409\n","Train Epoch: 13 [35840/151166 (24%)]\tLoss: 0.000129\n","Train Epoch: 13 [36480/151166 (24%)]\tLoss: 0.000381\n","Train Epoch: 13 [37120/151166 (25%)]\tLoss: 0.000588\n","Train Epoch: 13 [37760/151166 (25%)]\tLoss: 0.000125\n","Train Epoch: 13 [38400/151166 (25%)]\tLoss: 0.001422\n","Train Epoch: 13 [39040/151166 (26%)]\tLoss: 0.000842\n","Train Epoch: 13 [39680/151166 (26%)]\tLoss: 0.002325\n","Train Epoch: 13 [40320/151166 (27%)]\tLoss: 0.001303\n","Train Epoch: 13 [40960/151166 (27%)]\tLoss: 0.001579\n","Train Epoch: 13 [41600/151166 (28%)]\tLoss: 0.001929\n","Train Epoch: 13 [42240/151166 (28%)]\tLoss: 0.001555\n","Train Epoch: 13 [42880/151166 (28%)]\tLoss: 0.001220\n","Train Epoch: 13 [43520/151166 (29%)]\tLoss: 0.001191\n","Train Epoch: 13 [44160/151166 (29%)]\tLoss: 0.000486\n","Train Epoch: 13 [44800/151166 (30%)]\tLoss: 0.000197\n","Train Epoch: 13 [45440/151166 (30%)]\tLoss: 0.000482\n","Train Epoch: 13 [46080/151166 (30%)]\tLoss: 0.000954\n","Train Epoch: 13 [46720/151166 (31%)]\tLoss: 0.001062\n","Train Epoch: 13 [47360/151166 (31%)]\tLoss: 0.001108\n","Train Epoch: 13 [48000/151166 (32%)]\tLoss: 0.000247\n","Train Epoch: 13 [48640/151166 (32%)]\tLoss: 0.001339\n","Train Epoch: 13 [49280/151166 (33%)]\tLoss: 0.000505\n","Train Epoch: 13 [49920/151166 (33%)]\tLoss: 0.000460\n","Train Epoch: 13 [50560/151166 (33%)]\tLoss: 0.001150\n","Train Epoch: 13 [51200/151166 (34%)]\tLoss: 0.001059\n","Train Epoch: 13 [51840/151166 (34%)]\tLoss: 0.000144\n","Train Epoch: 13 [52480/151166 (35%)]\tLoss: 0.000289\n","Train Epoch: 13 [53120/151166 (35%)]\tLoss: 0.000375\n","Train Epoch: 13 [53760/151166 (36%)]\tLoss: 0.000681\n","Train Epoch: 13 [54400/151166 (36%)]\tLoss: 0.001577\n","Train Epoch: 13 [55040/151166 (36%)]\tLoss: 0.000546\n","Train Epoch: 13 [55680/151166 (37%)]\tLoss: 0.001015\n","Train Epoch: 13 [56320/151166 (37%)]\tLoss: 0.000274\n","Train Epoch: 13 [56960/151166 (38%)]\tLoss: 0.001536\n","Train Epoch: 13 [57600/151166 (38%)]\tLoss: 0.000209\n","Train Epoch: 13 [58240/151166 (39%)]\tLoss: 0.001035\n","Train Epoch: 13 [58880/151166 (39%)]\tLoss: 0.000698\n","Train Epoch: 13 [59520/151166 (39%)]\tLoss: 0.000449\n","Train Epoch: 13 [60160/151166 (40%)]\tLoss: 0.000489\n","Train Epoch: 13 [60800/151166 (40%)]\tLoss: 0.000939\n","Train Epoch: 13 [61440/151166 (41%)]\tLoss: 0.002814\n","Train Epoch: 13 [62080/151166 (41%)]\tLoss: 0.000909\n","Train Epoch: 13 [62720/151166 (41%)]\tLoss: 0.000567\n","Train Epoch: 13 [63360/151166 (42%)]\tLoss: 0.000920\n","Train Epoch: 13 [64000/151166 (42%)]\tLoss: 0.000291\n","Train Epoch: 13 [64640/151166 (43%)]\tLoss: 0.000762\n","Train Epoch: 13 [65280/151166 (43%)]\tLoss: 0.003342\n","Train Epoch: 13 [65920/151166 (44%)]\tLoss: 0.000605\n","Train Epoch: 13 [66560/151166 (44%)]\tLoss: 0.000947\n","Train Epoch: 13 [67200/151166 (44%)]\tLoss: 0.000740\n","Train Epoch: 13 [67840/151166 (45%)]\tLoss: 0.000410\n","Train Epoch: 13 [68480/151166 (45%)]\tLoss: 0.000610\n","Train Epoch: 13 [69120/151166 (46%)]\tLoss: 0.000675\n","Train Epoch: 13 [69760/151166 (46%)]\tLoss: 0.000898\n","Train Epoch: 13 [70400/151166 (47%)]\tLoss: 0.000584\n","Train Epoch: 13 [71040/151166 (47%)]\tLoss: 0.000631\n","Train Epoch: 13 [71680/151166 (47%)]\tLoss: 0.000718\n","Train Epoch: 13 [72320/151166 (48%)]\tLoss: 0.003345\n","Train Epoch: 13 [72960/151166 (48%)]\tLoss: 0.003953\n","Train Epoch: 13 [73600/151166 (49%)]\tLoss: 0.000165\n","Train Epoch: 13 [74240/151166 (49%)]\tLoss: 0.001538\n","Train Epoch: 13 [74880/151166 (50%)]\tLoss: 0.001154\n","Train Epoch: 13 [75520/151166 (50%)]\tLoss: 0.000182\n","Train Epoch: 13 [76160/151166 (50%)]\tLoss: 0.001120\n","Train Epoch: 13 [76800/151166 (51%)]\tLoss: 0.000509\n","Train Epoch: 13 [77440/151166 (51%)]\tLoss: 0.002330\n","Train Epoch: 13 [78080/151166 (52%)]\tLoss: 0.000394\n","Train Epoch: 13 [78720/151166 (52%)]\tLoss: 0.002610\n","Train Epoch: 13 [79360/151166 (52%)]\tLoss: 0.000745\n","Train Epoch: 13 [80000/151166 (53%)]\tLoss: 0.000148\n","Train Epoch: 13 [80640/151166 (53%)]\tLoss: 0.001403\n","Train Epoch: 13 [81280/151166 (54%)]\tLoss: 0.000527\n","Train Epoch: 13 [81920/151166 (54%)]\tLoss: 0.001038\n","Train Epoch: 13 [82560/151166 (55%)]\tLoss: 0.000814\n","Train Epoch: 13 [83200/151166 (55%)]\tLoss: 0.000754\n","Train Epoch: 13 [83840/151166 (55%)]\tLoss: 0.000134\n","Train Epoch: 13 [84480/151166 (56%)]\tLoss: 0.001443\n","Train Epoch: 13 [85120/151166 (56%)]\tLoss: 0.002477\n","Train Epoch: 13 [85760/151166 (57%)]\tLoss: 0.004311\n","Train Epoch: 13 [86400/151166 (57%)]\tLoss: 0.001980\n","Train Epoch: 13 [87040/151166 (58%)]\tLoss: 0.000702\n","Train Epoch: 13 [87680/151166 (58%)]\tLoss: 0.001306\n","Train Epoch: 13 [88320/151166 (58%)]\tLoss: 0.000239\n","Train Epoch: 13 [88960/151166 (59%)]\tLoss: 0.000325\n","Train Epoch: 13 [89600/151166 (59%)]\tLoss: 0.000795\n","Train Epoch: 13 [90240/151166 (60%)]\tLoss: 0.000216\n","Train Epoch: 13 [90880/151166 (60%)]\tLoss: 0.000946\n","Train Epoch: 13 [91520/151166 (61%)]\tLoss: 0.000952\n","Train Epoch: 13 [92160/151166 (61%)]\tLoss: 0.000437\n","Train Epoch: 13 [92800/151166 (61%)]\tLoss: 0.000331\n","Train Epoch: 13 [93440/151166 (62%)]\tLoss: 0.000902\n","Train Epoch: 13 [94080/151166 (62%)]\tLoss: 0.000755\n","Train Epoch: 13 [94720/151166 (63%)]\tLoss: 0.000607\n","Train Epoch: 13 [95360/151166 (63%)]\tLoss: 0.000593\n","Train Epoch: 13 [96000/151166 (64%)]\tLoss: 0.000620\n","Train Epoch: 13 [96640/151166 (64%)]\tLoss: 0.000397\n","Train Epoch: 13 [97280/151166 (64%)]\tLoss: 0.000732\n","Train Epoch: 13 [97920/151166 (65%)]\tLoss: 0.000616\n","Train Epoch: 13 [98560/151166 (65%)]\tLoss: 0.000615\n","Train Epoch: 13 [99200/151166 (66%)]\tLoss: 0.000421\n","Train Epoch: 13 [99840/151166 (66%)]\tLoss: 0.000332\n","Train Epoch: 13 [100480/151166 (66%)]\tLoss: 0.001521\n","Train Epoch: 13 [101120/151166 (67%)]\tLoss: 0.000999\n","Train Epoch: 13 [101760/151166 (67%)]\tLoss: 0.000560\n","Train Epoch: 13 [102400/151166 (68%)]\tLoss: 0.000411\n","Train Epoch: 13 [103040/151166 (68%)]\tLoss: 0.000223\n","Train Epoch: 13 [103680/151166 (69%)]\tLoss: 0.000723\n","Train Epoch: 13 [104320/151166 (69%)]\tLoss: 0.000143\n","Train Epoch: 13 [104960/151166 (69%)]\tLoss: 0.003483\n","Train Epoch: 13 [105600/151166 (70%)]\tLoss: 0.001511\n","Train Epoch: 13 [106240/151166 (70%)]\tLoss: 0.000250\n","Train Epoch: 13 [106880/151166 (71%)]\tLoss: 0.000562\n","Train Epoch: 13 [107520/151166 (71%)]\tLoss: 0.000491\n","Train Epoch: 13 [108160/151166 (72%)]\tLoss: 0.000940\n","Train Epoch: 13 [108800/151166 (72%)]\tLoss: 0.000365\n","Train Epoch: 13 [109440/151166 (72%)]\tLoss: 0.000686\n","Train Epoch: 13 [110080/151166 (73%)]\tLoss: 0.001096\n","Train Epoch: 13 [110720/151166 (73%)]\tLoss: 0.001121\n","Train Epoch: 13 [111360/151166 (74%)]\tLoss: 0.000458\n","Train Epoch: 13 [112000/151166 (74%)]\tLoss: 0.000305\n","Train Epoch: 13 [112640/151166 (75%)]\tLoss: 0.000818\n","Train Epoch: 13 [113280/151166 (75%)]\tLoss: 0.000949\n","Train Epoch: 13 [113920/151166 (75%)]\tLoss: 0.000258\n","Train Epoch: 13 [114560/151166 (76%)]\tLoss: 0.000583\n","Train Epoch: 13 [115200/151166 (76%)]\tLoss: 0.000145\n","Train Epoch: 13 [115840/151166 (77%)]\tLoss: 0.000650\n","Train Epoch: 13 [116480/151166 (77%)]\tLoss: 0.000329\n","Train Epoch: 13 [117120/151166 (77%)]\tLoss: 0.000417\n","Train Epoch: 13 [117760/151166 (78%)]\tLoss: 0.000214\n","Train Epoch: 13 [118400/151166 (78%)]\tLoss: 0.000540\n","Train Epoch: 13 [119040/151166 (79%)]\tLoss: 0.000223\n","Train Epoch: 13 [119680/151166 (79%)]\tLoss: 0.000289\n","Train Epoch: 13 [120320/151166 (80%)]\tLoss: 0.000483\n","Train Epoch: 13 [120960/151166 (80%)]\tLoss: 0.003867\n","Train Epoch: 13 [121600/151166 (80%)]\tLoss: 0.000133\n","Train Epoch: 13 [122240/151166 (81%)]\tLoss: 0.000388\n","Train Epoch: 13 [122880/151166 (81%)]\tLoss: 0.000550\n","Train Epoch: 13 [123520/151166 (82%)]\tLoss: 0.000700\n","Train Epoch: 13 [124160/151166 (82%)]\tLoss: 0.000200\n","Train Epoch: 13 [124800/151166 (83%)]\tLoss: 0.000376\n","Train Epoch: 13 [125440/151166 (83%)]\tLoss: 0.000174\n","Train Epoch: 13 [126080/151166 (83%)]\tLoss: 0.001023\n","Train Epoch: 13 [126720/151166 (84%)]\tLoss: 0.001616\n","Train Epoch: 13 [127360/151166 (84%)]\tLoss: 0.001120\n","Train Epoch: 13 [128000/151166 (85%)]\tLoss: 0.000534\n","Train Epoch: 13 [128640/151166 (85%)]\tLoss: 0.001454\n","Train Epoch: 13 [129280/151166 (86%)]\tLoss: 0.000248\n","Train Epoch: 13 [129920/151166 (86%)]\tLoss: 0.000316\n","Train Epoch: 13 [130560/151166 (86%)]\tLoss: 0.000787\n","Train Epoch: 13 [131200/151166 (87%)]\tLoss: 0.000674\n","Train Epoch: 13 [131840/151166 (87%)]\tLoss: 0.002003\n","Train Epoch: 13 [132480/151166 (88%)]\tLoss: 0.000228\n","Train Epoch: 13 [133120/151166 (88%)]\tLoss: 0.001233\n","Train Epoch: 13 [133760/151166 (88%)]\tLoss: 0.000684\n","Train Epoch: 13 [134400/151166 (89%)]\tLoss: 0.000395\n","Train Epoch: 13 [135040/151166 (89%)]\tLoss: 0.000240\n","Train Epoch: 13 [135680/151166 (90%)]\tLoss: 0.001446\n","Train Epoch: 13 [136320/151166 (90%)]\tLoss: 0.000119\n","Train Epoch: 13 [136960/151166 (91%)]\tLoss: 0.000657\n","Train Epoch: 13 [137600/151166 (91%)]\tLoss: 0.003757\n","Train Epoch: 13 [138240/151166 (91%)]\tLoss: 0.000818\n","Train Epoch: 13 [138880/151166 (92%)]\tLoss: 0.001404\n","Train Epoch: 13 [139520/151166 (92%)]\tLoss: 0.000274\n","Train Epoch: 13 [140160/151166 (93%)]\tLoss: 0.000702\n","Train Epoch: 13 [140800/151166 (93%)]\tLoss: 0.001270\n","Train Epoch: 13 [141440/151166 (94%)]\tLoss: 0.000770\n","Train Epoch: 13 [142080/151166 (94%)]\tLoss: 0.000951\n","Train Epoch: 13 [142720/151166 (94%)]\tLoss: 0.000489\n","Train Epoch: 13 [143360/151166 (95%)]\tLoss: 0.000320\n","Train Epoch: 13 [144000/151166 (95%)]\tLoss: 0.001307\n","Train Epoch: 13 [144640/151166 (96%)]\tLoss: 0.000625\n","Train Epoch: 13 [145280/151166 (96%)]\tLoss: 0.000093\n","Train Epoch: 13 [145920/151166 (97%)]\tLoss: 0.001020\n","Train Epoch: 13 [146560/151166 (97%)]\tLoss: 0.001078\n","Train Epoch: 13 [147200/151166 (97%)]\tLoss: 0.000349\n","Train Epoch: 13 [147840/151166 (98%)]\tLoss: 0.000147\n","Train Epoch: 13 [148480/151166 (98%)]\tLoss: 0.000842\n","Train Epoch: 13 [149120/151166 (99%)]\tLoss: 0.000446\n","Train Epoch: 13 [149760/151166 (99%)]\tLoss: 0.000099\n","Train Epoch: 13 [150400/151166 (99%)]\tLoss: 0.000698\n","Train Epoch: 13 [151040/151166 (100%)]\tLoss: 0.000277\n","Sample outputs (log probs): tensor([[-8.7258e+00, -1.1401e+01, -8.9550e+00, -1.0992e+01, -1.0741e+01,\n","         -6.0176e+00, -8.8213e+00, -5.5886e+00, -7.7547e+00, -1.2489e+01,\n","         -7.0168e+00, -9.2204e+00, -1.0741e+01, -7.5892e+00, -1.1204e+01,\n","         -5.7313e-02, -1.0703e+01, -8.6094e+00, -1.0872e+01, -5.9009e+00,\n","         -1.1882e+01, -4.9456e+00, -9.6361e+00, -1.0635e+01, -3.2998e+00,\n","         -1.2312e+01],\n","        [-3.2436e+01, -1.7760e+01, -1.8620e+01, -1.9502e+01, -1.5906e+01,\n","         -1.7207e+01, -1.6330e+01, -3.6690e+01, -1.6691e+01, -8.4008e+00,\n","         -3.0630e+01, -2.6011e+01, -3.2660e+01, -3.3652e+01, -1.5361e+01,\n","         -2.9577e+01, -2.3605e+01, -4.1546e+01, -2.2528e-04, -2.1404e+01,\n","         -2.9302e+01, -3.0287e+01, -3.0581e+01, -3.2436e+01, -1.7467e+01,\n","         -2.5349e+01],\n","        [-1.0556e+01, -2.0910e+01, -2.3991e+01, -2.6221e+01, -2.6798e+01,\n","         -2.3701e+01, -1.8546e+01, -7.1165e-05, -2.4517e+01, -2.4905e+01,\n","         -1.2246e+01, -2.0672e+01, -1.0201e+01, -1.3935e+01, -2.3446e+01,\n","         -1.6832e+01, -2.2636e+01, -1.6180e+01, -2.8754e+01, -1.9823e+01,\n","         -1.5753e+01, -1.7326e+01, -1.5864e+01, -2.0891e+01, -1.3151e+01,\n","         -2.6332e+01],\n","        [-1.0736e+01, -1.4977e+01, -1.1962e+01, -1.5321e+01, -1.1380e+01,\n","         -7.8349e-04, -8.0349e+00, -1.2125e+01, -1.0556e+01, -1.3649e+01,\n","         -1.4309e+01, -1.0518e+01, -2.0863e+01, -1.5328e+01, -1.7679e+01,\n","         -1.0523e+01, -1.1705e+01, -1.4382e+01, -8.0686e+00, -1.1644e+01,\n","         -1.7279e+01, -1.7261e+01, -1.7305e+01, -1.5116e+01, -1.5272e+01,\n","         -1.4923e+01],\n","        [-2.6372e+01, -1.6954e+01, -1.5096e+01, -2.1719e+01, -9.4265e+00,\n","         -1.0048e+01, -1.0751e+01, -3.1922e+01, -1.7963e+01, -1.1907e+01,\n","         -2.5130e+01, -2.4560e+01, -3.0818e+01, -3.0433e+01, -1.5756e+01,\n","         -2.1430e+01, -1.5821e+01, -3.1580e+01, -1.5258e-04, -2.0859e+01,\n","         -2.8206e+01, -2.7328e+01, -2.9236e+01, -3.1256e+01, -1.9077e+01,\n","         -2.6442e+01]], device='cuda:0')\n","Predicted classes: tensor([15, 18,  7,  5, 18], device='cuda:0')\n","Target classes: tensor([15, 18,  7,  5, 18], device='cuda:0')\n","\n","Test set: Average loss: 0.001592, Total sum loss: 0.471113, Accuracy: 36933/37792 (98%)\n","\n","Class A: 1224/1247 (98%)\n","Class B: 802/816 (98%)\n","Class C: 1925/1965 (98%)\n","Class D: 811/868 (93%)\n","Class E: 1008/1024 (98%)\n","Class F: 1826/1869 (98%)\n","Class G: 507/519 (98%)\n","Class H: 601/621 (97%)\n","Class I: 2372/2410 (98%)\n","Class J: 732/754 (97%)\n","Class K: 489/502 (97%)\n","Class L: 965/987 (98%)\n","Class M: 1750/1774 (99%)\n","Class N: 1591/1622 (98%)\n","Class O: 4916/5064 (97%)\n","Class P: 1584/1615 (98%)\n","Class Q: 520/536 (97%)\n","Class R: 974/992 (98%)\n","Class S: 4181/4228 (99%)\n","Class T: 1920/1932 (99%)\n","Class U: 2508/2598 (97%)\n","Class V: 861/904 (95%)\n","Class W: 912/938 (97%)\n","Class X: 547/560 (98%)\n","Class Y: 893/924 (97%)\n","Class Z: 514/523 (98%)\n","Model saved with new best test loss: 0.0016 \n","\n","Train Epoch: 14 [0/151166 (0%)]\tLoss: 0.000486\n","Train Epoch: 14 [640/151166 (0%)]\tLoss: 0.000347\n","Train Epoch: 14 [1280/151166 (1%)]\tLoss: 0.000402\n","Train Epoch: 14 [1920/151166 (1%)]\tLoss: 0.001673\n","Train Epoch: 14 [2560/151166 (2%)]\tLoss: 0.001161\n","Train Epoch: 14 [3200/151166 (2%)]\tLoss: 0.001714\n","Train Epoch: 14 [3840/151166 (3%)]\tLoss: 0.000309\n","Train Epoch: 14 [4480/151166 (3%)]\tLoss: 0.000221\n","Train Epoch: 14 [5120/151166 (3%)]\tLoss: 0.000320\n","Train Epoch: 14 [5760/151166 (4%)]\tLoss: 0.001668\n","Train Epoch: 14 [6400/151166 (4%)]\tLoss: 0.002255\n","Train Epoch: 14 [7040/151166 (5%)]\tLoss: 0.001789\n","Train Epoch: 14 [7680/151166 (5%)]\tLoss: 0.000359\n","Train Epoch: 14 [8320/151166 (6%)]\tLoss: 0.001691\n","Train Epoch: 14 [8960/151166 (6%)]\tLoss: 0.000234\n","Train Epoch: 14 [9600/151166 (6%)]\tLoss: 0.001119\n","Train Epoch: 14 [10240/151166 (7%)]\tLoss: 0.000546\n","Train Epoch: 14 [10880/151166 (7%)]\tLoss: 0.000521\n","Train Epoch: 14 [11520/151166 (8%)]\tLoss: 0.000212\n","Train Epoch: 14 [12160/151166 (8%)]\tLoss: 0.000410\n","Train Epoch: 14 [12800/151166 (8%)]\tLoss: 0.000337\n","Train Epoch: 14 [13440/151166 (9%)]\tLoss: 0.000349\n","Train Epoch: 14 [14080/151166 (9%)]\tLoss: 0.000149\n","Train Epoch: 14 [14720/151166 (10%)]\tLoss: 0.000889\n","Train Epoch: 14 [15360/151166 (10%)]\tLoss: 0.000596\n","Train Epoch: 14 [16000/151166 (11%)]\tLoss: 0.000769\n","Train Epoch: 14 [16640/151166 (11%)]\tLoss: 0.001070\n","Train Epoch: 14 [17280/151166 (11%)]\tLoss: 0.000117\n","Train Epoch: 14 [17920/151166 (12%)]\tLoss: 0.001267\n","Train Epoch: 14 [18560/151166 (12%)]\tLoss: 0.000123\n","Train Epoch: 14 [19200/151166 (13%)]\tLoss: 0.001250\n","Train Epoch: 14 [19840/151166 (13%)]\tLoss: 0.000408\n","Train Epoch: 14 [20480/151166 (14%)]\tLoss: 0.001577\n","Train Epoch: 14 [21120/151166 (14%)]\tLoss: 0.000465\n","Train Epoch: 14 [21760/151166 (14%)]\tLoss: 0.000924\n","Train Epoch: 14 [22400/151166 (15%)]\tLoss: 0.000302\n","Train Epoch: 14 [23040/151166 (15%)]\tLoss: 0.000438\n","Train Epoch: 14 [23680/151166 (16%)]\tLoss: 0.000525\n","Train Epoch: 14 [24320/151166 (16%)]\tLoss: 0.000302\n","Train Epoch: 14 [24960/151166 (17%)]\tLoss: 0.000625\n","Train Epoch: 14 [25600/151166 (17%)]\tLoss: 0.002703\n","Train Epoch: 14 [26240/151166 (17%)]\tLoss: 0.000278\n","Train Epoch: 14 [26880/151166 (18%)]\tLoss: 0.000458\n","Train Epoch: 14 [27520/151166 (18%)]\tLoss: 0.001275\n","Train Epoch: 14 [28160/151166 (19%)]\tLoss: 0.000624\n","Train Epoch: 14 [28800/151166 (19%)]\tLoss: 0.000299\n","Train Epoch: 14 [29440/151166 (19%)]\tLoss: 0.000675\n","Train Epoch: 14 [30080/151166 (20%)]\tLoss: 0.000618\n","Train Epoch: 14 [30720/151166 (20%)]\tLoss: 0.000662\n","Train Epoch: 14 [31360/151166 (21%)]\tLoss: 0.000234\n","Train Epoch: 14 [32000/151166 (21%)]\tLoss: 0.000644\n","Train Epoch: 14 [32640/151166 (22%)]\tLoss: 0.000424\n","Train Epoch: 14 [33280/151166 (22%)]\tLoss: 0.001009\n","Train Epoch: 14 [33920/151166 (22%)]\tLoss: 0.000800\n","Train Epoch: 14 [34560/151166 (23%)]\tLoss: 0.000368\n","Train Epoch: 14 [35200/151166 (23%)]\tLoss: 0.000244\n","Train Epoch: 14 [35840/151166 (24%)]\tLoss: 0.000574\n","Train Epoch: 14 [36480/151166 (24%)]\tLoss: 0.000164\n","Train Epoch: 14 [37120/151166 (25%)]\tLoss: 0.000833\n","Train Epoch: 14 [37760/151166 (25%)]\tLoss: 0.000539\n","Train Epoch: 14 [38400/151166 (25%)]\tLoss: 0.000742\n","Train Epoch: 14 [39040/151166 (26%)]\tLoss: 0.000156\n","Train Epoch: 14 [39680/151166 (26%)]\tLoss: 0.001211\n","Train Epoch: 14 [40320/151166 (27%)]\tLoss: 0.000210\n","Train Epoch: 14 [40960/151166 (27%)]\tLoss: 0.000624\n","Train Epoch: 14 [41600/151166 (28%)]\tLoss: 0.003467\n","Train Epoch: 14 [42240/151166 (28%)]\tLoss: 0.001135\n","Train Epoch: 14 [42880/151166 (28%)]\tLoss: 0.001117\n","Train Epoch: 14 [43520/151166 (29%)]\tLoss: 0.001543\n","Train Epoch: 14 [44160/151166 (29%)]\tLoss: 0.000282\n","Train Epoch: 14 [44800/151166 (30%)]\tLoss: 0.001035\n","Train Epoch: 14 [45440/151166 (30%)]\tLoss: 0.000574\n","Train Epoch: 14 [46080/151166 (30%)]\tLoss: 0.001453\n","Train Epoch: 14 [46720/151166 (31%)]\tLoss: 0.000748\n","Train Epoch: 14 [47360/151166 (31%)]\tLoss: 0.000329\n","Train Epoch: 14 [48000/151166 (32%)]\tLoss: 0.000553\n","Train Epoch: 14 [48640/151166 (32%)]\tLoss: 0.001515\n","Train Epoch: 14 [49280/151166 (33%)]\tLoss: 0.001740\n","Train Epoch: 14 [49920/151166 (33%)]\tLoss: 0.001109\n","Train Epoch: 14 [50560/151166 (33%)]\tLoss: 0.000105\n","Train Epoch: 14 [51200/151166 (34%)]\tLoss: 0.000398\n","Train Epoch: 14 [51840/151166 (34%)]\tLoss: 0.001221\n","Train Epoch: 14 [52480/151166 (35%)]\tLoss: 0.000409\n","Train Epoch: 14 [53120/151166 (35%)]\tLoss: 0.000216\n","Train Epoch: 14 [53760/151166 (36%)]\tLoss: 0.001625\n","Train Epoch: 14 [54400/151166 (36%)]\tLoss: 0.000889\n","Train Epoch: 14 [55040/151166 (36%)]\tLoss: 0.000347\n","Train Epoch: 14 [55680/151166 (37%)]\tLoss: 0.000276\n","Train Epoch: 14 [56320/151166 (37%)]\tLoss: 0.000921\n","Train Epoch: 14 [56960/151166 (38%)]\tLoss: 0.000154\n","Train Epoch: 14 [57600/151166 (38%)]\tLoss: 0.000661\n","Train Epoch: 14 [58240/151166 (39%)]\tLoss: 0.001631\n","Train Epoch: 14 [58880/151166 (39%)]\tLoss: 0.000789\n","Train Epoch: 14 [59520/151166 (39%)]\tLoss: 0.000181\n","Train Epoch: 14 [60160/151166 (40%)]\tLoss: 0.000399\n","Train Epoch: 14 [60800/151166 (40%)]\tLoss: 0.002081\n","Train Epoch: 14 [61440/151166 (41%)]\tLoss: 0.000448\n","Train Epoch: 14 [62080/151166 (41%)]\tLoss: 0.000607\n","Train Epoch: 14 [62720/151166 (41%)]\tLoss: 0.001435\n","Train Epoch: 14 [63360/151166 (42%)]\tLoss: 0.000763\n","Train Epoch: 14 [64000/151166 (42%)]\tLoss: 0.000844\n","Train Epoch: 14 [64640/151166 (43%)]\tLoss: 0.001108\n","Train Epoch: 14 [65280/151166 (43%)]\tLoss: 0.001806\n","Train Epoch: 14 [65920/151166 (44%)]\tLoss: 0.000745\n","Train Epoch: 14 [66560/151166 (44%)]\tLoss: 0.000585\n","Train Epoch: 14 [67200/151166 (44%)]\tLoss: 0.000504\n","Train Epoch: 14 [67840/151166 (45%)]\tLoss: 0.000403\n","Train Epoch: 14 [68480/151166 (45%)]\tLoss: 0.001047\n","Train Epoch: 14 [69120/151166 (46%)]\tLoss: 0.000467\n","Train Epoch: 14 [69760/151166 (46%)]\tLoss: 0.000258\n","Train Epoch: 14 [70400/151166 (47%)]\tLoss: 0.001185\n","Train Epoch: 14 [71040/151166 (47%)]\tLoss: 0.000881\n","Train Epoch: 14 [71680/151166 (47%)]\tLoss: 0.000295\n","Train Epoch: 14 [72320/151166 (48%)]\tLoss: 0.000855\n","Train Epoch: 14 [72960/151166 (48%)]\tLoss: 0.000494\n","Train Epoch: 14 [73600/151166 (49%)]\tLoss: 0.001282\n","Train Epoch: 14 [74240/151166 (49%)]\tLoss: 0.000422\n","Train Epoch: 14 [74880/151166 (50%)]\tLoss: 0.000422\n","Train Epoch: 14 [75520/151166 (50%)]\tLoss: 0.001660\n","Train Epoch: 14 [76160/151166 (50%)]\tLoss: 0.000564\n","Train Epoch: 14 [76800/151166 (51%)]\tLoss: 0.000267\n","Train Epoch: 14 [77440/151166 (51%)]\tLoss: 0.000887\n","Train Epoch: 14 [78080/151166 (52%)]\tLoss: 0.000792\n","Train Epoch: 14 [78720/151166 (52%)]\tLoss: 0.000793\n","Train Epoch: 14 [79360/151166 (52%)]\tLoss: 0.000996\n","Train Epoch: 14 [80000/151166 (53%)]\tLoss: 0.002899\n","Train Epoch: 14 [80640/151166 (53%)]\tLoss: 0.000293\n","Train Epoch: 14 [81280/151166 (54%)]\tLoss: 0.000895\n","Train Epoch: 14 [81920/151166 (54%)]\tLoss: 0.000081\n","Train Epoch: 14 [82560/151166 (55%)]\tLoss: 0.000387\n","Train Epoch: 14 [83200/151166 (55%)]\tLoss: 0.001845\n","Train Epoch: 14 [83840/151166 (55%)]\tLoss: 0.000054\n","Train Epoch: 14 [84480/151166 (56%)]\tLoss: 0.000454\n","Train Epoch: 14 [85120/151166 (56%)]\tLoss: 0.000620\n","Train Epoch: 14 [85760/151166 (57%)]\tLoss: 0.000310\n","Train Epoch: 14 [86400/151166 (57%)]\tLoss: 0.003957\n","Train Epoch: 14 [87040/151166 (58%)]\tLoss: 0.000673\n","Train Epoch: 14 [87680/151166 (58%)]\tLoss: 0.000504\n","Train Epoch: 14 [88320/151166 (58%)]\tLoss: 0.000500\n","Train Epoch: 14 [88960/151166 (59%)]\tLoss: 0.001965\n","Train Epoch: 14 [89600/151166 (59%)]\tLoss: 0.001074\n","Train Epoch: 14 [90240/151166 (60%)]\tLoss: 0.000234\n","Train Epoch: 14 [90880/151166 (60%)]\tLoss: 0.000639\n","Train Epoch: 14 [91520/151166 (61%)]\tLoss: 0.000078\n","Train Epoch: 14 [92160/151166 (61%)]\tLoss: 0.000538\n","Train Epoch: 14 [92800/151166 (61%)]\tLoss: 0.001000\n","Train Epoch: 14 [93440/151166 (62%)]\tLoss: 0.000560\n","Train Epoch: 14 [94080/151166 (62%)]\tLoss: 0.000186\n","Train Epoch: 14 [94720/151166 (63%)]\tLoss: 0.001151\n","Train Epoch: 14 [95360/151166 (63%)]\tLoss: 0.000255\n","Train Epoch: 14 [96000/151166 (64%)]\tLoss: 0.000447\n","Train Epoch: 14 [96640/151166 (64%)]\tLoss: 0.000703\n","Train Epoch: 14 [97280/151166 (64%)]\tLoss: 0.000452\n","Train Epoch: 14 [97920/151166 (65%)]\tLoss: 0.000478\n","Train Epoch: 14 [98560/151166 (65%)]\tLoss: 0.000516\n","Train Epoch: 14 [99200/151166 (66%)]\tLoss: 0.002509\n","Train Epoch: 14 [99840/151166 (66%)]\tLoss: 0.000220\n","Train Epoch: 14 [100480/151166 (66%)]\tLoss: 0.000504\n","Train Epoch: 14 [101120/151166 (67%)]\tLoss: 0.000307\n","Train Epoch: 14 [101760/151166 (67%)]\tLoss: 0.000390\n","Train Epoch: 14 [102400/151166 (68%)]\tLoss: 0.000244\n","Train Epoch: 14 [103040/151166 (68%)]\tLoss: 0.000369\n","Train Epoch: 14 [103680/151166 (69%)]\tLoss: 0.000766\n","Train Epoch: 14 [104320/151166 (69%)]\tLoss: 0.000613\n","Train Epoch: 14 [104960/151166 (69%)]\tLoss: 0.000259\n","Train Epoch: 14 [105600/151166 (70%)]\tLoss: 0.000370\n","Train Epoch: 14 [106240/151166 (70%)]\tLoss: 0.001049\n","Train Epoch: 14 [106880/151166 (71%)]\tLoss: 0.000521\n","Train Epoch: 14 [107520/151166 (71%)]\tLoss: 0.000244\n","Train Epoch: 14 [108160/151166 (72%)]\tLoss: 0.001378\n","Train Epoch: 14 [108800/151166 (72%)]\tLoss: 0.000289\n","Train Epoch: 14 [109440/151166 (72%)]\tLoss: 0.001591\n","Train Epoch: 14 [110080/151166 (73%)]\tLoss: 0.000943\n","Train Epoch: 14 [110720/151166 (73%)]\tLoss: 0.000118\n","Train Epoch: 14 [111360/151166 (74%)]\tLoss: 0.000310\n","Train Epoch: 14 [112000/151166 (74%)]\tLoss: 0.000196\n","Train Epoch: 14 [112640/151166 (75%)]\tLoss: 0.000429\n","Train Epoch: 14 [113280/151166 (75%)]\tLoss: 0.000616\n","Train Epoch: 14 [113920/151166 (75%)]\tLoss: 0.000209\n","Train Epoch: 14 [114560/151166 (76%)]\tLoss: 0.003427\n","Train Epoch: 14 [115200/151166 (76%)]\tLoss: 0.001171\n","Train Epoch: 14 [115840/151166 (77%)]\tLoss: 0.001198\n","Train Epoch: 14 [116480/151166 (77%)]\tLoss: 0.001511\n","Train Epoch: 14 [117120/151166 (77%)]\tLoss: 0.000679\n","Train Epoch: 14 [117760/151166 (78%)]\tLoss: 0.000193\n","Train Epoch: 14 [118400/151166 (78%)]\tLoss: 0.001707\n","Train Epoch: 14 [119040/151166 (79%)]\tLoss: 0.000881\n","Train Epoch: 14 [119680/151166 (79%)]\tLoss: 0.000506\n","Train Epoch: 14 [120320/151166 (80%)]\tLoss: 0.001766\n","Train Epoch: 14 [120960/151166 (80%)]\tLoss: 0.000742\n","Train Epoch: 14 [121600/151166 (80%)]\tLoss: 0.002883\n","Train Epoch: 14 [122240/151166 (81%)]\tLoss: 0.000111\n","Train Epoch: 14 [122880/151166 (81%)]\tLoss: 0.000348\n","Train Epoch: 14 [123520/151166 (82%)]\tLoss: 0.002094\n","Train Epoch: 14 [124160/151166 (82%)]\tLoss: 0.001394\n","Train Epoch: 14 [124800/151166 (83%)]\tLoss: 0.000163\n","Train Epoch: 14 [125440/151166 (83%)]\tLoss: 0.000707\n","Train Epoch: 14 [126080/151166 (83%)]\tLoss: 0.000464\n","Train Epoch: 14 [126720/151166 (84%)]\tLoss: 0.001664\n","Train Epoch: 14 [127360/151166 (84%)]\tLoss: 0.001317\n","Train Epoch: 14 [128000/151166 (85%)]\tLoss: 0.000241\n","Train Epoch: 14 [128640/151166 (85%)]\tLoss: 0.001510\n","Train Epoch: 14 [129280/151166 (86%)]\tLoss: 0.001161\n","Train Epoch: 14 [129920/151166 (86%)]\tLoss: 0.001457\n","Train Epoch: 14 [130560/151166 (86%)]\tLoss: 0.000486\n","Train Epoch: 14 [131200/151166 (87%)]\tLoss: 0.000740\n","Train Epoch: 14 [131840/151166 (87%)]\tLoss: 0.000964\n","Train Epoch: 14 [132480/151166 (88%)]\tLoss: 0.000200\n","Train Epoch: 14 [133120/151166 (88%)]\tLoss: 0.000518\n","Train Epoch: 14 [133760/151166 (88%)]\tLoss: 0.000737\n","Train Epoch: 14 [134400/151166 (89%)]\tLoss: 0.000853\n","Train Epoch: 14 [135040/151166 (89%)]\tLoss: 0.000857\n","Train Epoch: 14 [135680/151166 (90%)]\tLoss: 0.001191\n","Train Epoch: 14 [136320/151166 (90%)]\tLoss: 0.001590\n","Train Epoch: 14 [136960/151166 (91%)]\tLoss: 0.001091\n","Train Epoch: 14 [137600/151166 (91%)]\tLoss: 0.000775\n","Train Epoch: 14 [138240/151166 (91%)]\tLoss: 0.000202\n","Train Epoch: 14 [138880/151166 (92%)]\tLoss: 0.000530\n","Train Epoch: 14 [139520/151166 (92%)]\tLoss: 0.000625\n","Train Epoch: 14 [140160/151166 (93%)]\tLoss: 0.001351\n","Train Epoch: 14 [140800/151166 (93%)]\tLoss: 0.000467\n","Train Epoch: 14 [141440/151166 (94%)]\tLoss: 0.000499\n","Train Epoch: 14 [142080/151166 (94%)]\tLoss: 0.000964\n","Train Epoch: 14 [142720/151166 (94%)]\tLoss: 0.002044\n","Train Epoch: 14 [143360/151166 (95%)]\tLoss: 0.000704\n","Train Epoch: 14 [144000/151166 (95%)]\tLoss: 0.000446\n","Train Epoch: 14 [144640/151166 (96%)]\tLoss: 0.000750\n","Train Epoch: 14 [145280/151166 (96%)]\tLoss: 0.000206\n","Train Epoch: 14 [145920/151166 (97%)]\tLoss: 0.000338\n","Train Epoch: 14 [146560/151166 (97%)]\tLoss: 0.000105\n","Train Epoch: 14 [147200/151166 (97%)]\tLoss: 0.001004\n","Train Epoch: 14 [147840/151166 (98%)]\tLoss: 0.000523\n","Train Epoch: 14 [148480/151166 (98%)]\tLoss: 0.000365\n","Train Epoch: 14 [149120/151166 (99%)]\tLoss: 0.000227\n","Train Epoch: 14 [149760/151166 (99%)]\tLoss: 0.000533\n","Train Epoch: 14 [150400/151166 (99%)]\tLoss: 0.001396\n","Train Epoch: 14 [151040/151166 (100%)]\tLoss: 0.000657\n","Sample outputs (log probs): tensor([[-1.0079e+01, -1.7627e+01, -1.6734e+01, -1.3807e+01, -1.9692e+01,\n","         -7.3159e+00, -1.8774e+01, -1.3253e+01, -1.4051e+01, -2.1091e+01,\n","         -1.8721e+01, -1.9504e+01, -1.7738e+01, -1.3143e+01, -1.8380e+01,\n","         -7.4383e-04, -1.6588e+01, -1.1419e+01, -1.7249e+01, -1.1407e+01,\n","         -2.2417e+01, -1.6814e+01, -1.9796e+01, -2.0057e+01, -1.1646e+01,\n","         -1.8617e+01],\n","        [-1.4556e+01, -2.0884e+01, -1.5058e+01, -1.2235e+01, -1.9537e+01,\n","         -1.1561e+01, -1.8960e+01, -1.4866e+01, -6.7354e-04, -1.0423e+01,\n","         -1.4169e+01, -7.9091e+00, -1.7894e+01, -1.1714e+01, -1.6791e+01,\n","         -1.0290e+01, -1.7707e+01, -1.8670e+01, -1.4492e+01, -9.8698e+00,\n","         -1.2579e+01, -9.9872e+00, -1.5725e+01, -1.0062e+01, -9.5209e+00,\n","         -1.6722e+01],\n","        [-2.1553e+01, -1.8065e+01, -1.1012e+01, -9.9182e+00, -2.6671e+01,\n","         -2.4136e+01, -1.7423e+01, -2.8385e+01, -2.1907e+01, -1.9605e+01,\n","         -3.2934e+01, -2.6333e+01, -2.0447e+01, -1.7470e+01, -8.8688e-05,\n","         -1.6089e+01, -1.0698e+01, -2.7217e+01, -1.7829e+01, -2.0542e+01,\n","         -1.6264e+01, -2.4236e+01, -2.2651e+01, -3.7459e+01, -2.0016e+01,\n","         -3.0100e+01],\n","        [-8.2707e+00, -2.0414e+01, -2.2064e+01, -2.1908e+01, -2.7309e+01,\n","         -2.1767e+01, -1.9543e+01, -3.2801e-04, -2.3023e+01, -2.1809e+01,\n","         -1.3977e+01, -1.8474e+01, -9.7883e+00, -1.1413e+01, -2.2579e+01,\n","         -1.6810e+01, -2.0929e+01, -1.4912e+01, -2.4918e+01, -1.8384e+01,\n","         -1.4762e+01, -1.8728e+01, -1.2933e+01, -1.7240e+01, -1.3976e+01,\n","         -2.3516e+01],\n","        [-1.1197e+01, -3.0033e+00, -7.6283e+00, -1.3242e+01, -5.3838e+00,\n","         -8.8140e+00, -5.6774e-02, -1.5548e+01, -1.5178e+01, -1.1705e+01,\n","         -1.6261e+01, -1.4476e+01, -1.9243e+01, -2.0091e+01, -8.9123e+00,\n","         -1.3849e+01, -9.3568e+00, -1.5872e+01, -9.3214e+00, -1.6155e+01,\n","         -1.6020e+01, -1.7272e+01, -1.6431e+01, -2.2703e+01, -1.4684e+01,\n","         -1.1580e+01]], device='cuda:0')\n","Predicted classes: tensor([15,  8, 14,  7,  6], device='cuda:0')\n","Target classes: tensor([15,  8, 14,  7,  6], device='cuda:0')\n","\n","Test set: Average loss: 0.001592, Total sum loss: 0.471243, Accuracy: 36915/37792 (98%)\n","\n","Class A: 1229/1247 (99%)\n","Class B: 802/816 (98%)\n","Class C: 1927/1965 (98%)\n","Class D: 818/868 (94%)\n","Class E: 1009/1024 (99%)\n","Class F: 1837/1869 (98%)\n","Class G: 505/519 (97%)\n","Class H: 604/621 (97%)\n","Class I: 2377/2410 (99%)\n","Class J: 728/754 (97%)\n","Class K: 487/502 (97%)\n","Class L: 965/987 (98%)\n","Class M: 1745/1774 (98%)\n","Class N: 1583/1622 (98%)\n","Class O: 4883/5064 (96%)\n","Class P: 1586/1615 (98%)\n","Class Q: 517/536 (96%)\n","Class R: 974/992 (98%)\n","Class S: 4190/4228 (99%)\n","Class T: 1917/1932 (99%)\n","Class U: 2494/2598 (96%)\n","Class V: 870/904 (96%)\n","Class W: 913/938 (97%)\n","Class X: 549/560 (98%)\n","Class Y: 892/924 (97%)\n","Class Z: 514/523 (98%)\n","Train Epoch: 15 [0/151166 (0%)]\tLoss: 0.000597\n","Train Epoch: 15 [640/151166 (0%)]\tLoss: 0.000227\n","Train Epoch: 15 [1280/151166 (1%)]\tLoss: 0.001440\n","Train Epoch: 15 [1920/151166 (1%)]\tLoss: 0.000587\n","Train Epoch: 15 [2560/151166 (2%)]\tLoss: 0.000445\n","Train Epoch: 15 [3200/151166 (2%)]\tLoss: 0.000426\n","Train Epoch: 15 [3840/151166 (3%)]\tLoss: 0.000741\n","Train Epoch: 15 [4480/151166 (3%)]\tLoss: 0.000362\n","Train Epoch: 15 [5120/151166 (3%)]\tLoss: 0.000173\n","Train Epoch: 15 [5760/151166 (4%)]\tLoss: 0.000944\n","Train Epoch: 15 [6400/151166 (4%)]\tLoss: 0.000090\n","Train Epoch: 15 [7040/151166 (5%)]\tLoss: 0.003197\n","Train Epoch: 15 [7680/151166 (5%)]\tLoss: 0.000681\n","Train Epoch: 15 [8320/151166 (6%)]\tLoss: 0.002601\n","Train Epoch: 15 [8960/151166 (6%)]\tLoss: 0.001311\n","Train Epoch: 15 [9600/151166 (6%)]\tLoss: 0.000753\n","Train Epoch: 15 [10240/151166 (7%)]\tLoss: 0.000338\n","Train Epoch: 15 [10880/151166 (7%)]\tLoss: 0.000951\n","Train Epoch: 15 [11520/151166 (8%)]\tLoss: 0.002173\n","Train Epoch: 15 [12160/151166 (8%)]\tLoss: 0.001968\n","Train Epoch: 15 [12800/151166 (8%)]\tLoss: 0.001176\n","Train Epoch: 15 [13440/151166 (9%)]\tLoss: 0.000988\n","Train Epoch: 15 [14080/151166 (9%)]\tLoss: 0.000855\n","Train Epoch: 15 [14720/151166 (10%)]\tLoss: 0.000881\n","Train Epoch: 15 [15360/151166 (10%)]\tLoss: 0.001450\n","Train Epoch: 15 [16000/151166 (11%)]\tLoss: 0.000252\n","Train Epoch: 15 [16640/151166 (11%)]\tLoss: 0.002051\n","Train Epoch: 15 [17280/151166 (11%)]\tLoss: 0.000594\n","Train Epoch: 15 [17920/151166 (12%)]\tLoss: 0.000313\n","Train Epoch: 15 [18560/151166 (12%)]\tLoss: 0.000332\n","Train Epoch: 15 [19200/151166 (13%)]\tLoss: 0.000536\n","Train Epoch: 15 [19840/151166 (13%)]\tLoss: 0.002171\n","Train Epoch: 15 [20480/151166 (14%)]\tLoss: 0.000527\n","Train Epoch: 15 [21120/151166 (14%)]\tLoss: 0.000938\n","Train Epoch: 15 [21760/151166 (14%)]\tLoss: 0.000494\n","Train Epoch: 15 [22400/151166 (15%)]\tLoss: 0.000160\n","Train Epoch: 15 [23040/151166 (15%)]\tLoss: 0.000320\n","Train Epoch: 15 [23680/151166 (16%)]\tLoss: 0.001092\n","Train Epoch: 15 [24320/151166 (16%)]\tLoss: 0.000332\n","Train Epoch: 15 [24960/151166 (17%)]\tLoss: 0.000498\n","Train Epoch: 15 [25600/151166 (17%)]\tLoss: 0.001817\n","Train Epoch: 15 [26240/151166 (17%)]\tLoss: 0.000093\n","Train Epoch: 15 [26880/151166 (18%)]\tLoss: 0.000806\n","Train Epoch: 15 [27520/151166 (18%)]\tLoss: 0.001007\n","Train Epoch: 15 [28160/151166 (19%)]\tLoss: 0.000247\n","Train Epoch: 15 [28800/151166 (19%)]\tLoss: 0.000144\n","Train Epoch: 15 [29440/151166 (19%)]\tLoss: 0.001375\n","Train Epoch: 15 [30080/151166 (20%)]\tLoss: 0.000314\n","Train Epoch: 15 [30720/151166 (20%)]\tLoss: 0.000441\n","Train Epoch: 15 [31360/151166 (21%)]\tLoss: 0.000388\n","Train Epoch: 15 [32000/151166 (21%)]\tLoss: 0.000502\n","Train Epoch: 15 [32640/151166 (22%)]\tLoss: 0.000149\n","Train Epoch: 15 [33280/151166 (22%)]\tLoss: 0.000688\n","Train Epoch: 15 [33920/151166 (22%)]\tLoss: 0.000618\n","Train Epoch: 15 [34560/151166 (23%)]\tLoss: 0.000406\n","Train Epoch: 15 [35200/151166 (23%)]\tLoss: 0.002923\n","Train Epoch: 15 [35840/151166 (24%)]\tLoss: 0.000209\n","Train Epoch: 15 [36480/151166 (24%)]\tLoss: 0.001721\n","Train Epoch: 15 [37120/151166 (25%)]\tLoss: 0.000866\n","Train Epoch: 15 [37760/151166 (25%)]\tLoss: 0.000385\n","Train Epoch: 15 [38400/151166 (25%)]\tLoss: 0.000437\n","Train Epoch: 15 [39040/151166 (26%)]\tLoss: 0.000625\n","Train Epoch: 15 [39680/151166 (26%)]\tLoss: 0.000571\n","Train Epoch: 15 [40320/151166 (27%)]\tLoss: 0.001505\n","Train Epoch: 15 [40960/151166 (27%)]\tLoss: 0.000840\n","Train Epoch: 15 [41600/151166 (28%)]\tLoss: 0.001032\n","Train Epoch: 15 [42240/151166 (28%)]\tLoss: 0.000833\n","Train Epoch: 15 [42880/151166 (28%)]\tLoss: 0.000378\n","Train Epoch: 15 [43520/151166 (29%)]\tLoss: 0.000109\n","Train Epoch: 15 [44160/151166 (29%)]\tLoss: 0.001468\n","Train Epoch: 15 [44800/151166 (30%)]\tLoss: 0.000097\n","Train Epoch: 15 [45440/151166 (30%)]\tLoss: 0.002405\n","Train Epoch: 15 [46080/151166 (30%)]\tLoss: 0.000434\n","Train Epoch: 15 [46720/151166 (31%)]\tLoss: 0.000187\n","Train Epoch: 15 [47360/151166 (31%)]\tLoss: 0.000463\n","Train Epoch: 15 [48000/151166 (32%)]\tLoss: 0.000330\n","Train Epoch: 15 [48640/151166 (32%)]\tLoss: 0.000756\n","Train Epoch: 15 [49280/151166 (33%)]\tLoss: 0.001416\n","Train Epoch: 15 [49920/151166 (33%)]\tLoss: 0.000710\n","Train Epoch: 15 [50560/151166 (33%)]\tLoss: 0.000157\n","Train Epoch: 15 [51200/151166 (34%)]\tLoss: 0.000700\n","Train Epoch: 15 [51840/151166 (34%)]\tLoss: 0.001344\n","Train Epoch: 15 [52480/151166 (35%)]\tLoss: 0.000546\n","Train Epoch: 15 [53120/151166 (35%)]\tLoss: 0.000921\n","Train Epoch: 15 [53760/151166 (36%)]\tLoss: 0.000521\n","Train Epoch: 15 [54400/151166 (36%)]\tLoss: 0.001031\n","Train Epoch: 15 [55040/151166 (36%)]\tLoss: 0.001701\n","Train Epoch: 15 [55680/151166 (37%)]\tLoss: 0.000307\n","Train Epoch: 15 [56320/151166 (37%)]\tLoss: 0.000124\n","Train Epoch: 15 [56960/151166 (38%)]\tLoss: 0.000299\n","Train Epoch: 15 [57600/151166 (38%)]\tLoss: 0.000523\n","Train Epoch: 15 [58240/151166 (39%)]\tLoss: 0.001026\n","Train Epoch: 15 [58880/151166 (39%)]\tLoss: 0.000316\n","Train Epoch: 15 [59520/151166 (39%)]\tLoss: 0.000395\n","Train Epoch: 15 [60160/151166 (40%)]\tLoss: 0.001374\n","Train Epoch: 15 [60800/151166 (40%)]\tLoss: 0.000466\n","Train Epoch: 15 [61440/151166 (41%)]\tLoss: 0.000223\n","Train Epoch: 15 [62080/151166 (41%)]\tLoss: 0.000283\n","Train Epoch: 15 [62720/151166 (41%)]\tLoss: 0.001796\n","Train Epoch: 15 [63360/151166 (42%)]\tLoss: 0.000668\n","Train Epoch: 15 [64000/151166 (42%)]\tLoss: 0.000112\n","Train Epoch: 15 [64640/151166 (43%)]\tLoss: 0.000750\n","Train Epoch: 15 [65280/151166 (43%)]\tLoss: 0.002326\n","Train Epoch: 15 [65920/151166 (44%)]\tLoss: 0.000278\n","Train Epoch: 15 [66560/151166 (44%)]\tLoss: 0.000923\n","Train Epoch: 15 [67200/151166 (44%)]\tLoss: 0.000500\n","Train Epoch: 15 [67840/151166 (45%)]\tLoss: 0.001239\n","Train Epoch: 15 [68480/151166 (45%)]\tLoss: 0.000179\n","Train Epoch: 15 [69120/151166 (46%)]\tLoss: 0.001042\n","Train Epoch: 15 [69760/151166 (46%)]\tLoss: 0.000540\n","Train Epoch: 15 [70400/151166 (47%)]\tLoss: 0.000423\n","Train Epoch: 15 [71040/151166 (47%)]\tLoss: 0.000156\n","Train Epoch: 15 [71680/151166 (47%)]\tLoss: 0.000240\n","Train Epoch: 15 [72320/151166 (48%)]\tLoss: 0.001242\n","Train Epoch: 15 [72960/151166 (48%)]\tLoss: 0.001401\n","Train Epoch: 15 [73600/151166 (49%)]\tLoss: 0.000818\n","Train Epoch: 15 [74240/151166 (49%)]\tLoss: 0.000962\n","Train Epoch: 15 [74880/151166 (50%)]\tLoss: 0.001838\n","Train Epoch: 15 [75520/151166 (50%)]\tLoss: 0.001200\n","Train Epoch: 15 [76160/151166 (50%)]\tLoss: 0.000168\n","Train Epoch: 15 [76800/151166 (51%)]\tLoss: 0.001162\n","Train Epoch: 15 [77440/151166 (51%)]\tLoss: 0.000371\n","Train Epoch: 15 [78080/151166 (52%)]\tLoss: 0.000360\n","Train Epoch: 15 [78720/151166 (52%)]\tLoss: 0.000379\n","Train Epoch: 15 [79360/151166 (52%)]\tLoss: 0.000930\n","Train Epoch: 15 [80000/151166 (53%)]\tLoss: 0.000272\n","Train Epoch: 15 [80640/151166 (53%)]\tLoss: 0.000724\n","Train Epoch: 15 [81280/151166 (54%)]\tLoss: 0.000262\n","Train Epoch: 15 [81920/151166 (54%)]\tLoss: 0.002297\n","Train Epoch: 15 [82560/151166 (55%)]\tLoss: 0.000418\n","Train Epoch: 15 [83200/151166 (55%)]\tLoss: 0.000201\n","Train Epoch: 15 [83840/151166 (55%)]\tLoss: 0.002315\n","Train Epoch: 15 [84480/151166 (56%)]\tLoss: 0.001044\n","Train Epoch: 15 [85120/151166 (56%)]\tLoss: 0.000485\n","Train Epoch: 15 [85760/151166 (57%)]\tLoss: 0.000389\n","Train Epoch: 15 [86400/151166 (57%)]\tLoss: 0.000579\n","Train Epoch: 15 [87040/151166 (58%)]\tLoss: 0.001965\n","Train Epoch: 15 [87680/151166 (58%)]\tLoss: 0.000239\n","Train Epoch: 15 [88320/151166 (58%)]\tLoss: 0.000509\n","Train Epoch: 15 [88960/151166 (59%)]\tLoss: 0.001567\n","Train Epoch: 15 [89600/151166 (59%)]\tLoss: 0.000861\n","Train Epoch: 15 [90240/151166 (60%)]\tLoss: 0.000423\n","Train Epoch: 15 [90880/151166 (60%)]\tLoss: 0.000165\n","Train Epoch: 15 [91520/151166 (61%)]\tLoss: 0.000044\n","Train Epoch: 15 [92160/151166 (61%)]\tLoss: 0.000392\n","Train Epoch: 15 [92800/151166 (61%)]\tLoss: 0.001638\n","Train Epoch: 15 [93440/151166 (62%)]\tLoss: 0.000458\n","Train Epoch: 15 [94080/151166 (62%)]\tLoss: 0.000332\n","Train Epoch: 15 [94720/151166 (63%)]\tLoss: 0.000597\n","Train Epoch: 15 [95360/151166 (63%)]\tLoss: 0.001112\n","Train Epoch: 15 [96000/151166 (64%)]\tLoss: 0.000983\n","Train Epoch: 15 [96640/151166 (64%)]\tLoss: 0.000444\n","Train Epoch: 15 [97280/151166 (64%)]\tLoss: 0.000658\n","Train Epoch: 15 [97920/151166 (65%)]\tLoss: 0.000707\n","Train Epoch: 15 [98560/151166 (65%)]\tLoss: 0.000517\n","Train Epoch: 15 [99200/151166 (66%)]\tLoss: 0.002064\n","Train Epoch: 15 [99840/151166 (66%)]\tLoss: 0.001328\n","Train Epoch: 15 [100480/151166 (66%)]\tLoss: 0.000178\n","Train Epoch: 15 [101120/151166 (67%)]\tLoss: 0.000186\n","Train Epoch: 15 [101760/151166 (67%)]\tLoss: 0.000324\n","Train Epoch: 15 [102400/151166 (68%)]\tLoss: 0.000182\n","Train Epoch: 15 [103040/151166 (68%)]\tLoss: 0.000163\n","Train Epoch: 15 [103680/151166 (69%)]\tLoss: 0.001534\n","Train Epoch: 15 [104320/151166 (69%)]\tLoss: 0.000389\n","Train Epoch: 15 [104960/151166 (69%)]\tLoss: 0.000938\n","Train Epoch: 15 [105600/151166 (70%)]\tLoss: 0.000993\n","Train Epoch: 15 [106240/151166 (70%)]\tLoss: 0.000249\n","Train Epoch: 15 [106880/151166 (71%)]\tLoss: 0.000897\n","Train Epoch: 15 [107520/151166 (71%)]\tLoss: 0.000685\n","Train Epoch: 15 [108160/151166 (72%)]\tLoss: 0.002762\n","Train Epoch: 15 [108800/151166 (72%)]\tLoss: 0.000242\n","Train Epoch: 15 [109440/151166 (72%)]\tLoss: 0.000913\n","Train Epoch: 15 [110080/151166 (73%)]\tLoss: 0.000111\n","Train Epoch: 15 [110720/151166 (73%)]\tLoss: 0.000356\n","Train Epoch: 15 [111360/151166 (74%)]\tLoss: 0.001636\n","Train Epoch: 15 [112000/151166 (74%)]\tLoss: 0.000320\n","Train Epoch: 15 [112640/151166 (75%)]\tLoss: 0.000431\n","Train Epoch: 15 [113280/151166 (75%)]\tLoss: 0.000856\n","Train Epoch: 15 [113920/151166 (75%)]\tLoss: 0.000412\n","Train Epoch: 15 [114560/151166 (76%)]\tLoss: 0.000139\n","Train Epoch: 15 [115200/151166 (76%)]\tLoss: 0.000088\n","Train Epoch: 15 [115840/151166 (77%)]\tLoss: 0.001020\n","Train Epoch: 15 [116480/151166 (77%)]\tLoss: 0.001009\n","Train Epoch: 15 [117120/151166 (77%)]\tLoss: 0.000240\n","Train Epoch: 15 [117760/151166 (78%)]\tLoss: 0.000797\n","Train Epoch: 15 [118400/151166 (78%)]\tLoss: 0.001282\n","Train Epoch: 15 [119040/151166 (79%)]\tLoss: 0.000238\n","Train Epoch: 15 [119680/151166 (79%)]\tLoss: 0.000604\n","Train Epoch: 15 [120320/151166 (80%)]\tLoss: 0.000765\n","Train Epoch: 15 [120960/151166 (80%)]\tLoss: 0.000592\n","Train Epoch: 15 [121600/151166 (80%)]\tLoss: 0.000552\n","Train Epoch: 15 [122240/151166 (81%)]\tLoss: 0.002181\n","Train Epoch: 15 [122880/151166 (81%)]\tLoss: 0.000562\n","Train Epoch: 15 [123520/151166 (82%)]\tLoss: 0.000681\n","Train Epoch: 15 [124160/151166 (82%)]\tLoss: 0.000448\n","Train Epoch: 15 [124800/151166 (83%)]\tLoss: 0.001346\n","Train Epoch: 15 [125440/151166 (83%)]\tLoss: 0.000163\n","Train Epoch: 15 [126080/151166 (83%)]\tLoss: 0.001085\n","Train Epoch: 15 [126720/151166 (84%)]\tLoss: 0.005443\n","Train Epoch: 15 [127360/151166 (84%)]\tLoss: 0.001043\n","Train Epoch: 15 [128000/151166 (85%)]\tLoss: 0.003103\n","Train Epoch: 15 [128640/151166 (85%)]\tLoss: 0.000987\n","Train Epoch: 15 [129280/151166 (86%)]\tLoss: 0.001304\n","Train Epoch: 15 [129920/151166 (86%)]\tLoss: 0.001663\n","Train Epoch: 15 [130560/151166 (86%)]\tLoss: 0.001976\n","Train Epoch: 15 [131200/151166 (87%)]\tLoss: 0.001238\n","Train Epoch: 15 [131840/151166 (87%)]\tLoss: 0.000430\n","Train Epoch: 15 [132480/151166 (88%)]\tLoss: 0.000177\n","Train Epoch: 15 [133120/151166 (88%)]\tLoss: 0.000180\n","Train Epoch: 15 [133760/151166 (88%)]\tLoss: 0.000465\n","Train Epoch: 15 [134400/151166 (89%)]\tLoss: 0.000654\n","Train Epoch: 15 [135040/151166 (89%)]\tLoss: 0.000464\n","Train Epoch: 15 [135680/151166 (90%)]\tLoss: 0.001015\n","Train Epoch: 15 [136320/151166 (90%)]\tLoss: 0.001356\n","Train Epoch: 15 [136960/151166 (91%)]\tLoss: 0.001781\n","Train Epoch: 15 [137600/151166 (91%)]\tLoss: 0.000677\n","Train Epoch: 15 [138240/151166 (91%)]\tLoss: 0.000503\n","Train Epoch: 15 [138880/151166 (92%)]\tLoss: 0.001471\n","Train Epoch: 15 [139520/151166 (92%)]\tLoss: 0.000165\n","Train Epoch: 15 [140160/151166 (93%)]\tLoss: 0.000458\n","Train Epoch: 15 [140800/151166 (93%)]\tLoss: 0.000468\n","Train Epoch: 15 [141440/151166 (94%)]\tLoss: 0.000218\n","Train Epoch: 15 [142080/151166 (94%)]\tLoss: 0.000356\n","Train Epoch: 15 [142720/151166 (94%)]\tLoss: 0.001077\n","Train Epoch: 15 [143360/151166 (95%)]\tLoss: 0.000390\n","Train Epoch: 15 [144000/151166 (95%)]\tLoss: 0.002423\n","Train Epoch: 15 [144640/151166 (96%)]\tLoss: 0.002608\n","Train Epoch: 15 [145280/151166 (96%)]\tLoss: 0.002073\n","Train Epoch: 15 [145920/151166 (97%)]\tLoss: 0.000547\n","Train Epoch: 15 [146560/151166 (97%)]\tLoss: 0.001610\n","Train Epoch: 15 [147200/151166 (97%)]\tLoss: 0.002109\n","Train Epoch: 15 [147840/151166 (98%)]\tLoss: 0.001320\n","Train Epoch: 15 [148480/151166 (98%)]\tLoss: 0.000225\n","Train Epoch: 15 [149120/151166 (99%)]\tLoss: 0.001387\n","Train Epoch: 15 [149760/151166 (99%)]\tLoss: 0.000509\n","Train Epoch: 15 [150400/151166 (99%)]\tLoss: 0.000351\n","Train Epoch: 15 [151040/151166 (100%)]\tLoss: 0.000701\n","Sample outputs (log probs): tensor([[-1.8893e+01, -2.2711e+01, -2.1432e+01, -1.7991e+01, -2.7312e+01,\n","         -1.1106e+01, -2.4994e+01, -2.5659e+01, -2.4430e+01, -2.9301e+01,\n","         -3.0312e+01, -3.1827e+01, -2.9065e+01, -2.2820e+01, -2.2712e+01,\n","         -1.5497e-05, -1.5220e+01, -1.6079e+01, -2.3285e+01, -1.5828e+01,\n","         -3.0707e+01, -2.3512e+01, -2.8307e+01, -3.2630e+01, -1.9110e+01,\n","         -2.6876e+01],\n","        [-1.0451e+01, -1.7244e+01, -1.4187e+01, -1.8828e+01, -1.4867e+01,\n","         -5.6167e-03, -1.2796e+01, -1.8550e+01, -1.5769e+01, -1.8437e+01,\n","         -2.0398e+01, -2.0089e+01, -2.6370e+01, -1.9405e+01, -1.9030e+01,\n","         -5.1923e+00, -1.2627e+01, -1.3485e+01, -1.2580e+01, -1.4021e+01,\n","         -2.5783e+01, -1.9296e+01, -2.3265e+01, -2.4660e+01, -1.8202e+01,\n","         -2.1719e+01],\n","        [-2.0751e+01, -1.4986e+01, -1.1125e+01, -8.2977e+00, -2.3456e+01,\n","         -1.9539e+01, -1.6265e+01, -1.1936e+01, -9.7273e+00, -4.7748e+00,\n","         -2.1168e+01, -1.0978e+01, -1.5905e+01, -7.8108e+00, -7.0863e+00,\n","         -1.3401e+01, -1.3256e+01, -2.2949e+01, -1.6672e+01, -1.3885e+01,\n","         -4.6328e-02, -3.3461e+00, -1.1768e+01, -1.7903e+01, -1.1711e+01,\n","         -1.9567e+01],\n","        [-1.3119e+01, -2.2295e+01, -2.6254e+01, -2.1991e+01, -3.2199e+01,\n","         -2.9843e+01, -2.3741e+01, -1.0844e+01, -2.7723e+01, -3.0121e+01,\n","         -1.3806e+01, -2.4838e+01, -1.7773e-04, -8.7730e+00, -2.4103e+01,\n","         -2.2154e+01, -2.7605e+01, -1.5426e+01, -3.0532e+01, -2.3503e+01,\n","         -1.8613e+01, -2.2440e+01, -1.8526e+01, -2.1234e+01, -2.2059e+01,\n","         -3.1182e+01],\n","        [-9.3498e+00, -1.8570e+01, -1.2260e+01, -1.2994e+01, -1.4831e+01,\n","         -8.1401e+00, -1.3221e+01, -9.6545e+00, -2.0372e-02, -9.2459e+00,\n","         -7.3703e+00, -4.1448e+00, -1.4620e+01, -8.2424e+00, -1.5563e+01,\n","         -9.6381e+00, -1.5426e+01, -1.4525e+01, -1.1526e+01, -7.4116e+00,\n","         -1.0723e+01, -1.0085e+01, -1.2423e+01, -6.4295e+00, -7.5687e+00,\n","         -1.3935e+01]], device='cuda:0')\n","Predicted classes: tensor([15,  5, 20, 12,  8], device='cuda:0')\n","Target classes: tensor([15,  5, 20, 12,  8], device='cuda:0')\n","\n","Test set: Average loss: 0.001576, Total sum loss: 0.466570, Accuracy: 36909/37792 (98%)\n","\n","Class A: 1229/1247 (99%)\n","Class B: 802/816 (98%)\n","Class C: 1922/1965 (98%)\n","Class D: 821/868 (95%)\n","Class E: 1006/1024 (98%)\n","Class F: 1826/1869 (98%)\n","Class G: 505/519 (97%)\n","Class H: 601/621 (97%)\n","Class I: 2378/2410 (99%)\n","Class J: 735/754 (97%)\n","Class K: 489/502 (97%)\n","Class L: 968/987 (98%)\n","Class M: 1748/1774 (99%)\n","Class N: 1592/1622 (98%)\n","Class O: 4874/5064 (96%)\n","Class P: 1588/1615 (98%)\n","Class Q: 520/536 (97%)\n","Class R: 971/992 (98%)\n","Class S: 4177/4228 (99%)\n","Class T: 1916/1932 (99%)\n","Class U: 2506/2598 (96%)\n","Class V: 866/904 (96%)\n","Class W: 914/938 (97%)\n","Class X: 549/560 (98%)\n","Class Y: 892/924 (97%)\n","Class Z: 514/523 (98%)\n","Model saved with new best test loss: 0.0016 \n","\n","Train Epoch: 16 [0/151166 (0%)]\tLoss: 0.000173\n","Train Epoch: 16 [640/151166 (0%)]\tLoss: 0.000327\n","Train Epoch: 16 [1280/151166 (1%)]\tLoss: 0.000789\n","Train Epoch: 16 [1920/151166 (1%)]\tLoss: 0.000114\n","Train Epoch: 16 [2560/151166 (2%)]\tLoss: 0.000539\n","Train Epoch: 16 [3200/151166 (2%)]\tLoss: 0.000998\n","Train Epoch: 16 [3840/151166 (3%)]\tLoss: 0.000102\n","Train Epoch: 16 [4480/151166 (3%)]\tLoss: 0.000345\n","Train Epoch: 16 [5120/151166 (3%)]\tLoss: 0.000548\n","Train Epoch: 16 [5760/151166 (4%)]\tLoss: 0.000430\n","Train Epoch: 16 [6400/151166 (4%)]\tLoss: 0.000177\n","Train Epoch: 16 [7040/151166 (5%)]\tLoss: 0.000776\n","Train Epoch: 16 [7680/151166 (5%)]\tLoss: 0.000486\n","Train Epoch: 16 [8320/151166 (6%)]\tLoss: 0.007150\n","Train Epoch: 16 [8960/151166 (6%)]\tLoss: 0.000260\n","Train Epoch: 16 [9600/151166 (6%)]\tLoss: 0.000345\n","Train Epoch: 16 [10240/151166 (7%)]\tLoss: 0.000979\n","Train Epoch: 16 [10880/151166 (7%)]\tLoss: 0.000432\n","Train Epoch: 16 [11520/151166 (8%)]\tLoss: 0.000972\n","Train Epoch: 16 [12160/151166 (8%)]\tLoss: 0.000405\n","Train Epoch: 16 [12800/151166 (8%)]\tLoss: 0.000179\n","Train Epoch: 16 [13440/151166 (9%)]\tLoss: 0.000939\n","Train Epoch: 16 [14080/151166 (9%)]\tLoss: 0.000330\n","Train Epoch: 16 [14720/151166 (10%)]\tLoss: 0.000791\n","Train Epoch: 16 [15360/151166 (10%)]\tLoss: 0.001337\n","Train Epoch: 16 [16000/151166 (11%)]\tLoss: 0.000220\n","Train Epoch: 16 [16640/151166 (11%)]\tLoss: 0.000724\n","Train Epoch: 16 [17280/151166 (11%)]\tLoss: 0.000405\n","Train Epoch: 16 [17920/151166 (12%)]\tLoss: 0.000195\n","Train Epoch: 16 [18560/151166 (12%)]\tLoss: 0.000850\n","Train Epoch: 16 [19200/151166 (13%)]\tLoss: 0.000121\n","Train Epoch: 16 [19840/151166 (13%)]\tLoss: 0.001179\n","Train Epoch: 16 [20480/151166 (14%)]\tLoss: 0.000664\n","Train Epoch: 16 [21120/151166 (14%)]\tLoss: 0.000134\n","Train Epoch: 16 [21760/151166 (14%)]\tLoss: 0.000264\n","Train Epoch: 16 [22400/151166 (15%)]\tLoss: 0.000372\n","Train Epoch: 16 [23040/151166 (15%)]\tLoss: 0.001640\n","Train Epoch: 16 [23680/151166 (16%)]\tLoss: 0.000158\n","Train Epoch: 16 [24320/151166 (16%)]\tLoss: 0.000261\n","Train Epoch: 16 [24960/151166 (17%)]\tLoss: 0.000607\n","Train Epoch: 16 [25600/151166 (17%)]\tLoss: 0.000062\n","Train Epoch: 16 [26240/151166 (17%)]\tLoss: 0.002376\n","Train Epoch: 16 [26880/151166 (18%)]\tLoss: 0.000274\n","Train Epoch: 16 [27520/151166 (18%)]\tLoss: 0.000268\n","Train Epoch: 16 [28160/151166 (19%)]\tLoss: 0.000957\n","Train Epoch: 16 [28800/151166 (19%)]\tLoss: 0.000199\n","Train Epoch: 16 [29440/151166 (19%)]\tLoss: 0.000249\n","Train Epoch: 16 [30080/151166 (20%)]\tLoss: 0.001055\n","Train Epoch: 16 [30720/151166 (20%)]\tLoss: 0.001009\n","Train Epoch: 16 [31360/151166 (21%)]\tLoss: 0.000074\n","Train Epoch: 16 [32000/151166 (21%)]\tLoss: 0.000297\n","Train Epoch: 16 [32640/151166 (22%)]\tLoss: 0.000508\n","Train Epoch: 16 [33280/151166 (22%)]\tLoss: 0.002664\n","Train Epoch: 16 [33920/151166 (22%)]\tLoss: 0.001204\n","Train Epoch: 16 [34560/151166 (23%)]\tLoss: 0.001206\n","Train Epoch: 16 [35200/151166 (23%)]\tLoss: 0.000405\n","Train Epoch: 16 [35840/151166 (24%)]\tLoss: 0.000616\n","Train Epoch: 16 [36480/151166 (24%)]\tLoss: 0.000037\n","Train Epoch: 16 [37120/151166 (25%)]\tLoss: 0.001225\n","Train Epoch: 16 [37760/151166 (25%)]\tLoss: 0.001184\n","Train Epoch: 16 [38400/151166 (25%)]\tLoss: 0.000522\n","Train Epoch: 16 [39040/151166 (26%)]\tLoss: 0.002001\n","Train Epoch: 16 [39680/151166 (26%)]\tLoss: 0.000490\n","Train Epoch: 16 [40320/151166 (27%)]\tLoss: 0.000643\n","Train Epoch: 16 [40960/151166 (27%)]\tLoss: 0.000221\n","Train Epoch: 16 [41600/151166 (28%)]\tLoss: 0.000776\n","Train Epoch: 16 [42240/151166 (28%)]\tLoss: 0.001590\n","Train Epoch: 16 [42880/151166 (28%)]\tLoss: 0.000409\n","Train Epoch: 16 [43520/151166 (29%)]\tLoss: 0.000208\n","Train Epoch: 16 [44160/151166 (29%)]\tLoss: 0.000427\n","Train Epoch: 16 [44800/151166 (30%)]\tLoss: 0.000803\n","Train Epoch: 16 [45440/151166 (30%)]\tLoss: 0.000490\n","Train Epoch: 16 [46080/151166 (30%)]\tLoss: 0.000391\n","Train Epoch: 16 [46720/151166 (31%)]\tLoss: 0.000125\n","Train Epoch: 16 [47360/151166 (31%)]\tLoss: 0.000176\n","Train Epoch: 16 [48000/151166 (32%)]\tLoss: 0.000398\n","Train Epoch: 16 [48640/151166 (32%)]\tLoss: 0.000199\n","Train Epoch: 16 [49280/151166 (33%)]\tLoss: 0.000634\n","Train Epoch: 16 [49920/151166 (33%)]\tLoss: 0.000560\n","Train Epoch: 16 [50560/151166 (33%)]\tLoss: 0.000259\n","Train Epoch: 16 [51200/151166 (34%)]\tLoss: 0.002129\n","Train Epoch: 16 [51840/151166 (34%)]\tLoss: 0.001291\n","Train Epoch: 16 [52480/151166 (35%)]\tLoss: 0.000125\n","Train Epoch: 16 [53120/151166 (35%)]\tLoss: 0.000546\n","Train Epoch: 16 [53760/151166 (36%)]\tLoss: 0.000612\n","Train Epoch: 16 [54400/151166 (36%)]\tLoss: 0.000377\n","Train Epoch: 16 [55040/151166 (36%)]\tLoss: 0.000203\n","Train Epoch: 16 [55680/151166 (37%)]\tLoss: 0.000941\n","Train Epoch: 16 [56320/151166 (37%)]\tLoss: 0.000176\n","Train Epoch: 16 [56960/151166 (38%)]\tLoss: 0.000218\n","Train Epoch: 16 [57600/151166 (38%)]\tLoss: 0.000457\n","Train Epoch: 16 [58240/151166 (39%)]\tLoss: 0.000309\n","Train Epoch: 16 [58880/151166 (39%)]\tLoss: 0.000302\n","Train Epoch: 16 [59520/151166 (39%)]\tLoss: 0.001839\n","Train Epoch: 16 [60160/151166 (40%)]\tLoss: 0.001050\n","Train Epoch: 16 [60800/151166 (40%)]\tLoss: 0.000421\n","Train Epoch: 16 [61440/151166 (41%)]\tLoss: 0.001983\n","Train Epoch: 16 [62080/151166 (41%)]\tLoss: 0.000670\n","Train Epoch: 16 [62720/151166 (41%)]\tLoss: 0.000551\n","Train Epoch: 16 [63360/151166 (42%)]\tLoss: 0.000370\n","Train Epoch: 16 [64000/151166 (42%)]\tLoss: 0.000220\n","Train Epoch: 16 [64640/151166 (43%)]\tLoss: 0.000123\n","Train Epoch: 16 [65280/151166 (43%)]\tLoss: 0.000228\n","Train Epoch: 16 [65920/151166 (44%)]\tLoss: 0.000166\n","Train Epoch: 16 [66560/151166 (44%)]\tLoss: 0.001381\n","Train Epoch: 16 [67200/151166 (44%)]\tLoss: 0.000706\n","Train Epoch: 16 [67840/151166 (45%)]\tLoss: 0.000529\n","Train Epoch: 16 [68480/151166 (45%)]\tLoss: 0.000952\n","Train Epoch: 16 [69120/151166 (46%)]\tLoss: 0.000206\n","Train Epoch: 16 [69760/151166 (46%)]\tLoss: 0.001003\n","Train Epoch: 16 [70400/151166 (47%)]\tLoss: 0.001169\n","Train Epoch: 16 [71040/151166 (47%)]\tLoss: 0.000287\n","Train Epoch: 16 [71680/151166 (47%)]\tLoss: 0.000589\n","Train Epoch: 16 [72320/151166 (48%)]\tLoss: 0.001041\n","Train Epoch: 16 [72960/151166 (48%)]\tLoss: 0.000666\n","Train Epoch: 16 [73600/151166 (49%)]\tLoss: 0.000141\n","Train Epoch: 16 [74240/151166 (49%)]\tLoss: 0.000160\n","Train Epoch: 16 [74880/151166 (50%)]\tLoss: 0.002378\n","Train Epoch: 16 [75520/151166 (50%)]\tLoss: 0.000810\n","Train Epoch: 16 [76160/151166 (50%)]\tLoss: 0.000988\n","Train Epoch: 16 [76800/151166 (51%)]\tLoss: 0.000329\n","Train Epoch: 16 [77440/151166 (51%)]\tLoss: 0.001559\n","Train Epoch: 16 [78080/151166 (52%)]\tLoss: 0.000392\n","Train Epoch: 16 [78720/151166 (52%)]\tLoss: 0.001134\n","Train Epoch: 16 [79360/151166 (52%)]\tLoss: 0.002654\n","Train Epoch: 16 [80000/151166 (53%)]\tLoss: 0.000396\n","Train Epoch: 16 [80640/151166 (53%)]\tLoss: 0.000164\n","Train Epoch: 16 [81280/151166 (54%)]\tLoss: 0.000385\n","Train Epoch: 16 [81920/151166 (54%)]\tLoss: 0.000250\n","Train Epoch: 16 [82560/151166 (55%)]\tLoss: 0.000477\n","Train Epoch: 16 [83200/151166 (55%)]\tLoss: 0.000651\n","Train Epoch: 16 [83840/151166 (55%)]\tLoss: 0.000353\n","Train Epoch: 16 [84480/151166 (56%)]\tLoss: 0.000129\n","Train Epoch: 16 [85120/151166 (56%)]\tLoss: 0.000978\n","Train Epoch: 16 [85760/151166 (57%)]\tLoss: 0.002494\n","Train Epoch: 16 [86400/151166 (57%)]\tLoss: 0.000322\n","Train Epoch: 16 [87040/151166 (58%)]\tLoss: 0.000678\n","Train Epoch: 16 [87680/151166 (58%)]\tLoss: 0.001054\n","Train Epoch: 16 [88320/151166 (58%)]\tLoss: 0.000082\n","Train Epoch: 16 [88960/151166 (59%)]\tLoss: 0.000355\n","Train Epoch: 16 [89600/151166 (59%)]\tLoss: 0.000952\n","Train Epoch: 16 [90240/151166 (60%)]\tLoss: 0.000418\n","Train Epoch: 16 [90880/151166 (60%)]\tLoss: 0.000776\n","Train Epoch: 16 [91520/151166 (61%)]\tLoss: 0.000157\n","Train Epoch: 16 [92160/151166 (61%)]\tLoss: 0.001976\n","Train Epoch: 16 [92800/151166 (61%)]\tLoss: 0.000268\n","Train Epoch: 16 [93440/151166 (62%)]\tLoss: 0.001310\n","Train Epoch: 16 [94080/151166 (62%)]\tLoss: 0.000093\n","Train Epoch: 16 [94720/151166 (63%)]\tLoss: 0.000493\n","Train Epoch: 16 [95360/151166 (63%)]\tLoss: 0.000169\n","Train Epoch: 16 [96000/151166 (64%)]\tLoss: 0.000768\n","Train Epoch: 16 [96640/151166 (64%)]\tLoss: 0.000705\n","Train Epoch: 16 [97280/151166 (64%)]\tLoss: 0.000475\n","Train Epoch: 16 [97920/151166 (65%)]\tLoss: 0.000244\n","Train Epoch: 16 [98560/151166 (65%)]\tLoss: 0.000834\n","Train Epoch: 16 [99200/151166 (66%)]\tLoss: 0.000115\n","Train Epoch: 16 [99840/151166 (66%)]\tLoss: 0.000292\n","Train Epoch: 16 [100480/151166 (66%)]\tLoss: 0.000606\n","Train Epoch: 16 [101120/151166 (67%)]\tLoss: 0.000857\n","Train Epoch: 16 [101760/151166 (67%)]\tLoss: 0.000912\n","Train Epoch: 16 [102400/151166 (68%)]\tLoss: 0.000959\n","Train Epoch: 16 [103040/151166 (68%)]\tLoss: 0.000090\n","Train Epoch: 16 [103680/151166 (69%)]\tLoss: 0.000695\n","Train Epoch: 16 [104320/151166 (69%)]\tLoss: 0.000565\n","Train Epoch: 16 [104960/151166 (69%)]\tLoss: 0.002971\n","Train Epoch: 16 [105600/151166 (70%)]\tLoss: 0.000433\n","Train Epoch: 16 [106240/151166 (70%)]\tLoss: 0.000289\n","Train Epoch: 16 [106880/151166 (71%)]\tLoss: 0.002892\n","Train Epoch: 16 [107520/151166 (71%)]\tLoss: 0.000457\n","Train Epoch: 16 [108160/151166 (72%)]\tLoss: 0.001029\n","Train Epoch: 16 [108800/151166 (72%)]\tLoss: 0.001325\n","Train Epoch: 16 [109440/151166 (72%)]\tLoss: 0.001382\n","Train Epoch: 16 [110080/151166 (73%)]\tLoss: 0.000741\n","Train Epoch: 16 [110720/151166 (73%)]\tLoss: 0.000497\n","Train Epoch: 16 [111360/151166 (74%)]\tLoss: 0.000246\n","Train Epoch: 16 [112000/151166 (74%)]\tLoss: 0.000635\n","Train Epoch: 16 [112640/151166 (75%)]\tLoss: 0.000137\n","Train Epoch: 16 [113280/151166 (75%)]\tLoss: 0.002780\n","Train Epoch: 16 [113920/151166 (75%)]\tLoss: 0.000589\n","Train Epoch: 16 [114560/151166 (76%)]\tLoss: 0.000654\n","Train Epoch: 16 [115200/151166 (76%)]\tLoss: 0.000536\n","Train Epoch: 16 [115840/151166 (77%)]\tLoss: 0.000764\n","Train Epoch: 16 [116480/151166 (77%)]\tLoss: 0.000205\n","Train Epoch: 16 [117120/151166 (77%)]\tLoss: 0.000281\n","Train Epoch: 16 [117760/151166 (78%)]\tLoss: 0.000184\n","Train Epoch: 16 [118400/151166 (78%)]\tLoss: 0.002437\n","Train Epoch: 16 [119040/151166 (79%)]\tLoss: 0.000790\n","Train Epoch: 16 [119680/151166 (79%)]\tLoss: 0.000261\n","Train Epoch: 16 [120320/151166 (80%)]\tLoss: 0.000288\n","Train Epoch: 16 [120960/151166 (80%)]\tLoss: 0.001333\n","Train Epoch: 16 [121600/151166 (80%)]\tLoss: 0.000712\n","Train Epoch: 16 [122240/151166 (81%)]\tLoss: 0.000642\n","Train Epoch: 16 [122880/151166 (81%)]\tLoss: 0.000395\n","Train Epoch: 16 [123520/151166 (82%)]\tLoss: 0.000262\n","Train Epoch: 16 [124160/151166 (82%)]\tLoss: 0.000768\n","Train Epoch: 16 [124800/151166 (83%)]\tLoss: 0.000349\n","Train Epoch: 16 [125440/151166 (83%)]\tLoss: 0.001912\n","Train Epoch: 16 [126080/151166 (83%)]\tLoss: 0.001107\n","Train Epoch: 16 [126720/151166 (84%)]\tLoss: 0.000216\n","Train Epoch: 16 [127360/151166 (84%)]\tLoss: 0.000417\n","Train Epoch: 16 [128000/151166 (85%)]\tLoss: 0.000291\n","Train Epoch: 16 [128640/151166 (85%)]\tLoss: 0.001010\n","Train Epoch: 16 [129280/151166 (86%)]\tLoss: 0.000459\n","Train Epoch: 16 [129920/151166 (86%)]\tLoss: 0.000320\n","Train Epoch: 16 [130560/151166 (86%)]\tLoss: 0.001524\n","Train Epoch: 16 [131200/151166 (87%)]\tLoss: 0.000491\n","Train Epoch: 16 [131840/151166 (87%)]\tLoss: 0.000511\n","Train Epoch: 16 [132480/151166 (88%)]\tLoss: 0.000748\n","Train Epoch: 16 [133120/151166 (88%)]\tLoss: 0.000335\n","Train Epoch: 16 [133760/151166 (88%)]\tLoss: 0.000126\n","Train Epoch: 16 [134400/151166 (89%)]\tLoss: 0.001013\n","Train Epoch: 16 [135040/151166 (89%)]\tLoss: 0.000466\n","Train Epoch: 16 [135680/151166 (90%)]\tLoss: 0.000873\n","Train Epoch: 16 [136320/151166 (90%)]\tLoss: 0.001277\n","Train Epoch: 16 [136960/151166 (91%)]\tLoss: 0.000508\n","Train Epoch: 16 [137600/151166 (91%)]\tLoss: 0.000399\n","Train Epoch: 16 [138240/151166 (91%)]\tLoss: 0.000389\n","Train Epoch: 16 [138880/151166 (92%)]\tLoss: 0.000920\n","Train Epoch: 16 [139520/151166 (92%)]\tLoss: 0.001153\n","Train Epoch: 16 [140160/151166 (93%)]\tLoss: 0.000458\n","Train Epoch: 16 [140800/151166 (93%)]\tLoss: 0.000208\n","Train Epoch: 16 [141440/151166 (94%)]\tLoss: 0.000386\n","Train Epoch: 16 [142080/151166 (94%)]\tLoss: 0.000973\n","Train Epoch: 16 [142720/151166 (94%)]\tLoss: 0.002205\n","Train Epoch: 16 [143360/151166 (95%)]\tLoss: 0.000840\n","Train Epoch: 16 [144000/151166 (95%)]\tLoss: 0.000673\n","Train Epoch: 16 [144640/151166 (96%)]\tLoss: 0.002313\n","Train Epoch: 16 [145280/151166 (96%)]\tLoss: 0.000150\n","Train Epoch: 16 [145920/151166 (97%)]\tLoss: 0.000098\n","Train Epoch: 16 [146560/151166 (97%)]\tLoss: 0.000325\n","Train Epoch: 16 [147200/151166 (97%)]\tLoss: 0.001132\n","Train Epoch: 16 [147840/151166 (98%)]\tLoss: 0.000418\n","Train Epoch: 16 [148480/151166 (98%)]\tLoss: 0.000097\n","Train Epoch: 16 [149120/151166 (99%)]\tLoss: 0.000203\n","Train Epoch: 16 [149760/151166 (99%)]\tLoss: 0.000332\n","Train Epoch: 16 [150400/151166 (99%)]\tLoss: 0.000232\n","Train Epoch: 16 [151040/151166 (100%)]\tLoss: 0.000099\n","Sample outputs (log probs): tensor([[-2.6354e+01, -2.0680e+01, -1.4837e+01, -1.3384e+01, -2.4796e+01,\n","         -2.3934e+01, -1.9415e+01, -1.6677e+01, -1.2784e+01, -1.1138e+01,\n","         -2.1789e+01, -1.3699e+01, -1.5314e+01, -1.2246e+01, -1.1566e+01,\n","         -1.7665e+01, -1.9013e+01, -2.7325e+01, -2.0662e+01, -1.7014e+01,\n","         -3.4556e-03, -5.6808e+00, -1.5239e+01, -2.0653e+01, -1.2521e+01,\n","         -2.2893e+01],\n","        [-2.6382e+01, -2.7171e+01, -2.3025e+01, -2.2605e+01, -2.2243e+01,\n","         -2.2675e+01, -2.0976e+01, -1.6363e+01, -1.4019e+01, -1.9801e+01,\n","         -1.6566e+01, -1.7959e+01, -1.9106e+01, -1.4696e+01, -2.3325e+01,\n","         -1.7393e+01, -2.6676e+01, -2.7677e+01, -2.3044e+01, -1.9304e+01,\n","         -1.1576e+01, -1.3672e-04, -1.1365e+01, -1.7665e+01, -9.0760e+00,\n","         -2.8342e+01],\n","        [-1.0040e+01, -1.0387e+01, -1.8811e+01, -2.1997e+01, -1.8335e+01,\n","         -1.5862e+01, -1.6995e+01, -1.5698e+01, -2.5297e+01, -2.7412e+01,\n","         -1.5112e+01, -2.1004e+01, -1.7192e+01, -1.7554e+01, -2.4238e+01,\n","         -1.1775e+01, -1.1887e+01, -8.9761e-05, -2.1445e+01, -1.8192e+01,\n","         -2.1572e+01, -2.5050e+01, -2.1376e+01, -1.8125e+01, -2.1858e+01,\n","         -1.7059e+01],\n","        [-1.7963e+01, -1.5585e+01, -7.1904e+00, -8.9440e+00, -1.6881e+01,\n","         -1.9559e+01, -1.3947e+01, -1.4055e+01, -1.0211e+01, -3.5876e+00,\n","         -2.0675e+01, -1.0939e+01, -1.5426e+01, -9.6000e+00, -5.4942e+00,\n","         -1.4521e+01, -1.2654e+01, -1.9468e+01, -1.5164e+01, -1.4039e+01,\n","         -3.4506e-02, -6.8000e+00, -1.1848e+01, -1.9168e+01, -1.1898e+01,\n","         -1.4652e+01],\n","        [-2.1038e+01, -1.7242e+01, -1.8540e+01, -2.2131e+01, -2.1174e+01,\n","         -8.7805e+00, -2.5139e+01, -2.3186e+01, -2.3125e+01, -2.9389e+01,\n","         -2.4009e+01, -2.7760e+01, -2.5877e+01, -2.4439e+01, -2.4347e+01,\n","         -1.6950e-04, -2.0860e+01, -1.1067e+01, -2.2579e+01, -1.5604e+01,\n","         -2.9879e+01, -2.3606e+01, -3.1746e+01, -2.5578e+01, -1.6973e+01,\n","         -1.9873e+01]], device='cuda:0')\n","Predicted classes: tensor([20, 21, 17, 20, 15], device='cuda:0')\n","Target classes: tensor([20, 21, 17, 20, 15], device='cuda:0')\n","\n","Test set: Average loss: 0.001567, Total sum loss: 0.463733, Accuracy: 36966/37792 (98%)\n","\n","Class A: 1230/1247 (99%)\n","Class B: 802/816 (98%)\n","Class C: 1923/1965 (98%)\n","Class D: 809/868 (93%)\n","Class E: 1009/1024 (99%)\n","Class F: 1831/1869 (98%)\n","Class G: 507/519 (98%)\n","Class H: 602/621 (97%)\n","Class I: 2379/2410 (99%)\n","Class J: 733/754 (97%)\n","Class K: 488/502 (97%)\n","Class L: 968/987 (98%)\n","Class M: 1746/1774 (98%)\n","Class N: 1585/1622 (98%)\n","Class O: 4928/5064 (97%)\n","Class P: 1584/1615 (98%)\n","Class Q: 520/536 (97%)\n","Class R: 972/992 (98%)\n","Class S: 4193/4228 (99%)\n","Class T: 1918/1932 (99%)\n","Class U: 2517/2598 (97%)\n","Class V: 858/904 (95%)\n","Class W: 915/938 (98%)\n","Class X: 546/560 (98%)\n","Class Y: 888/924 (96%)\n","Class Z: 515/523 (98%)\n","Model saved with new best test loss: 0.0016 \n","\n","Train Epoch: 17 [0/151166 (0%)]\tLoss: 0.001343\n","Train Epoch: 17 [640/151166 (0%)]\tLoss: 0.000508\n","Train Epoch: 17 [1280/151166 (1%)]\tLoss: 0.000088\n","Train Epoch: 17 [1920/151166 (1%)]\tLoss: 0.000712\n","Train Epoch: 17 [2560/151166 (2%)]\tLoss: 0.001093\n","Train Epoch: 17 [3200/151166 (2%)]\tLoss: 0.000653\n","Train Epoch: 17 [3840/151166 (3%)]\tLoss: 0.000280\n","Train Epoch: 17 [4480/151166 (3%)]\tLoss: 0.000277\n","Train Epoch: 17 [5120/151166 (3%)]\tLoss: 0.000258\n","Train Epoch: 17 [5760/151166 (4%)]\tLoss: 0.000359\n","Train Epoch: 17 [6400/151166 (4%)]\tLoss: 0.000991\n","Train Epoch: 17 [7040/151166 (5%)]\tLoss: 0.002201\n","Train Epoch: 17 [7680/151166 (5%)]\tLoss: 0.000465\n","Train Epoch: 17 [8320/151166 (6%)]\tLoss: 0.000273\n","Train Epoch: 17 [8960/151166 (6%)]\tLoss: 0.002062\n","Train Epoch: 17 [9600/151166 (6%)]\tLoss: 0.000192\n","Train Epoch: 17 [10240/151166 (7%)]\tLoss: 0.000316\n","Train Epoch: 17 [10880/151166 (7%)]\tLoss: 0.000137\n","Train Epoch: 17 [11520/151166 (8%)]\tLoss: 0.000527\n","Train Epoch: 17 [12160/151166 (8%)]\tLoss: 0.000282\n","Train Epoch: 17 [12800/151166 (8%)]\tLoss: 0.000114\n","Train Epoch: 17 [13440/151166 (9%)]\tLoss: 0.001176\n","Train Epoch: 17 [14080/151166 (9%)]\tLoss: 0.000217\n","Train Epoch: 17 [14720/151166 (10%)]\tLoss: 0.000724\n","Train Epoch: 17 [15360/151166 (10%)]\tLoss: 0.001855\n","Train Epoch: 17 [16000/151166 (11%)]\tLoss: 0.000885\n","Train Epoch: 17 [16640/151166 (11%)]\tLoss: 0.000202\n","Train Epoch: 17 [17280/151166 (11%)]\tLoss: 0.000237\n","Train Epoch: 17 [17920/151166 (12%)]\tLoss: 0.002272\n","Train Epoch: 17 [18560/151166 (12%)]\tLoss: 0.000493\n","Train Epoch: 17 [19200/151166 (13%)]\tLoss: 0.000770\n","Train Epoch: 17 [19840/151166 (13%)]\tLoss: 0.000258\n","Train Epoch: 17 [20480/151166 (14%)]\tLoss: 0.001316\n","Train Epoch: 17 [21120/151166 (14%)]\tLoss: 0.000463\n","Train Epoch: 17 [21760/151166 (14%)]\tLoss: 0.000084\n","Train Epoch: 17 [22400/151166 (15%)]\tLoss: 0.000555\n","Train Epoch: 17 [23040/151166 (15%)]\tLoss: 0.000360\n","Train Epoch: 17 [23680/151166 (16%)]\tLoss: 0.000081\n","Train Epoch: 17 [24320/151166 (16%)]\tLoss: 0.001419\n","Train Epoch: 17 [24960/151166 (17%)]\tLoss: 0.001313\n","Train Epoch: 17 [25600/151166 (17%)]\tLoss: 0.000484\n","Train Epoch: 17 [26240/151166 (17%)]\tLoss: 0.000722\n","Train Epoch: 17 [26880/151166 (18%)]\tLoss: 0.000886\n","Train Epoch: 17 [27520/151166 (18%)]\tLoss: 0.000127\n","Train Epoch: 17 [28160/151166 (19%)]\tLoss: 0.000854\n","Train Epoch: 17 [28800/151166 (19%)]\tLoss: 0.000219\n","Train Epoch: 17 [29440/151166 (19%)]\tLoss: 0.001340\n","Train Epoch: 17 [30080/151166 (20%)]\tLoss: 0.000534\n","Train Epoch: 17 [30720/151166 (20%)]\tLoss: 0.000344\n","Train Epoch: 17 [31360/151166 (21%)]\tLoss: 0.000134\n","Train Epoch: 17 [32000/151166 (21%)]\tLoss: 0.000433\n","Train Epoch: 17 [32640/151166 (22%)]\tLoss: 0.000550\n","Train Epoch: 17 [33280/151166 (22%)]\tLoss: 0.000397\n","Train Epoch: 17 [33920/151166 (22%)]\tLoss: 0.000228\n","Train Epoch: 17 [34560/151166 (23%)]\tLoss: 0.000190\n","Train Epoch: 17 [35200/151166 (23%)]\tLoss: 0.000280\n","Train Epoch: 17 [35840/151166 (24%)]\tLoss: 0.000261\n","Train Epoch: 17 [36480/151166 (24%)]\tLoss: 0.000686\n","Train Epoch: 17 [37120/151166 (25%)]\tLoss: 0.001375\n","Train Epoch: 17 [37760/151166 (25%)]\tLoss: 0.000568\n","Train Epoch: 17 [38400/151166 (25%)]\tLoss: 0.000449\n","Train Epoch: 17 [39040/151166 (26%)]\tLoss: 0.000258\n","Train Epoch: 17 [39680/151166 (26%)]\tLoss: 0.000578\n","Train Epoch: 17 [40320/151166 (27%)]\tLoss: 0.000323\n","Train Epoch: 17 [40960/151166 (27%)]\tLoss: 0.000284\n","Train Epoch: 17 [41600/151166 (28%)]\tLoss: 0.000598\n","Train Epoch: 17 [42240/151166 (28%)]\tLoss: 0.001871\n","Train Epoch: 17 [42880/151166 (28%)]\tLoss: 0.000050\n","Train Epoch: 17 [43520/151166 (29%)]\tLoss: 0.000571\n","Train Epoch: 17 [44160/151166 (29%)]\tLoss: 0.000429\n","Train Epoch: 17 [44800/151166 (30%)]\tLoss: 0.000051\n","Train Epoch: 17 [45440/151166 (30%)]\tLoss: 0.000321\n","Train Epoch: 17 [46080/151166 (30%)]\tLoss: 0.002265\n","Train Epoch: 17 [46720/151166 (31%)]\tLoss: 0.000827\n","Train Epoch: 17 [47360/151166 (31%)]\tLoss: 0.000665\n","Train Epoch: 17 [48000/151166 (32%)]\tLoss: 0.000453\n","Train Epoch: 17 [48640/151166 (32%)]\tLoss: 0.000288\n","Train Epoch: 17 [49280/151166 (33%)]\tLoss: 0.000424\n","Train Epoch: 17 [49920/151166 (33%)]\tLoss: 0.001194\n","Train Epoch: 17 [50560/151166 (33%)]\tLoss: 0.000254\n","Train Epoch: 17 [51200/151166 (34%)]\tLoss: 0.000326\n","Train Epoch: 17 [51840/151166 (34%)]\tLoss: 0.000247\n","Train Epoch: 17 [52480/151166 (35%)]\tLoss: 0.000138\n","Train Epoch: 17 [53120/151166 (35%)]\tLoss: 0.001094\n","Train Epoch: 17 [53760/151166 (36%)]\tLoss: 0.001050\n","Train Epoch: 17 [54400/151166 (36%)]\tLoss: 0.000845\n","Train Epoch: 17 [55040/151166 (36%)]\tLoss: 0.000454\n","Train Epoch: 17 [55680/151166 (37%)]\tLoss: 0.001111\n","Train Epoch: 17 [56320/151166 (37%)]\tLoss: 0.001616\n","Train Epoch: 17 [56960/151166 (38%)]\tLoss: 0.000421\n","Train Epoch: 17 [57600/151166 (38%)]\tLoss: 0.000635\n","Train Epoch: 17 [58240/151166 (39%)]\tLoss: 0.000659\n","Train Epoch: 17 [58880/151166 (39%)]\tLoss: 0.000212\n","Train Epoch: 17 [59520/151166 (39%)]\tLoss: 0.000389\n","Train Epoch: 17 [60160/151166 (40%)]\tLoss: 0.000544\n","Train Epoch: 17 [60800/151166 (40%)]\tLoss: 0.000860\n","Train Epoch: 17 [61440/151166 (41%)]\tLoss: 0.000518\n","Train Epoch: 17 [62080/151166 (41%)]\tLoss: 0.000970\n","Train Epoch: 17 [62720/151166 (41%)]\tLoss: 0.000659\n","Train Epoch: 17 [63360/151166 (42%)]\tLoss: 0.000410\n","Train Epoch: 17 [64000/151166 (42%)]\tLoss: 0.000688\n","Train Epoch: 17 [64640/151166 (43%)]\tLoss: 0.000227\n","Train Epoch: 17 [65280/151166 (43%)]\tLoss: 0.002664\n","Train Epoch: 17 [65920/151166 (44%)]\tLoss: 0.000364\n","Train Epoch: 17 [66560/151166 (44%)]\tLoss: 0.000221\n","Train Epoch: 17 [67200/151166 (44%)]\tLoss: 0.000284\n","Train Epoch: 17 [67840/151166 (45%)]\tLoss: 0.000334\n","Train Epoch: 17 [68480/151166 (45%)]\tLoss: 0.000464\n","Train Epoch: 17 [69120/151166 (46%)]\tLoss: 0.000295\n","Train Epoch: 17 [69760/151166 (46%)]\tLoss: 0.000192\n","Train Epoch: 17 [70400/151166 (47%)]\tLoss: 0.000421\n","Train Epoch: 17 [71040/151166 (47%)]\tLoss: 0.000152\n","Train Epoch: 17 [71680/151166 (47%)]\tLoss: 0.000184\n","Train Epoch: 17 [72320/151166 (48%)]\tLoss: 0.000363\n","Train Epoch: 17 [72960/151166 (48%)]\tLoss: 0.001819\n","Train Epoch: 17 [73600/151166 (49%)]\tLoss: 0.000238\n","Train Epoch: 17 [74240/151166 (49%)]\tLoss: 0.001064\n","Train Epoch: 17 [74880/151166 (50%)]\tLoss: 0.000617\n","Train Epoch: 17 [75520/151166 (50%)]\tLoss: 0.000330\n","Train Epoch: 17 [76160/151166 (50%)]\tLoss: 0.002599\n","Train Epoch: 17 [76800/151166 (51%)]\tLoss: 0.002049\n","Train Epoch: 17 [77440/151166 (51%)]\tLoss: 0.000700\n","Train Epoch: 17 [78080/151166 (52%)]\tLoss: 0.000296\n","Train Epoch: 17 [78720/151166 (52%)]\tLoss: 0.000663\n","Train Epoch: 17 [79360/151166 (52%)]\tLoss: 0.000650\n","Train Epoch: 17 [80000/151166 (53%)]\tLoss: 0.001500\n","Train Epoch: 17 [80640/151166 (53%)]\tLoss: 0.000072\n","Train Epoch: 17 [81280/151166 (54%)]\tLoss: 0.000507\n","Train Epoch: 17 [81920/151166 (54%)]\tLoss: 0.000744\n","Train Epoch: 17 [82560/151166 (55%)]\tLoss: 0.000984\n","Train Epoch: 17 [83200/151166 (55%)]\tLoss: 0.000589\n","Train Epoch: 17 [83840/151166 (55%)]\tLoss: 0.000617\n","Train Epoch: 17 [84480/151166 (56%)]\tLoss: 0.000652\n","Train Epoch: 17 [85120/151166 (56%)]\tLoss: 0.001743\n","Train Epoch: 17 [85760/151166 (57%)]\tLoss: 0.000217\n","Train Epoch: 17 [86400/151166 (57%)]\tLoss: 0.001466\n","Train Epoch: 17 [87040/151166 (58%)]\tLoss: 0.001194\n","Train Epoch: 17 [87680/151166 (58%)]\tLoss: 0.002785\n","Train Epoch: 17 [88320/151166 (58%)]\tLoss: 0.000198\n","Train Epoch: 17 [88960/151166 (59%)]\tLoss: 0.000204\n","Train Epoch: 17 [89600/151166 (59%)]\tLoss: 0.000210\n","Train Epoch: 17 [90240/151166 (60%)]\tLoss: 0.000458\n","Train Epoch: 17 [90880/151166 (60%)]\tLoss: 0.000953\n","Train Epoch: 17 [91520/151166 (61%)]\tLoss: 0.000231\n","Train Epoch: 17 [92160/151166 (61%)]\tLoss: 0.000212\n","Train Epoch: 17 [92800/151166 (61%)]\tLoss: 0.000411\n","Train Epoch: 17 [93440/151166 (62%)]\tLoss: 0.002232\n","Train Epoch: 17 [94080/151166 (62%)]\tLoss: 0.002380\n","Train Epoch: 17 [94720/151166 (63%)]\tLoss: 0.001054\n","Train Epoch: 17 [95360/151166 (63%)]\tLoss: 0.000989\n","Train Epoch: 17 [96000/151166 (64%)]\tLoss: 0.000723\n","Train Epoch: 17 [96640/151166 (64%)]\tLoss: 0.004020\n","Train Epoch: 17 [97280/151166 (64%)]\tLoss: 0.000068\n","Train Epoch: 17 [97920/151166 (65%)]\tLoss: 0.000272\n","Train Epoch: 17 [98560/151166 (65%)]\tLoss: 0.000250\n","Train Epoch: 17 [99200/151166 (66%)]\tLoss: 0.000426\n","Train Epoch: 17 [99840/151166 (66%)]\tLoss: 0.001134\n","Train Epoch: 17 [100480/151166 (66%)]\tLoss: 0.000221\n","Train Epoch: 17 [101120/151166 (67%)]\tLoss: 0.000713\n","Train Epoch: 17 [101760/151166 (67%)]\tLoss: 0.000112\n","Train Epoch: 17 [102400/151166 (68%)]\tLoss: 0.000853\n","Train Epoch: 17 [103040/151166 (68%)]\tLoss: 0.000769\n","Train Epoch: 17 [103680/151166 (69%)]\tLoss: 0.000143\n","Train Epoch: 17 [104320/151166 (69%)]\tLoss: 0.000602\n","Train Epoch: 17 [104960/151166 (69%)]\tLoss: 0.000581\n","Train Epoch: 17 [105600/151166 (70%)]\tLoss: 0.001478\n","Train Epoch: 17 [106240/151166 (70%)]\tLoss: 0.000513\n","Train Epoch: 17 [106880/151166 (71%)]\tLoss: 0.000642\n","Train Epoch: 17 [107520/151166 (71%)]\tLoss: 0.000229\n","Train Epoch: 17 [108160/151166 (72%)]\tLoss: 0.000590\n","Train Epoch: 17 [108800/151166 (72%)]\tLoss: 0.000223\n","Train Epoch: 17 [109440/151166 (72%)]\tLoss: 0.001495\n","Train Epoch: 17 [110080/151166 (73%)]\tLoss: 0.000550\n","Train Epoch: 17 [110720/151166 (73%)]\tLoss: 0.000209\n","Train Epoch: 17 [111360/151166 (74%)]\tLoss: 0.000422\n","Train Epoch: 17 [112000/151166 (74%)]\tLoss: 0.000150\n","Train Epoch: 17 [112640/151166 (75%)]\tLoss: 0.000518\n","Train Epoch: 17 [113280/151166 (75%)]\tLoss: 0.000194\n","Train Epoch: 17 [113920/151166 (75%)]\tLoss: 0.000113\n","Train Epoch: 17 [114560/151166 (76%)]\tLoss: 0.001037\n","Train Epoch: 17 [115200/151166 (76%)]\tLoss: 0.000564\n","Train Epoch: 17 [115840/151166 (77%)]\tLoss: 0.000518\n","Train Epoch: 17 [116480/151166 (77%)]\tLoss: 0.000320\n","Train Epoch: 17 [117120/151166 (77%)]\tLoss: 0.002626\n","Train Epoch: 17 [117760/151166 (78%)]\tLoss: 0.001138\n","Train Epoch: 17 [118400/151166 (78%)]\tLoss: 0.000472\n","Train Epoch: 17 [119040/151166 (79%)]\tLoss: 0.001193\n","Train Epoch: 17 [119680/151166 (79%)]\tLoss: 0.000856\n","Train Epoch: 17 [120320/151166 (80%)]\tLoss: 0.001250\n","Train Epoch: 17 [120960/151166 (80%)]\tLoss: 0.000202\n","Train Epoch: 17 [121600/151166 (80%)]\tLoss: 0.000633\n","Train Epoch: 17 [122240/151166 (81%)]\tLoss: 0.000915\n","Train Epoch: 17 [122880/151166 (81%)]\tLoss: 0.000140\n","Train Epoch: 17 [123520/151166 (82%)]\tLoss: 0.002637\n","Train Epoch: 17 [124160/151166 (82%)]\tLoss: 0.001665\n","Train Epoch: 17 [124800/151166 (83%)]\tLoss: 0.000414\n","Train Epoch: 17 [125440/151166 (83%)]\tLoss: 0.000402\n","Train Epoch: 17 [126080/151166 (83%)]\tLoss: 0.000578\n","Train Epoch: 17 [126720/151166 (84%)]\tLoss: 0.000137\n","Train Epoch: 17 [127360/151166 (84%)]\tLoss: 0.000959\n","Train Epoch: 17 [128000/151166 (85%)]\tLoss: 0.000149\n","Train Epoch: 17 [128640/151166 (85%)]\tLoss: 0.000405\n","Train Epoch: 17 [129280/151166 (86%)]\tLoss: 0.000765\n","Train Epoch: 17 [129920/151166 (86%)]\tLoss: 0.000250\n","Train Epoch: 17 [130560/151166 (86%)]\tLoss: 0.000884\n","Train Epoch: 17 [131200/151166 (87%)]\tLoss: 0.000679\n","Train Epoch: 17 [131840/151166 (87%)]\tLoss: 0.000174\n","Train Epoch: 17 [132480/151166 (88%)]\tLoss: 0.000116\n","Train Epoch: 17 [133120/151166 (88%)]\tLoss: 0.001831\n","Train Epoch: 17 [133760/151166 (88%)]\tLoss: 0.000312\n","Train Epoch: 17 [134400/151166 (89%)]\tLoss: 0.001000\n","Train Epoch: 17 [135040/151166 (89%)]\tLoss: 0.001941\n","Train Epoch: 17 [135680/151166 (90%)]\tLoss: 0.002754\n","Train Epoch: 17 [136320/151166 (90%)]\tLoss: 0.001561\n","Train Epoch: 17 [136960/151166 (91%)]\tLoss: 0.000205\n","Train Epoch: 17 [137600/151166 (91%)]\tLoss: 0.001331\n","Train Epoch: 17 [138240/151166 (91%)]\tLoss: 0.001373\n","Train Epoch: 17 [138880/151166 (92%)]\tLoss: 0.000207\n","Train Epoch: 17 [139520/151166 (92%)]\tLoss: 0.000683\n","Train Epoch: 17 [140160/151166 (93%)]\tLoss: 0.002665\n","Train Epoch: 17 [140800/151166 (93%)]\tLoss: 0.000101\n","Train Epoch: 17 [141440/151166 (94%)]\tLoss: 0.000178\n","Train Epoch: 17 [142080/151166 (94%)]\tLoss: 0.001114\n","Train Epoch: 17 [142720/151166 (94%)]\tLoss: 0.000417\n","Train Epoch: 17 [143360/151166 (95%)]\tLoss: 0.000868\n","Train Epoch: 17 [144000/151166 (95%)]\tLoss: 0.001589\n","Train Epoch: 17 [144640/151166 (96%)]\tLoss: 0.001531\n","Train Epoch: 17 [145280/151166 (96%)]\tLoss: 0.000897\n","Train Epoch: 17 [145920/151166 (97%)]\tLoss: 0.001158\n","Train Epoch: 17 [146560/151166 (97%)]\tLoss: 0.000619\n","Train Epoch: 17 [147200/151166 (97%)]\tLoss: 0.000081\n","Train Epoch: 17 [147840/151166 (98%)]\tLoss: 0.000675\n","Train Epoch: 17 [148480/151166 (98%)]\tLoss: 0.001793\n","Train Epoch: 17 [149120/151166 (99%)]\tLoss: 0.000226\n","Train Epoch: 17 [149760/151166 (99%)]\tLoss: 0.000329\n","Train Epoch: 17 [150400/151166 (99%)]\tLoss: 0.000439\n","Train Epoch: 17 [151040/151166 (100%)]\tLoss: 0.000260\n","Sample outputs (log probs): tensor([[-3.4827e+01, -2.2115e+01, -1.8878e+01, -2.4950e+01, -1.4546e+01,\n","         -1.4935e+01, -1.5547e+01, -4.1619e+01, -2.0057e+01, -1.2976e+01,\n","         -3.2542e+01, -2.8511e+01, -3.6472e+01, -3.7166e+01, -1.9379e+01,\n","         -3.1080e+01, -2.3885e+01, -4.4988e+01, -3.3379e-06, -2.4673e+01,\n","         -3.4891e+01, -3.4267e+01, -3.4850e+01, -3.7583e+01, -2.2145e+01,\n","         -3.1091e+01],\n","        [-1.9027e+01, -1.8688e+01, -2.0623e-05, -1.6241e+01, -1.3308e+01,\n","         -1.7607e+01, -1.4308e+01, -2.6522e+01, -1.5714e+01, -1.8458e+01,\n","         -2.1285e+01, -1.4583e+01, -2.0345e+01, -1.8646e+01, -1.1070e+01,\n","         -1.7301e+01, -1.3512e+01, -1.4776e+01, -1.5744e+01, -1.8311e+01,\n","         -1.7710e+01, -2.3100e+01, -2.7162e+01, -2.6631e+01, -2.0211e+01,\n","         -2.0622e+01],\n","        [-1.5585e+01, -2.0674e+01, -2.1891e+01, -1.7272e+01, -2.8343e+01,\n","         -2.8680e+01, -1.9042e+01, -1.7067e+01, -2.3669e+01, -2.4418e+01,\n","         -2.1662e+01, -2.5643e+01, -4.2334e-04, -7.7808e+00, -1.6427e+01,\n","         -2.1562e+01, -1.9483e+01, -1.9343e+01, -2.6810e+01, -2.0256e+01,\n","         -1.6087e+01, -1.7689e+01, -1.2180e+01, -2.1707e+01, -2.2480e+01,\n","         -2.6097e+01],\n","        [-1.8698e+01, -2.0820e+01, -2.8530e+01, -3.3661e+01, -2.6602e+01,\n","         -3.2953e+01, -2.2661e+01, -1.2505e+01, -2.8416e+01, -3.6133e+01,\n","         -1.5974e-05, -1.8135e+01, -1.7930e+01, -1.5758e+01, -3.5244e+01,\n","         -2.3988e+01, -2.8662e+01, -1.1348e+01, -3.1422e+01, -2.8727e+01,\n","         -1.9274e+01, -2.4362e+01, -1.8526e+01, -1.4860e+01, -2.1454e+01,\n","         -3.1191e+01],\n","        [-1.0231e+01, -9.4157e+00, -1.6283e+01, -1.8336e+01, -1.6362e+01,\n","         -1.5125e+01, -1.3363e+01, -1.7105e+01, -2.3845e+01, -2.7212e+01,\n","         -1.4207e+01, -2.1651e+01, -1.8559e+01, -1.6017e+01, -2.1578e+01,\n","         -9.5747e+00, -7.9094e+00, -5.5727e-04, -2.0968e+01, -1.7868e+01,\n","         -1.8756e+01, -2.3980e+01, -1.8573e+01, -1.9840e+01, -2.1389e+01,\n","         -1.8933e+01]], device='cuda:0')\n","Predicted classes: tensor([18,  2, 12, 10, 17], device='cuda:0')\n","Target classes: tensor([18,  2, 12, 10, 17], device='cuda:0')\n","\n","Test set: Average loss: 0.001578, Total sum loss: 0.467078, Accuracy: 36945/37792 (98%)\n","\n","Class A: 1228/1247 (98%)\n","Class B: 801/816 (98%)\n","Class C: 1924/1965 (98%)\n","Class D: 807/868 (93%)\n","Class E: 1007/1024 (98%)\n","Class F: 1828/1869 (98%)\n","Class G: 508/519 (98%)\n","Class H: 601/621 (97%)\n","Class I: 2377/2410 (99%)\n","Class J: 730/754 (97%)\n","Class K: 490/502 (98%)\n","Class L: 963/987 (98%)\n","Class M: 1746/1774 (98%)\n","Class N: 1586/1622 (98%)\n","Class O: 4927/5064 (97%)\n","Class P: 1588/1615 (98%)\n","Class Q: 524/536 (98%)\n","Class R: 970/992 (98%)\n","Class S: 4181/4228 (99%)\n","Class T: 1916/1932 (99%)\n","Class U: 2502/2598 (96%)\n","Class V: 865/904 (96%)\n","Class W: 921/938 (98%)\n","Class X: 542/560 (97%)\n","Class Y: 900/924 (97%)\n","Class Z: 513/523 (98%)\n","Train Epoch: 18 [0/151166 (0%)]\tLoss: 0.000534\n","Train Epoch: 18 [640/151166 (0%)]\tLoss: 0.000915\n","Train Epoch: 18 [1280/151166 (1%)]\tLoss: 0.000272\n","Train Epoch: 18 [1920/151166 (1%)]\tLoss: 0.000538\n","Train Epoch: 18 [2560/151166 (2%)]\tLoss: 0.000140\n","Train Epoch: 18 [3200/151166 (2%)]\tLoss: 0.000168\n","Train Epoch: 18 [3840/151166 (3%)]\tLoss: 0.001398\n","Train Epoch: 18 [4480/151166 (3%)]\tLoss: 0.000527\n","Train Epoch: 18 [5120/151166 (3%)]\tLoss: 0.000813\n","Train Epoch: 18 [5760/151166 (4%)]\tLoss: 0.000660\n","Train Epoch: 18 [6400/151166 (4%)]\tLoss: 0.000517\n","Train Epoch: 18 [7040/151166 (5%)]\tLoss: 0.000292\n","Train Epoch: 18 [7680/151166 (5%)]\tLoss: 0.000670\n","Train Epoch: 18 [8320/151166 (6%)]\tLoss: 0.000995\n","Train Epoch: 18 [8960/151166 (6%)]\tLoss: 0.000764\n","Train Epoch: 18 [9600/151166 (6%)]\tLoss: 0.000649\n","Train Epoch: 18 [10240/151166 (7%)]\tLoss: 0.000835\n","Train Epoch: 18 [10880/151166 (7%)]\tLoss: 0.000592\n","Train Epoch: 18 [11520/151166 (8%)]\tLoss: 0.000479\n","Train Epoch: 18 [12160/151166 (8%)]\tLoss: 0.000734\n","Train Epoch: 18 [12800/151166 (8%)]\tLoss: 0.000288\n","Train Epoch: 18 [13440/151166 (9%)]\tLoss: 0.001197\n","Train Epoch: 18 [14080/151166 (9%)]\tLoss: 0.000373\n","Train Epoch: 18 [14720/151166 (10%)]\tLoss: 0.000752\n","Train Epoch: 18 [15360/151166 (10%)]\tLoss: 0.000503\n","Train Epoch: 18 [16000/151166 (11%)]\tLoss: 0.000462\n","Train Epoch: 18 [16640/151166 (11%)]\tLoss: 0.000337\n","Train Epoch: 18 [17280/151166 (11%)]\tLoss: 0.000242\n","Train Epoch: 18 [17920/151166 (12%)]\tLoss: 0.000228\n","Train Epoch: 18 [18560/151166 (12%)]\tLoss: 0.000228\n","Train Epoch: 18 [19200/151166 (13%)]\tLoss: 0.000519\n","Train Epoch: 18 [19840/151166 (13%)]\tLoss: 0.000282\n","Train Epoch: 18 [20480/151166 (14%)]\tLoss: 0.000149\n","Train Epoch: 18 [21120/151166 (14%)]\tLoss: 0.000761\n","Train Epoch: 18 [21760/151166 (14%)]\tLoss: 0.000294\n","Train Epoch: 18 [22400/151166 (15%)]\tLoss: 0.000374\n","Train Epoch: 18 [23040/151166 (15%)]\tLoss: 0.001094\n","Train Epoch: 18 [23680/151166 (16%)]\tLoss: 0.000542\n","Train Epoch: 18 [24320/151166 (16%)]\tLoss: 0.000201\n","Train Epoch: 18 [24960/151166 (17%)]\tLoss: 0.000776\n","Train Epoch: 18 [25600/151166 (17%)]\tLoss: 0.001119\n","Train Epoch: 18 [26240/151166 (17%)]\tLoss: 0.000157\n","Train Epoch: 18 [26880/151166 (18%)]\tLoss: 0.000844\n","Train Epoch: 18 [27520/151166 (18%)]\tLoss: 0.000325\n","Train Epoch: 18 [28160/151166 (19%)]\tLoss: 0.000439\n","Train Epoch: 18 [28800/151166 (19%)]\tLoss: 0.000268\n","Train Epoch: 18 [29440/151166 (19%)]\tLoss: 0.000428\n","Train Epoch: 18 [30080/151166 (20%)]\tLoss: 0.000499\n","Train Epoch: 18 [30720/151166 (20%)]\tLoss: 0.000820\n","Train Epoch: 18 [31360/151166 (21%)]\tLoss: 0.002297\n","Train Epoch: 18 [32000/151166 (21%)]\tLoss: 0.001021\n","Train Epoch: 18 [32640/151166 (22%)]\tLoss: 0.000461\n","Train Epoch: 18 [33280/151166 (22%)]\tLoss: 0.000194\n","Train Epoch: 18 [33920/151166 (22%)]\tLoss: 0.000333\n","Train Epoch: 18 [34560/151166 (23%)]\tLoss: 0.000239\n","Train Epoch: 18 [35200/151166 (23%)]\tLoss: 0.000201\n","Train Epoch: 18 [35840/151166 (24%)]\tLoss: 0.000578\n","Train Epoch: 18 [36480/151166 (24%)]\tLoss: 0.001493\n","Train Epoch: 18 [37120/151166 (25%)]\tLoss: 0.000560\n","Train Epoch: 18 [37760/151166 (25%)]\tLoss: 0.000503\n","Train Epoch: 18 [38400/151166 (25%)]\tLoss: 0.000633\n","Train Epoch: 18 [39040/151166 (26%)]\tLoss: 0.000518\n","Train Epoch: 18 [39680/151166 (26%)]\tLoss: 0.000195\n","Train Epoch: 18 [40320/151166 (27%)]\tLoss: 0.000624\n","Train Epoch: 18 [40960/151166 (27%)]\tLoss: 0.000224\n","Train Epoch: 18 [41600/151166 (28%)]\tLoss: 0.000387\n","Train Epoch: 18 [42240/151166 (28%)]\tLoss: 0.000251\n","Train Epoch: 18 [42880/151166 (28%)]\tLoss: 0.000281\n","Train Epoch: 18 [43520/151166 (29%)]\tLoss: 0.000169\n","Train Epoch: 18 [44160/151166 (29%)]\tLoss: 0.001374\n","Train Epoch: 18 [44800/151166 (30%)]\tLoss: 0.000126\n","Train Epoch: 18 [45440/151166 (30%)]\tLoss: 0.000882\n","Train Epoch: 18 [46080/151166 (30%)]\tLoss: 0.002704\n","Train Epoch: 18 [46720/151166 (31%)]\tLoss: 0.000346\n","Train Epoch: 18 [47360/151166 (31%)]\tLoss: 0.000396\n","Train Epoch: 18 [48000/151166 (32%)]\tLoss: 0.001662\n","Train Epoch: 18 [48640/151166 (32%)]\tLoss: 0.000087\n","Train Epoch: 18 [49280/151166 (33%)]\tLoss: 0.002130\n","Train Epoch: 18 [49920/151166 (33%)]\tLoss: 0.000579\n","Train Epoch: 18 [50560/151166 (33%)]\tLoss: 0.000676\n","Train Epoch: 18 [51200/151166 (34%)]\tLoss: 0.000353\n","Train Epoch: 18 [51840/151166 (34%)]\tLoss: 0.000311\n","Train Epoch: 18 [52480/151166 (35%)]\tLoss: 0.002577\n","Train Epoch: 18 [53120/151166 (35%)]\tLoss: 0.000541\n","Train Epoch: 18 [53760/151166 (36%)]\tLoss: 0.000098\n","Train Epoch: 18 [54400/151166 (36%)]\tLoss: 0.000701\n","Train Epoch: 18 [55040/151166 (36%)]\tLoss: 0.000508\n","Train Epoch: 18 [55680/151166 (37%)]\tLoss: 0.001823\n","Train Epoch: 18 [56320/151166 (37%)]\tLoss: 0.000238\n","Train Epoch: 18 [56960/151166 (38%)]\tLoss: 0.000774\n","Train Epoch: 18 [57600/151166 (38%)]\tLoss: 0.000796\n","Train Epoch: 18 [58240/151166 (39%)]\tLoss: 0.000311\n","Train Epoch: 18 [58880/151166 (39%)]\tLoss: 0.000733\n","Train Epoch: 18 [59520/151166 (39%)]\tLoss: 0.001882\n","Train Epoch: 18 [60160/151166 (40%)]\tLoss: 0.000318\n","Train Epoch: 18 [60800/151166 (40%)]\tLoss: 0.000538\n","Train Epoch: 18 [61440/151166 (41%)]\tLoss: 0.000217\n","Train Epoch: 18 [62080/151166 (41%)]\tLoss: 0.000136\n","Train Epoch: 18 [62720/151166 (41%)]\tLoss: 0.000276\n","Train Epoch: 18 [63360/151166 (42%)]\tLoss: 0.000321\n","Train Epoch: 18 [64000/151166 (42%)]\tLoss: 0.000396\n","Train Epoch: 18 [64640/151166 (43%)]\tLoss: 0.001495\n","Train Epoch: 18 [65280/151166 (43%)]\tLoss: 0.000356\n","Train Epoch: 18 [65920/151166 (44%)]\tLoss: 0.001415\n","Train Epoch: 18 [66560/151166 (44%)]\tLoss: 0.000190\n","Train Epoch: 18 [67200/151166 (44%)]\tLoss: 0.000174\n","Train Epoch: 18 [67840/151166 (45%)]\tLoss: 0.000892\n","Train Epoch: 18 [68480/151166 (45%)]\tLoss: 0.000303\n","Train Epoch: 18 [69120/151166 (46%)]\tLoss: 0.001254\n","Train Epoch: 18 [69760/151166 (46%)]\tLoss: 0.001428\n","Train Epoch: 18 [70400/151166 (47%)]\tLoss: 0.000280\n","Train Epoch: 18 [71040/151166 (47%)]\tLoss: 0.001348\n","Train Epoch: 18 [71680/151166 (47%)]\tLoss: 0.001346\n","Train Epoch: 18 [72320/151166 (48%)]\tLoss: 0.000827\n","Train Epoch: 18 [72960/151166 (48%)]\tLoss: 0.000213\n","Train Epoch: 18 [73600/151166 (49%)]\tLoss: 0.000123\n","Train Epoch: 18 [74240/151166 (49%)]\tLoss: 0.000347\n","Train Epoch: 18 [74880/151166 (50%)]\tLoss: 0.001420\n","Train Epoch: 18 [75520/151166 (50%)]\tLoss: 0.000799\n","Train Epoch: 18 [76160/151166 (50%)]\tLoss: 0.000378\n","Train Epoch: 18 [76800/151166 (51%)]\tLoss: 0.000658\n","Train Epoch: 18 [77440/151166 (51%)]\tLoss: 0.005448\n","Train Epoch: 18 [78080/151166 (52%)]\tLoss: 0.000401\n","Train Epoch: 18 [78720/151166 (52%)]\tLoss: 0.001015\n","Train Epoch: 18 [79360/151166 (52%)]\tLoss: 0.001221\n","Train Epoch: 18 [80000/151166 (53%)]\tLoss: 0.000379\n","Train Epoch: 18 [80640/151166 (53%)]\tLoss: 0.001165\n","Train Epoch: 18 [81280/151166 (54%)]\tLoss: 0.001078\n","Train Epoch: 18 [81920/151166 (54%)]\tLoss: 0.000235\n","Train Epoch: 18 [82560/151166 (55%)]\tLoss: 0.001124\n","Train Epoch: 18 [83200/151166 (55%)]\tLoss: 0.000768\n","Train Epoch: 18 [83840/151166 (55%)]\tLoss: 0.001103\n","Train Epoch: 18 [84480/151166 (56%)]\tLoss: 0.000290\n","Train Epoch: 18 [85120/151166 (56%)]\tLoss: 0.000489\n","Train Epoch: 18 [85760/151166 (57%)]\tLoss: 0.000853\n","Train Epoch: 18 [86400/151166 (57%)]\tLoss: 0.000343\n","Train Epoch: 18 [87040/151166 (58%)]\tLoss: 0.002008\n","Train Epoch: 18 [87680/151166 (58%)]\tLoss: 0.000435\n","Train Epoch: 18 [88320/151166 (58%)]\tLoss: 0.000145\n","Train Epoch: 18 [88960/151166 (59%)]\tLoss: 0.000219\n","Train Epoch: 18 [89600/151166 (59%)]\tLoss: 0.000849\n","Train Epoch: 18 [90240/151166 (60%)]\tLoss: 0.000618\n","Train Epoch: 18 [90880/151166 (60%)]\tLoss: 0.000712\n","Train Epoch: 18 [91520/151166 (61%)]\tLoss: 0.000336\n","Train Epoch: 18 [92160/151166 (61%)]\tLoss: 0.000396\n","Train Epoch: 18 [92800/151166 (61%)]\tLoss: 0.000369\n","Train Epoch: 18 [93440/151166 (62%)]\tLoss: 0.000809\n","Train Epoch: 18 [94080/151166 (62%)]\tLoss: 0.000720\n","Train Epoch: 18 [94720/151166 (63%)]\tLoss: 0.000331\n","Train Epoch: 18 [95360/151166 (63%)]\tLoss: 0.000472\n","Train Epoch: 18 [96000/151166 (64%)]\tLoss: 0.000547\n","Train Epoch: 18 [96640/151166 (64%)]\tLoss: 0.000465\n","Train Epoch: 18 [97280/151166 (64%)]\tLoss: 0.000802\n","Train Epoch: 18 [97920/151166 (65%)]\tLoss: 0.000127\n","Train Epoch: 18 [98560/151166 (65%)]\tLoss: 0.000678\n","Train Epoch: 18 [99200/151166 (66%)]\tLoss: 0.000621\n","Train Epoch: 18 [99840/151166 (66%)]\tLoss: 0.000436\n","Train Epoch: 18 [100480/151166 (66%)]\tLoss: 0.002092\n","Train Epoch: 18 [101120/151166 (67%)]\tLoss: 0.001019\n","Train Epoch: 18 [101760/151166 (67%)]\tLoss: 0.000243\n","Train Epoch: 18 [102400/151166 (68%)]\tLoss: 0.000851\n","Train Epoch: 18 [103040/151166 (68%)]\tLoss: 0.000334\n","Train Epoch: 18 [103680/151166 (69%)]\tLoss: 0.000492\n","Train Epoch: 18 [104320/151166 (69%)]\tLoss: 0.000805\n","Train Epoch: 18 [104960/151166 (69%)]\tLoss: 0.000255\n","Train Epoch: 18 [105600/151166 (70%)]\tLoss: 0.000132\n","Train Epoch: 18 [106240/151166 (70%)]\tLoss: 0.000127\n","Train Epoch: 18 [106880/151166 (71%)]\tLoss: 0.000108\n","Train Epoch: 18 [107520/151166 (71%)]\tLoss: 0.000221\n","Train Epoch: 18 [108160/151166 (72%)]\tLoss: 0.000783\n","Train Epoch: 18 [108800/151166 (72%)]\tLoss: 0.000090\n","Train Epoch: 18 [109440/151166 (72%)]\tLoss: 0.000411\n","Train Epoch: 18 [110080/151166 (73%)]\tLoss: 0.000791\n","Train Epoch: 18 [110720/151166 (73%)]\tLoss: 0.001095\n","Train Epoch: 18 [111360/151166 (74%)]\tLoss: 0.000724\n","Train Epoch: 18 [112000/151166 (74%)]\tLoss: 0.001065\n","Train Epoch: 18 [112640/151166 (75%)]\tLoss: 0.001808\n","Train Epoch: 18 [113280/151166 (75%)]\tLoss: 0.000510\n","Train Epoch: 18 [113920/151166 (75%)]\tLoss: 0.000259\n","Train Epoch: 18 [114560/151166 (76%)]\tLoss: 0.000497\n","Train Epoch: 18 [115200/151166 (76%)]\tLoss: 0.000192\n","Train Epoch: 18 [115840/151166 (77%)]\tLoss: 0.000227\n","Train Epoch: 18 [116480/151166 (77%)]\tLoss: 0.000580\n","Train Epoch: 18 [117120/151166 (77%)]\tLoss: 0.000772\n","Train Epoch: 18 [117760/151166 (78%)]\tLoss: 0.003119\n","Train Epoch: 18 [118400/151166 (78%)]\tLoss: 0.000644\n","Train Epoch: 18 [119040/151166 (79%)]\tLoss: 0.000965\n","Train Epoch: 18 [119680/151166 (79%)]\tLoss: 0.000365\n","Train Epoch: 18 [120320/151166 (80%)]\tLoss: 0.000507\n","Train Epoch: 18 [120960/151166 (80%)]\tLoss: 0.000518\n","Train Epoch: 18 [121600/151166 (80%)]\tLoss: 0.000615\n","Train Epoch: 18 [122240/151166 (81%)]\tLoss: 0.000224\n","Train Epoch: 18 [122880/151166 (81%)]\tLoss: 0.001237\n","Train Epoch: 18 [123520/151166 (82%)]\tLoss: 0.000242\n","Train Epoch: 18 [124160/151166 (82%)]\tLoss: 0.000543\n","Train Epoch: 18 [124800/151166 (83%)]\tLoss: 0.000574\n","Train Epoch: 18 [125440/151166 (83%)]\tLoss: 0.000266\n","Train Epoch: 18 [126080/151166 (83%)]\tLoss: 0.000081\n","Train Epoch: 18 [126720/151166 (84%)]\tLoss: 0.000417\n","Train Epoch: 18 [127360/151166 (84%)]\tLoss: 0.002217\n","Train Epoch: 18 [128000/151166 (85%)]\tLoss: 0.000198\n","Train Epoch: 18 [128640/151166 (85%)]\tLoss: 0.000275\n","Train Epoch: 18 [129280/151166 (86%)]\tLoss: 0.000295\n","Train Epoch: 18 [129920/151166 (86%)]\tLoss: 0.000357\n","Train Epoch: 18 [130560/151166 (86%)]\tLoss: 0.000451\n","Train Epoch: 18 [131200/151166 (87%)]\tLoss: 0.000574\n","Train Epoch: 18 [131840/151166 (87%)]\tLoss: 0.000382\n","Train Epoch: 18 [132480/151166 (88%)]\tLoss: 0.001314\n","Train Epoch: 18 [133120/151166 (88%)]\tLoss: 0.000296\n","Train Epoch: 18 [133760/151166 (88%)]\tLoss: 0.000261\n","Train Epoch: 18 [134400/151166 (89%)]\tLoss: 0.000302\n","Train Epoch: 18 [135040/151166 (89%)]\tLoss: 0.000452\n","Train Epoch: 18 [135680/151166 (90%)]\tLoss: 0.000397\n","Train Epoch: 18 [136320/151166 (90%)]\tLoss: 0.001426\n","Train Epoch: 18 [136960/151166 (91%)]\tLoss: 0.000807\n","Train Epoch: 18 [137600/151166 (91%)]\tLoss: 0.000220\n","Train Epoch: 18 [138240/151166 (91%)]\tLoss: 0.001045\n","Train Epoch: 18 [138880/151166 (92%)]\tLoss: 0.003298\n","Train Epoch: 18 [139520/151166 (92%)]\tLoss: 0.000143\n","Train Epoch: 18 [140160/151166 (93%)]\tLoss: 0.000484\n","Train Epoch: 18 [140800/151166 (93%)]\tLoss: 0.000878\n","Train Epoch: 18 [141440/151166 (94%)]\tLoss: 0.000642\n","Train Epoch: 18 [142080/151166 (94%)]\tLoss: 0.000752\n","Train Epoch: 18 [142720/151166 (94%)]\tLoss: 0.000103\n","Train Epoch: 18 [143360/151166 (95%)]\tLoss: 0.000928\n","Train Epoch: 18 [144000/151166 (95%)]\tLoss: 0.001633\n","Train Epoch: 18 [144640/151166 (96%)]\tLoss: 0.000139\n","Train Epoch: 18 [145280/151166 (96%)]\tLoss: 0.000241\n","Train Epoch: 18 [145920/151166 (97%)]\tLoss: 0.002452\n","Train Epoch: 18 [146560/151166 (97%)]\tLoss: 0.000108\n","Train Epoch: 18 [147200/151166 (97%)]\tLoss: 0.000502\n","Train Epoch: 18 [147840/151166 (98%)]\tLoss: 0.000262\n","Train Epoch: 18 [148480/151166 (98%)]\tLoss: 0.000794\n","Train Epoch: 18 [149120/151166 (99%)]\tLoss: 0.000475\n","Train Epoch: 18 [149760/151166 (99%)]\tLoss: 0.000219\n","Train Epoch: 18 [150400/151166 (99%)]\tLoss: 0.000407\n","Train Epoch: 18 [151040/151166 (100%)]\tLoss: 0.000444\n","Sample outputs (log probs): tensor([[-2.2933e+01, -1.5709e+01, -1.3970e+01, -9.0066e+00, -2.3934e+01,\n","         -2.7287e+01, -2.2954e+01, -2.9967e+01, -2.0324e+01, -1.9166e+01,\n","         -3.0266e+01, -2.7471e+01, -1.7269e+01, -1.6522e+01, -1.2469e-04,\n","         -1.7343e+01, -1.5414e+01, -2.2764e+01, -1.8526e+01, -2.2626e+01,\n","         -1.4144e+01, -2.1595e+01, -2.4049e+01, -3.3717e+01, -2.3845e+01,\n","         -2.8168e+01],\n","        [-1.1588e+01, -1.0455e+01, -6.6553e+00, -9.5273e+00, -1.4515e+01,\n","         -1.4624e+01, -7.8630e+00, -1.5398e+01, -1.0423e+01, -6.1809e+00,\n","         -1.9859e+01, -1.4142e+01, -1.4162e+01, -1.2441e+01, -8.1445e-03,\n","         -1.4044e+01, -6.2506e+00, -1.8680e+01, -1.2151e+01, -1.2250e+01,\n","         -6.1861e+00, -8.4265e+00, -1.5219e+01, -2.0609e+01, -1.1941e+01,\n","         -1.6914e+01],\n","        [-1.2857e+01, -1.8717e+01, -1.9459e+01, -1.7267e+01, -2.0812e+01,\n","         -8.4898e+00, -2.2661e+01, -1.8849e+01, -2.2084e+01, -2.6603e+01,\n","         -2.4027e+01, -2.9162e+01, -2.1532e+01, -1.6502e+01, -2.0022e+01,\n","         -2.2230e-04, -1.6774e+01, -1.1205e+01, -2.0321e+01, -1.4988e+01,\n","         -2.7751e+01, -2.0170e+01, -2.2867e+01, -2.5824e+01, -1.6480e+01,\n","         -2.2680e+01],\n","        [-3.1875e+01, -1.7374e+01, -1.5345e+01, -1.9736e+01, -1.4919e+01,\n","         -1.0677e+01, -1.3238e+01, -3.1936e+01, -1.2258e+01, -9.0697e+00,\n","         -2.3007e+01, -1.6430e+01, -3.5300e+01, -2.8778e+01, -2.1310e+01,\n","         -2.6841e+01, -2.1675e+01, -3.8185e+01, -1.4554e-04, -2.0493e+01,\n","         -2.6414e+01, -2.6671e+01, -2.6325e+01, -2.5092e+01, -1.5715e+01,\n","         -2.3908e+01],\n","        [-1.4692e+01, -1.1011e+01, -6.3441e+00, -9.8693e+00, -1.9322e+01,\n","         -1.9521e+01, -9.5104e+00, -1.6975e+01, -1.5771e+01, -1.0865e+01,\n","         -1.9740e+01, -1.5535e+01, -1.5658e+01, -1.2666e+01, -5.4351e-03,\n","         -1.4987e+01, -5.7223e+00, -1.9577e+01, -8.5536e+00, -1.6412e+01,\n","         -1.0398e+01, -1.7028e+01, -1.5887e+01, -2.4137e+01, -1.3267e+01,\n","         -2.1972e+01]], device='cuda:0')\n","Predicted classes: tensor([14, 14, 15, 18, 14], device='cuda:0')\n","Target classes: tensor([14, 14, 15, 18, 14], device='cuda:0')\n","\n","Test set: Average loss: 0.001570, Total sum loss: 0.464614, Accuracy: 36957/37792 (98%)\n","\n","Class A: 1229/1247 (99%)\n","Class B: 802/816 (98%)\n","Class C: 1928/1965 (98%)\n","Class D: 798/868 (92%)\n","Class E: 1010/1024 (99%)\n","Class F: 1829/1869 (98%)\n","Class G: 508/519 (98%)\n","Class H: 601/621 (97%)\n","Class I: 2379/2410 (99%)\n","Class J: 735/754 (97%)\n","Class K: 490/502 (98%)\n","Class L: 964/987 (98%)\n","Class M: 1747/1774 (98%)\n","Class N: 1591/1622 (98%)\n","Class O: 4931/5064 (97%)\n","Class P: 1584/1615 (98%)\n","Class Q: 522/536 (97%)\n","Class R: 972/992 (98%)\n","Class S: 4188/4228 (99%)\n","Class T: 1918/1932 (99%)\n","Class U: 2492/2598 (96%)\n","Class V: 871/904 (96%)\n","Class W: 920/938 (98%)\n","Class X: 546/560 (98%)\n","Class Y: 889/924 (96%)\n","Class Z: 513/523 (98%)\n","Train Epoch: 19 [0/151166 (0%)]\tLoss: 0.000148\n","Train Epoch: 19 [640/151166 (0%)]\tLoss: 0.001033\n","Train Epoch: 19 [1280/151166 (1%)]\tLoss: 0.000337\n","Train Epoch: 19 [1920/151166 (1%)]\tLoss: 0.000606\n","Train Epoch: 19 [2560/151166 (2%)]\tLoss: 0.001398\n","Train Epoch: 19 [3200/151166 (2%)]\tLoss: 0.000550\n","Train Epoch: 19 [3840/151166 (3%)]\tLoss: 0.003296\n","Train Epoch: 19 [4480/151166 (3%)]\tLoss: 0.000923\n","Train Epoch: 19 [5120/151166 (3%)]\tLoss: 0.000425\n","Train Epoch: 19 [5760/151166 (4%)]\tLoss: 0.000393\n","Train Epoch: 19 [6400/151166 (4%)]\tLoss: 0.000310\n","Train Epoch: 19 [7040/151166 (5%)]\tLoss: 0.000129\n","Train Epoch: 19 [7680/151166 (5%)]\tLoss: 0.000231\n","Train Epoch: 19 [8320/151166 (6%)]\tLoss: 0.001157\n","Train Epoch: 19 [8960/151166 (6%)]\tLoss: 0.000540\n","Train Epoch: 19 [9600/151166 (6%)]\tLoss: 0.000800\n","Train Epoch: 19 [10240/151166 (7%)]\tLoss: 0.000358\n","Train Epoch: 19 [10880/151166 (7%)]\tLoss: 0.000196\n","Train Epoch: 19 [11520/151166 (8%)]\tLoss: 0.000774\n","Train Epoch: 19 [12160/151166 (8%)]\tLoss: 0.001307\n","Train Epoch: 19 [12800/151166 (8%)]\tLoss: 0.000498\n","Train Epoch: 19 [13440/151166 (9%)]\tLoss: 0.002286\n","Train Epoch: 19 [14080/151166 (9%)]\tLoss: 0.000331\n","Train Epoch: 19 [14720/151166 (10%)]\tLoss: 0.000506\n","Train Epoch: 19 [15360/151166 (10%)]\tLoss: 0.000165\n","Train Epoch: 19 [16000/151166 (11%)]\tLoss: 0.000421\n","Train Epoch: 19 [16640/151166 (11%)]\tLoss: 0.001719\n","Train Epoch: 19 [17280/151166 (11%)]\tLoss: 0.000205\n","Train Epoch: 19 [17920/151166 (12%)]\tLoss: 0.000532\n","Train Epoch: 19 [18560/151166 (12%)]\tLoss: 0.000859\n","Train Epoch: 19 [19200/151166 (13%)]\tLoss: 0.000557\n","Train Epoch: 19 [19840/151166 (13%)]\tLoss: 0.000376\n","Train Epoch: 19 [20480/151166 (14%)]\tLoss: 0.000330\n","Train Epoch: 19 [21120/151166 (14%)]\tLoss: 0.001105\n","Train Epoch: 19 [21760/151166 (14%)]\tLoss: 0.000734\n","Train Epoch: 19 [22400/151166 (15%)]\tLoss: 0.001157\n","Train Epoch: 19 [23040/151166 (15%)]\tLoss: 0.000326\n","Train Epoch: 19 [23680/151166 (16%)]\tLoss: 0.000148\n","Train Epoch: 19 [24320/151166 (16%)]\tLoss: 0.000161\n","Train Epoch: 19 [24960/151166 (17%)]\tLoss: 0.001088\n","Train Epoch: 19 [25600/151166 (17%)]\tLoss: 0.001080\n","Train Epoch: 19 [26240/151166 (17%)]\tLoss: 0.000216\n","Train Epoch: 19 [26880/151166 (18%)]\tLoss: 0.000909\n","Train Epoch: 19 [27520/151166 (18%)]\tLoss: 0.000752\n","Train Epoch: 19 [28160/151166 (19%)]\tLoss: 0.000469\n","Train Epoch: 19 [28800/151166 (19%)]\tLoss: 0.000490\n","Train Epoch: 19 [29440/151166 (19%)]\tLoss: 0.000391\n","Train Epoch: 19 [30080/151166 (20%)]\tLoss: 0.002578\n","Train Epoch: 19 [30720/151166 (20%)]\tLoss: 0.000641\n","Train Epoch: 19 [31360/151166 (21%)]\tLoss: 0.000589\n","Train Epoch: 19 [32000/151166 (21%)]\tLoss: 0.000885\n","Train Epoch: 19 [32640/151166 (22%)]\tLoss: 0.000274\n","Train Epoch: 19 [33280/151166 (22%)]\tLoss: 0.001097\n","Train Epoch: 19 [33920/151166 (22%)]\tLoss: 0.001615\n","Train Epoch: 19 [34560/151166 (23%)]\tLoss: 0.000292\n","Train Epoch: 19 [35200/151166 (23%)]\tLoss: 0.000187\n","Train Epoch: 19 [35840/151166 (24%)]\tLoss: 0.001402\n","Train Epoch: 19 [36480/151166 (24%)]\tLoss: 0.000462\n","Train Epoch: 19 [37120/151166 (25%)]\tLoss: 0.000357\n","Train Epoch: 19 [37760/151166 (25%)]\tLoss: 0.000371\n","Train Epoch: 19 [38400/151166 (25%)]\tLoss: 0.001103\n","Train Epoch: 19 [39040/151166 (26%)]\tLoss: 0.000661\n","Train Epoch: 19 [39680/151166 (26%)]\tLoss: 0.000201\n","Train Epoch: 19 [40320/151166 (27%)]\tLoss: 0.000996\n","Train Epoch: 19 [40960/151166 (27%)]\tLoss: 0.000721\n","Train Epoch: 19 [41600/151166 (28%)]\tLoss: 0.000246\n","Train Epoch: 19 [42240/151166 (28%)]\tLoss: 0.000885\n","Train Epoch: 19 [42880/151166 (28%)]\tLoss: 0.000454\n","Train Epoch: 19 [43520/151166 (29%)]\tLoss: 0.000336\n","Train Epoch: 19 [44160/151166 (29%)]\tLoss: 0.000487\n","Train Epoch: 19 [44800/151166 (30%)]\tLoss: 0.001117\n","Train Epoch: 19 [45440/151166 (30%)]\tLoss: 0.001096\n","Train Epoch: 19 [46080/151166 (30%)]\tLoss: 0.000344\n","Train Epoch: 19 [46720/151166 (31%)]\tLoss: 0.001138\n","Train Epoch: 19 [47360/151166 (31%)]\tLoss: 0.000673\n","Train Epoch: 19 [48000/151166 (32%)]\tLoss: 0.000636\n","Train Epoch: 19 [48640/151166 (32%)]\tLoss: 0.000709\n","Train Epoch: 19 [49280/151166 (33%)]\tLoss: 0.000091\n","Train Epoch: 19 [49920/151166 (33%)]\tLoss: 0.000585\n","Train Epoch: 19 [50560/151166 (33%)]\tLoss: 0.001538\n","Train Epoch: 19 [51200/151166 (34%)]\tLoss: 0.000123\n","Train Epoch: 19 [51840/151166 (34%)]\tLoss: 0.000339\n","Train Epoch: 19 [52480/151166 (35%)]\tLoss: 0.000425\n","Train Epoch: 19 [53120/151166 (35%)]\tLoss: 0.000823\n","Train Epoch: 19 [53760/151166 (36%)]\tLoss: 0.001804\n","Train Epoch: 19 [54400/151166 (36%)]\tLoss: 0.000623\n","Train Epoch: 19 [55040/151166 (36%)]\tLoss: 0.000111\n","Train Epoch: 19 [55680/151166 (37%)]\tLoss: 0.001125\n","Train Epoch: 19 [56320/151166 (37%)]\tLoss: 0.000115\n","Train Epoch: 19 [56960/151166 (38%)]\tLoss: 0.000555\n","Train Epoch: 19 [57600/151166 (38%)]\tLoss: 0.000564\n","Train Epoch: 19 [58240/151166 (39%)]\tLoss: 0.001180\n","Train Epoch: 19 [58880/151166 (39%)]\tLoss: 0.000126\n","Train Epoch: 19 [59520/151166 (39%)]\tLoss: 0.000256\n","Train Epoch: 19 [60160/151166 (40%)]\tLoss: 0.000939\n","Train Epoch: 19 [60800/151166 (40%)]\tLoss: 0.000206\n","Train Epoch: 19 [61440/151166 (41%)]\tLoss: 0.000328\n","Train Epoch: 19 [62080/151166 (41%)]\tLoss: 0.001145\n","Train Epoch: 19 [62720/151166 (41%)]\tLoss: 0.000785\n","Train Epoch: 19 [63360/151166 (42%)]\tLoss: 0.000613\n","Train Epoch: 19 [64000/151166 (42%)]\tLoss: 0.000229\n","Train Epoch: 19 [64640/151166 (43%)]\tLoss: 0.000207\n","Train Epoch: 19 [65280/151166 (43%)]\tLoss: 0.000200\n","Train Epoch: 19 [65920/151166 (44%)]\tLoss: 0.000709\n","Train Epoch: 19 [66560/151166 (44%)]\tLoss: 0.001041\n","Train Epoch: 19 [67200/151166 (44%)]\tLoss: 0.001127\n","Train Epoch: 19 [67840/151166 (45%)]\tLoss: 0.000258\n","Train Epoch: 19 [68480/151166 (45%)]\tLoss: 0.000601\n","Train Epoch: 19 [69120/151166 (46%)]\tLoss: 0.000366\n","Train Epoch: 19 [69760/151166 (46%)]\tLoss: 0.000659\n","Train Epoch: 19 [70400/151166 (47%)]\tLoss: 0.000392\n","Train Epoch: 19 [71040/151166 (47%)]\tLoss: 0.000917\n","Train Epoch: 19 [71680/151166 (47%)]\tLoss: 0.002793\n","Train Epoch: 19 [72320/151166 (48%)]\tLoss: 0.000435\n","Train Epoch: 19 [72960/151166 (48%)]\tLoss: 0.002364\n","Train Epoch: 19 [73600/151166 (49%)]\tLoss: 0.000549\n","Train Epoch: 19 [74240/151166 (49%)]\tLoss: 0.000292\n","Train Epoch: 19 [74880/151166 (50%)]\tLoss: 0.000995\n","Train Epoch: 19 [75520/151166 (50%)]\tLoss: 0.000393\n","Train Epoch: 19 [76160/151166 (50%)]\tLoss: 0.000579\n","Train Epoch: 19 [76800/151166 (51%)]\tLoss: 0.000751\n","Train Epoch: 19 [77440/151166 (51%)]\tLoss: 0.000598\n","Train Epoch: 19 [78080/151166 (52%)]\tLoss: 0.001695\n","Train Epoch: 19 [78720/151166 (52%)]\tLoss: 0.000317\n","Train Epoch: 19 [79360/151166 (52%)]\tLoss: 0.000824\n","Train Epoch: 19 [80000/151166 (53%)]\tLoss: 0.000238\n","Train Epoch: 19 [80640/151166 (53%)]\tLoss: 0.000153\n","Train Epoch: 19 [81280/151166 (54%)]\tLoss: 0.000216\n","Train Epoch: 19 [81920/151166 (54%)]\tLoss: 0.000073\n","Train Epoch: 19 [82560/151166 (55%)]\tLoss: 0.000264\n","Train Epoch: 19 [83200/151166 (55%)]\tLoss: 0.000473\n","Train Epoch: 19 [83840/151166 (55%)]\tLoss: 0.000840\n","Train Epoch: 19 [84480/151166 (56%)]\tLoss: 0.000506\n","Train Epoch: 19 [85120/151166 (56%)]\tLoss: 0.001655\n","Train Epoch: 19 [85760/151166 (57%)]\tLoss: 0.000385\n","Train Epoch: 19 [86400/151166 (57%)]\tLoss: 0.000510\n","Train Epoch: 19 [87040/151166 (58%)]\tLoss: 0.000376\n","Train Epoch: 19 [87680/151166 (58%)]\tLoss: 0.000049\n","Train Epoch: 19 [88320/151166 (58%)]\tLoss: 0.000064\n","Train Epoch: 19 [88960/151166 (59%)]\tLoss: 0.000265\n","Train Epoch: 19 [89600/151166 (59%)]\tLoss: 0.000827\n","Train Epoch: 19 [90240/151166 (60%)]\tLoss: 0.000985\n","Train Epoch: 19 [90880/151166 (60%)]\tLoss: 0.000156\n","Train Epoch: 19 [91520/151166 (61%)]\tLoss: 0.001152\n","Train Epoch: 19 [92160/151166 (61%)]\tLoss: 0.000643\n","Train Epoch: 19 [92800/151166 (61%)]\tLoss: 0.001727\n","Train Epoch: 19 [93440/151166 (62%)]\tLoss: 0.000153\n","Train Epoch: 19 [94080/151166 (62%)]\tLoss: 0.000399\n","Train Epoch: 19 [94720/151166 (63%)]\tLoss: 0.000165\n","Train Epoch: 19 [95360/151166 (63%)]\tLoss: 0.000200\n","Train Epoch: 19 [96000/151166 (64%)]\tLoss: 0.000849\n","Train Epoch: 19 [96640/151166 (64%)]\tLoss: 0.001303\n","Train Epoch: 19 [97280/151166 (64%)]\tLoss: 0.000698\n","Train Epoch: 19 [97920/151166 (65%)]\tLoss: 0.000483\n","Train Epoch: 19 [98560/151166 (65%)]\tLoss: 0.001228\n","Train Epoch: 19 [99200/151166 (66%)]\tLoss: 0.000513\n","Train Epoch: 19 [99840/151166 (66%)]\tLoss: 0.000187\n","Train Epoch: 19 [100480/151166 (66%)]\tLoss: 0.000209\n","Train Epoch: 19 [101120/151166 (67%)]\tLoss: 0.000122\n","Train Epoch: 19 [101760/151166 (67%)]\tLoss: 0.000410\n","Train Epoch: 19 [102400/151166 (68%)]\tLoss: 0.000612\n","Train Epoch: 19 [103040/151166 (68%)]\tLoss: 0.000546\n","Train Epoch: 19 [103680/151166 (69%)]\tLoss: 0.000663\n","Train Epoch: 19 [104320/151166 (69%)]\tLoss: 0.000094\n","Train Epoch: 19 [104960/151166 (69%)]\tLoss: 0.000489\n","Train Epoch: 19 [105600/151166 (70%)]\tLoss: 0.000419\n","Train Epoch: 19 [106240/151166 (70%)]\tLoss: 0.001396\n","Train Epoch: 19 [106880/151166 (71%)]\tLoss: 0.000210\n","Train Epoch: 19 [107520/151166 (71%)]\tLoss: 0.000352\n","Train Epoch: 19 [108160/151166 (72%)]\tLoss: 0.000413\n","Train Epoch: 19 [108800/151166 (72%)]\tLoss: 0.000495\n","Train Epoch: 19 [109440/151166 (72%)]\tLoss: 0.000536\n","Train Epoch: 19 [110080/151166 (73%)]\tLoss: 0.000647\n","Train Epoch: 19 [110720/151166 (73%)]\tLoss: 0.000580\n","Train Epoch: 19 [111360/151166 (74%)]\tLoss: 0.000769\n","Train Epoch: 19 [112000/151166 (74%)]\tLoss: 0.000251\n","Train Epoch: 19 [112640/151166 (75%)]\tLoss: 0.000494\n","Train Epoch: 19 [113280/151166 (75%)]\tLoss: 0.002603\n","Train Epoch: 19 [113920/151166 (75%)]\tLoss: 0.001121\n","Train Epoch: 19 [114560/151166 (76%)]\tLoss: 0.000860\n","Train Epoch: 19 [115200/151166 (76%)]\tLoss: 0.000670\n","Train Epoch: 19 [115840/151166 (77%)]\tLoss: 0.000757\n","Train Epoch: 19 [116480/151166 (77%)]\tLoss: 0.001217\n","Train Epoch: 19 [117120/151166 (77%)]\tLoss: 0.001053\n","Train Epoch: 19 [117760/151166 (78%)]\tLoss: 0.000531\n","Train Epoch: 19 [118400/151166 (78%)]\tLoss: 0.001377\n","Train Epoch: 19 [119040/151166 (79%)]\tLoss: 0.000530\n","Train Epoch: 19 [119680/151166 (79%)]\tLoss: 0.004098\n","Train Epoch: 19 [120320/151166 (80%)]\tLoss: 0.001541\n","Train Epoch: 19 [120960/151166 (80%)]\tLoss: 0.000428\n","Train Epoch: 19 [121600/151166 (80%)]\tLoss: 0.000097\n","Train Epoch: 19 [122240/151166 (81%)]\tLoss: 0.000805\n","Train Epoch: 19 [122880/151166 (81%)]\tLoss: 0.000434\n","Train Epoch: 19 [123520/151166 (82%)]\tLoss: 0.000537\n","Train Epoch: 19 [124160/151166 (82%)]\tLoss: 0.000322\n","Train Epoch: 19 [124800/151166 (83%)]\tLoss: 0.000084\n","Train Epoch: 19 [125440/151166 (83%)]\tLoss: 0.000764\n","Train Epoch: 19 [126080/151166 (83%)]\tLoss: 0.000111\n","Train Epoch: 19 [126720/151166 (84%)]\tLoss: 0.000242\n","Train Epoch: 19 [127360/151166 (84%)]\tLoss: 0.000486\n","Train Epoch: 19 [128000/151166 (85%)]\tLoss: 0.000579\n","Train Epoch: 19 [128640/151166 (85%)]\tLoss: 0.000355\n","Train Epoch: 19 [129280/151166 (86%)]\tLoss: 0.000271\n","Train Epoch: 19 [129920/151166 (86%)]\tLoss: 0.000313\n","Train Epoch: 19 [130560/151166 (86%)]\tLoss: 0.000090\n","Train Epoch: 19 [131200/151166 (87%)]\tLoss: 0.000223\n","Train Epoch: 19 [131840/151166 (87%)]\tLoss: 0.000944\n","Train Epoch: 19 [132480/151166 (88%)]\tLoss: 0.001627\n","Train Epoch: 19 [133120/151166 (88%)]\tLoss: 0.000292\n","Train Epoch: 19 [133760/151166 (88%)]\tLoss: 0.000169\n","Train Epoch: 19 [134400/151166 (89%)]\tLoss: 0.000755\n","Train Epoch: 19 [135040/151166 (89%)]\tLoss: 0.000573\n","Train Epoch: 19 [135680/151166 (90%)]\tLoss: 0.000240\n","Train Epoch: 19 [136320/151166 (90%)]\tLoss: 0.000733\n","Train Epoch: 19 [136960/151166 (91%)]\tLoss: 0.000235\n","Train Epoch: 19 [137600/151166 (91%)]\tLoss: 0.000489\n","Train Epoch: 19 [138240/151166 (91%)]\tLoss: 0.000838\n","Train Epoch: 19 [138880/151166 (92%)]\tLoss: 0.000121\n","Train Epoch: 19 [139520/151166 (92%)]\tLoss: 0.000984\n","Train Epoch: 19 [140160/151166 (93%)]\tLoss: 0.001110\n","Train Epoch: 19 [140800/151166 (93%)]\tLoss: 0.000397\n","Train Epoch: 19 [141440/151166 (94%)]\tLoss: 0.000243\n","Train Epoch: 19 [142080/151166 (94%)]\tLoss: 0.002054\n","Train Epoch: 19 [142720/151166 (94%)]\tLoss: 0.000274\n","Train Epoch: 19 [143360/151166 (95%)]\tLoss: 0.000814\n","Train Epoch: 19 [144000/151166 (95%)]\tLoss: 0.000191\n","Train Epoch: 19 [144640/151166 (96%)]\tLoss: 0.000337\n","Train Epoch: 19 [145280/151166 (96%)]\tLoss: 0.004002\n","Train Epoch: 19 [145920/151166 (97%)]\tLoss: 0.001246\n","Train Epoch: 19 [146560/151166 (97%)]\tLoss: 0.000462\n","Train Epoch: 19 [147200/151166 (97%)]\tLoss: 0.000291\n","Train Epoch: 19 [147840/151166 (98%)]\tLoss: 0.000627\n","Train Epoch: 19 [148480/151166 (98%)]\tLoss: 0.001038\n","Train Epoch: 19 [149120/151166 (99%)]\tLoss: 0.000641\n","Train Epoch: 19 [149760/151166 (99%)]\tLoss: 0.000631\n","Train Epoch: 19 [150400/151166 (99%)]\tLoss: 0.001510\n","Train Epoch: 19 [151040/151166 (100%)]\tLoss: 0.000879\n","Sample outputs (log probs): tensor([[-1.6335e+01, -2.1285e+01, -1.4450e+01, -1.3796e+01, -1.4140e+01,\n","         -7.6062e+00, -2.0751e+01, -2.2047e+01, -1.0306e+01, -6.8034e+00,\n","         -1.8950e+01, -1.8388e+01, -1.4376e+01, -1.6373e+01, -1.5545e+01,\n","         -1.1956e+01, -2.0495e+01, -1.9640e+01, -1.4570e+01, -1.8741e-03,\n","         -1.5926e+01, -1.0608e+01, -1.9657e+01, -1.4646e+01, -8.7987e+00,\n","         -1.0004e+01],\n","        [-2.5336e+01, -2.1508e+01, -1.8477e-05, -2.2194e+01, -1.1800e+01,\n","         -1.6877e+01, -1.3123e+01, -2.9919e+01, -1.4674e+01, -2.1235e+01,\n","         -1.3478e+01, -1.1978e+01, -2.5589e+01, -2.3757e+01, -1.4582e+01,\n","         -2.2846e+01, -1.8635e+01, -1.7743e+01, -1.5444e+01, -1.9441e+01,\n","         -1.8359e+01, -2.7882e+01, -2.9551e+01, -2.7467e+01, -2.1852e+01,\n","         -1.9755e+01],\n","        [-9.4709e+00, -9.4734e+00, -2.5206e+01, -2.3959e+01, -2.4751e+01,\n","         -1.6881e+01, -2.3504e+01, -2.1468e+01, -3.0688e+01, -3.2210e+01,\n","         -1.8499e+01, -3.0397e+01, -1.9325e+01, -2.0649e+01, -2.7872e+01,\n","         -1.4358e+01, -2.0125e+01, -1.5460e-04, -2.3447e+01, -2.3919e+01,\n","         -3.2713e+01, -3.2145e+01, -2.8084e+01, -2.1728e+01, -2.8155e+01,\n","         -2.1338e+01],\n","        [-1.7855e+01, -1.2835e+01, -1.7602e+01, -2.3218e+01, -1.1962e+01,\n","         -1.9123e+01, -1.9672e+01, -2.0646e+01, -2.3285e+01, -3.1878e+01,\n","         -1.0861e+01, -2.0156e+01, -2.4160e+01, -1.7023e+01, -2.6841e+01,\n","         -1.5388e+01, -2.1227e+01, -2.8729e-05, -2.3286e+01, -2.4031e+01,\n","         -2.1943e+01, -2.4972e+01, -2.1652e+01, -1.7162e+01, -2.4685e+01,\n","         -1.5169e+01],\n","        [-1.9388e+01, -2.2467e+01, -1.4611e+01, -1.8223e+01, -1.6097e+01,\n","         -2.0263e+01, -1.8386e+01, -2.1747e+01, -1.2866e+01, -2.3829e+01,\n","         -1.4349e+01, -2.2411e-05, -2.6164e+01, -1.9024e+01, -2.4521e+01,\n","         -2.5469e+01, -2.3701e+01, -1.7686e+01, -2.3668e+01, -2.2032e+01,\n","         -1.3290e+01, -2.3808e+01, -2.3193e+01, -1.5954e+01, -2.2728e+01,\n","         -1.0992e+01]], device='cuda:0')\n","Predicted classes: tensor([19,  2, 17, 17, 11], device='cuda:0')\n","Target classes: tensor([19,  2, 17, 17, 11], device='cuda:0')\n","\n","Test set: Average loss: 0.001543, Total sum loss: 0.456741, Accuracy: 36936/37792 (98%)\n","\n","Class A: 1226/1247 (98%)\n","Class B: 804/816 (99%)\n","Class C: 1925/1965 (98%)\n","Class D: 814/868 (94%)\n","Class E: 1005/1024 (98%)\n","Class F: 1828/1869 (98%)\n","Class G: 507/519 (98%)\n","Class H: 602/621 (97%)\n","Class I: 2379/2410 (99%)\n","Class J: 733/754 (97%)\n","Class K: 490/502 (98%)\n","Class L: 964/987 (98%)\n","Class M: 1749/1774 (99%)\n","Class N: 1591/1622 (98%)\n","Class O: 4901/5064 (97%)\n","Class P: 1581/1615 (98%)\n","Class Q: 524/536 (98%)\n","Class R: 974/992 (98%)\n","Class S: 4171/4228 (99%)\n","Class T: 1917/1932 (99%)\n","Class U: 2507/2598 (96%)\n","Class V: 863/904 (95%)\n","Class W: 918/938 (98%)\n","Class X: 547/560 (98%)\n","Class Y: 900/924 (97%)\n","Class Z: 516/523 (99%)\n","Model saved with new best test loss: 0.0015 \n","\n","Train Epoch: 20 [0/151166 (0%)]\tLoss: 0.000210\n","Train Epoch: 20 [640/151166 (0%)]\tLoss: 0.000229\n","Train Epoch: 20 [1280/151166 (1%)]\tLoss: 0.000446\n","Train Epoch: 20 [1920/151166 (1%)]\tLoss: 0.000818\n","Train Epoch: 20 [2560/151166 (2%)]\tLoss: 0.000854\n","Train Epoch: 20 [3200/151166 (2%)]\tLoss: 0.001317\n","Train Epoch: 20 [3840/151166 (3%)]\tLoss: 0.000217\n","Train Epoch: 20 [4480/151166 (3%)]\tLoss: 0.000383\n","Train Epoch: 20 [5120/151166 (3%)]\tLoss: 0.001260\n","Train Epoch: 20 [5760/151166 (4%)]\tLoss: 0.000486\n","Train Epoch: 20 [6400/151166 (4%)]\tLoss: 0.000646\n","Train Epoch: 20 [7040/151166 (5%)]\tLoss: 0.000244\n","Train Epoch: 20 [7680/151166 (5%)]\tLoss: 0.000294\n","Train Epoch: 20 [8320/151166 (6%)]\tLoss: 0.001808\n","Train Epoch: 20 [8960/151166 (6%)]\tLoss: 0.000359\n","Train Epoch: 20 [9600/151166 (6%)]\tLoss: 0.000455\n","Train Epoch: 20 [10240/151166 (7%)]\tLoss: 0.000688\n","Train Epoch: 20 [10880/151166 (7%)]\tLoss: 0.001059\n","Train Epoch: 20 [11520/151166 (8%)]\tLoss: 0.000355\n","Train Epoch: 20 [12160/151166 (8%)]\tLoss: 0.000260\n","Train Epoch: 20 [12800/151166 (8%)]\tLoss: 0.000280\n","Train Epoch: 20 [13440/151166 (9%)]\tLoss: 0.001210\n","Train Epoch: 20 [14080/151166 (9%)]\tLoss: 0.000490\n","Train Epoch: 20 [14720/151166 (10%)]\tLoss: 0.001143\n","Train Epoch: 20 [15360/151166 (10%)]\tLoss: 0.000109\n","Train Epoch: 20 [16000/151166 (11%)]\tLoss: 0.000512\n","Train Epoch: 20 [16640/151166 (11%)]\tLoss: 0.002845\n","Train Epoch: 20 [17280/151166 (11%)]\tLoss: 0.002255\n","Train Epoch: 20 [17920/151166 (12%)]\tLoss: 0.000534\n","Train Epoch: 20 [18560/151166 (12%)]\tLoss: 0.000438\n","Train Epoch: 20 [19200/151166 (13%)]\tLoss: 0.000695\n","Train Epoch: 20 [19840/151166 (13%)]\tLoss: 0.000374\n","Train Epoch: 20 [20480/151166 (14%)]\tLoss: 0.002345\n","Train Epoch: 20 [21120/151166 (14%)]\tLoss: 0.004444\n","Train Epoch: 20 [21760/151166 (14%)]\tLoss: 0.000192\n","Train Epoch: 20 [22400/151166 (15%)]\tLoss: 0.000304\n","Train Epoch: 20 [23040/151166 (15%)]\tLoss: 0.000883\n","Train Epoch: 20 [23680/151166 (16%)]\tLoss: 0.000551\n","Train Epoch: 20 [24320/151166 (16%)]\tLoss: 0.000316\n","Train Epoch: 20 [24960/151166 (17%)]\tLoss: 0.000349\n","Train Epoch: 20 [25600/151166 (17%)]\tLoss: 0.000435\n","Train Epoch: 20 [26240/151166 (17%)]\tLoss: 0.001333\n","Train Epoch: 20 [26880/151166 (18%)]\tLoss: 0.000767\n","Train Epoch: 20 [27520/151166 (18%)]\tLoss: 0.000537\n","Train Epoch: 20 [28160/151166 (19%)]\tLoss: 0.000145\n","Train Epoch: 20 [28800/151166 (19%)]\tLoss: 0.001044\n","Train Epoch: 20 [29440/151166 (19%)]\tLoss: 0.000259\n","Train Epoch: 20 [30080/151166 (20%)]\tLoss: 0.000592\n","Train Epoch: 20 [30720/151166 (20%)]\tLoss: 0.000798\n","Train Epoch: 20 [31360/151166 (21%)]\tLoss: 0.000219\n","Train Epoch: 20 [32000/151166 (21%)]\tLoss: 0.000117\n","Train Epoch: 20 [32640/151166 (22%)]\tLoss: 0.000139\n","Train Epoch: 20 [33280/151166 (22%)]\tLoss: 0.001102\n","Train Epoch: 20 [33920/151166 (22%)]\tLoss: 0.000937\n","Train Epoch: 20 [34560/151166 (23%)]\tLoss: 0.000213\n","Train Epoch: 20 [35200/151166 (23%)]\tLoss: 0.001235\n","Train Epoch: 20 [35840/151166 (24%)]\tLoss: 0.000792\n","Train Epoch: 20 [36480/151166 (24%)]\tLoss: 0.000946\n","Train Epoch: 20 [37120/151166 (25%)]\tLoss: 0.000773\n","Train Epoch: 20 [37760/151166 (25%)]\tLoss: 0.000533\n","Train Epoch: 20 [38400/151166 (25%)]\tLoss: 0.000609\n","Train Epoch: 20 [39040/151166 (26%)]\tLoss: 0.000342\n","Train Epoch: 20 [39680/151166 (26%)]\tLoss: 0.000330\n","Train Epoch: 20 [40320/151166 (27%)]\tLoss: 0.000178\n","Train Epoch: 20 [40960/151166 (27%)]\tLoss: 0.000167\n","Train Epoch: 20 [41600/151166 (28%)]\tLoss: 0.000109\n","Train Epoch: 20 [42240/151166 (28%)]\tLoss: 0.000132\n","Train Epoch: 20 [42880/151166 (28%)]\tLoss: 0.000818\n","Train Epoch: 20 [43520/151166 (29%)]\tLoss: 0.000327\n","Train Epoch: 20 [44160/151166 (29%)]\tLoss: 0.000442\n","Train Epoch: 20 [44800/151166 (30%)]\tLoss: 0.000736\n","Train Epoch: 20 [45440/151166 (30%)]\tLoss: 0.000738\n","Train Epoch: 20 [46080/151166 (30%)]\tLoss: 0.000786\n","Train Epoch: 20 [46720/151166 (31%)]\tLoss: 0.000332\n","Train Epoch: 20 [47360/151166 (31%)]\tLoss: 0.000435\n","Train Epoch: 20 [48000/151166 (32%)]\tLoss: 0.000184\n","Train Epoch: 20 [48640/151166 (32%)]\tLoss: 0.000955\n","Train Epoch: 20 [49280/151166 (33%)]\tLoss: 0.000169\n","Train Epoch: 20 [49920/151166 (33%)]\tLoss: 0.002834\n","Train Epoch: 20 [50560/151166 (33%)]\tLoss: 0.000176\n","Train Epoch: 20 [51200/151166 (34%)]\tLoss: 0.000396\n","Train Epoch: 20 [51840/151166 (34%)]\tLoss: 0.000169\n","Train Epoch: 20 [52480/151166 (35%)]\tLoss: 0.001028\n","Train Epoch: 20 [53120/151166 (35%)]\tLoss: 0.000594\n","Train Epoch: 20 [53760/151166 (36%)]\tLoss: 0.000369\n","Train Epoch: 20 [54400/151166 (36%)]\tLoss: 0.001041\n","Train Epoch: 20 [55040/151166 (36%)]\tLoss: 0.000890\n","Train Epoch: 20 [55680/151166 (37%)]\tLoss: 0.000570\n","Train Epoch: 20 [56320/151166 (37%)]\tLoss: 0.001721\n","Train Epoch: 20 [56960/151166 (38%)]\tLoss: 0.000150\n","Train Epoch: 20 [57600/151166 (38%)]\tLoss: 0.001310\n","Train Epoch: 20 [58240/151166 (39%)]\tLoss: 0.000835\n","Train Epoch: 20 [58880/151166 (39%)]\tLoss: 0.000170\n","Train Epoch: 20 [59520/151166 (39%)]\tLoss: 0.000198\n","Train Epoch: 20 [60160/151166 (40%)]\tLoss: 0.001291\n","Train Epoch: 20 [60800/151166 (40%)]\tLoss: 0.000138\n","Train Epoch: 20 [61440/151166 (41%)]\tLoss: 0.001038\n","Train Epoch: 20 [62080/151166 (41%)]\tLoss: 0.000378\n","Train Epoch: 20 [62720/151166 (41%)]\tLoss: 0.002881\n","Train Epoch: 20 [63360/151166 (42%)]\tLoss: 0.000690\n","Train Epoch: 20 [64000/151166 (42%)]\tLoss: 0.000303\n","Train Epoch: 20 [64640/151166 (43%)]\tLoss: 0.000694\n","Train Epoch: 20 [65280/151166 (43%)]\tLoss: 0.000839\n","Train Epoch: 20 [65920/151166 (44%)]\tLoss: 0.000197\n","Train Epoch: 20 [66560/151166 (44%)]\tLoss: 0.000352\n","Train Epoch: 20 [67200/151166 (44%)]\tLoss: 0.000119\n","Train Epoch: 20 [67840/151166 (45%)]\tLoss: 0.001018\n","Train Epoch: 20 [68480/151166 (45%)]\tLoss: 0.000728\n","Train Epoch: 20 [69120/151166 (46%)]\tLoss: 0.000696\n","Train Epoch: 20 [69760/151166 (46%)]\tLoss: 0.001077\n","Train Epoch: 20 [70400/151166 (47%)]\tLoss: 0.000232\n","Train Epoch: 20 [71040/151166 (47%)]\tLoss: 0.001135\n","Train Epoch: 20 [71680/151166 (47%)]\tLoss: 0.001615\n","Train Epoch: 20 [72320/151166 (48%)]\tLoss: 0.000191\n","Train Epoch: 20 [72960/151166 (48%)]\tLoss: 0.000376\n","Train Epoch: 20 [73600/151166 (49%)]\tLoss: 0.000595\n","Train Epoch: 20 [74240/151166 (49%)]\tLoss: 0.000501\n","Train Epoch: 20 [74880/151166 (50%)]\tLoss: 0.001183\n","Train Epoch: 20 [75520/151166 (50%)]\tLoss: 0.000458\n","Train Epoch: 20 [76160/151166 (50%)]\tLoss: 0.000406\n","Train Epoch: 20 [76800/151166 (51%)]\tLoss: 0.000476\n","Train Epoch: 20 [77440/151166 (51%)]\tLoss: 0.001091\n","Train Epoch: 20 [78080/151166 (52%)]\tLoss: 0.001432\n","Train Epoch: 20 [78720/151166 (52%)]\tLoss: 0.000246\n","Train Epoch: 20 [79360/151166 (52%)]\tLoss: 0.001834\n","Train Epoch: 20 [80000/151166 (53%)]\tLoss: 0.000326\n","Train Epoch: 20 [80640/151166 (53%)]\tLoss: 0.000669\n","Train Epoch: 20 [81280/151166 (54%)]\tLoss: 0.000918\n","Train Epoch: 20 [81920/151166 (54%)]\tLoss: 0.000936\n","Train Epoch: 20 [82560/151166 (55%)]\tLoss: 0.000137\n","Train Epoch: 20 [83200/151166 (55%)]\tLoss: 0.001026\n","Train Epoch: 20 [83840/151166 (55%)]\tLoss: 0.000337\n","Train Epoch: 20 [84480/151166 (56%)]\tLoss: 0.001299\n","Train Epoch: 20 [85120/151166 (56%)]\tLoss: 0.000463\n","Train Epoch: 20 [85760/151166 (57%)]\tLoss: 0.000370\n","Train Epoch: 20 [86400/151166 (57%)]\tLoss: 0.000154\n","Train Epoch: 20 [87040/151166 (58%)]\tLoss: 0.001054\n","Train Epoch: 20 [87680/151166 (58%)]\tLoss: 0.000967\n","Train Epoch: 20 [88320/151166 (58%)]\tLoss: 0.001449\n","Train Epoch: 20 [88960/151166 (59%)]\tLoss: 0.000203\n","Train Epoch: 20 [89600/151166 (59%)]\tLoss: 0.002030\n","Train Epoch: 20 [90240/151166 (60%)]\tLoss: 0.000221\n","Train Epoch: 20 [90880/151166 (60%)]\tLoss: 0.001746\n","Train Epoch: 20 [91520/151166 (61%)]\tLoss: 0.000483\n","Train Epoch: 20 [92160/151166 (61%)]\tLoss: 0.000131\n","Train Epoch: 20 [92800/151166 (61%)]\tLoss: 0.000194\n","Train Epoch: 20 [93440/151166 (62%)]\tLoss: 0.000700\n","Train Epoch: 20 [94080/151166 (62%)]\tLoss: 0.000209\n","Train Epoch: 20 [94720/151166 (63%)]\tLoss: 0.000264\n","Train Epoch: 20 [95360/151166 (63%)]\tLoss: 0.000178\n","Train Epoch: 20 [96000/151166 (64%)]\tLoss: 0.000510\n","Train Epoch: 20 [96640/151166 (64%)]\tLoss: 0.000275\n","Train Epoch: 20 [97280/151166 (64%)]\tLoss: 0.000307\n","Train Epoch: 20 [97920/151166 (65%)]\tLoss: 0.000430\n","Train Epoch: 20 [98560/151166 (65%)]\tLoss: 0.000454\n","Train Epoch: 20 [99200/151166 (66%)]\tLoss: 0.000327\n","Train Epoch: 20 [99840/151166 (66%)]\tLoss: 0.000859\n","Train Epoch: 20 [100480/151166 (66%)]\tLoss: 0.000862\n","Train Epoch: 20 [101120/151166 (67%)]\tLoss: 0.000740\n","Train Epoch: 20 [101760/151166 (67%)]\tLoss: 0.000289\n","Train Epoch: 20 [102400/151166 (68%)]\tLoss: 0.000201\n","Train Epoch: 20 [103040/151166 (68%)]\tLoss: 0.000441\n","Train Epoch: 20 [103680/151166 (69%)]\tLoss: 0.000299\n","Train Epoch: 20 [104320/151166 (69%)]\tLoss: 0.000158\n","Train Epoch: 20 [104960/151166 (69%)]\tLoss: 0.000449\n","Train Epoch: 20 [105600/151166 (70%)]\tLoss: 0.000681\n","Train Epoch: 20 [106240/151166 (70%)]\tLoss: 0.000191\n","Train Epoch: 20 [106880/151166 (71%)]\tLoss: 0.001170\n","Train Epoch: 20 [107520/151166 (71%)]\tLoss: 0.000418\n","Train Epoch: 20 [108160/151166 (72%)]\tLoss: 0.000205\n","Train Epoch: 20 [108800/151166 (72%)]\tLoss: 0.000401\n","Train Epoch: 20 [109440/151166 (72%)]\tLoss: 0.000871\n","Train Epoch: 20 [110080/151166 (73%)]\tLoss: 0.001198\n","Train Epoch: 20 [110720/151166 (73%)]\tLoss: 0.000443\n","Train Epoch: 20 [111360/151166 (74%)]\tLoss: 0.000426\n","Train Epoch: 20 [112000/151166 (74%)]\tLoss: 0.000470\n","Train Epoch: 20 [112640/151166 (75%)]\tLoss: 0.000297\n","Train Epoch: 20 [113280/151166 (75%)]\tLoss: 0.000112\n","Train Epoch: 20 [113920/151166 (75%)]\tLoss: 0.001160\n","Train Epoch: 20 [114560/151166 (76%)]\tLoss: 0.000338\n","Train Epoch: 20 [115200/151166 (76%)]\tLoss: 0.000844\n","Train Epoch: 20 [115840/151166 (77%)]\tLoss: 0.003399\n","Train Epoch: 20 [116480/151166 (77%)]\tLoss: 0.000773\n","Train Epoch: 20 [117120/151166 (77%)]\tLoss: 0.001225\n","Train Epoch: 20 [117760/151166 (78%)]\tLoss: 0.000385\n","Train Epoch: 20 [118400/151166 (78%)]\tLoss: 0.000165\n","Train Epoch: 20 [119040/151166 (79%)]\tLoss: 0.000461\n","Train Epoch: 20 [119680/151166 (79%)]\tLoss: 0.000173\n","Train Epoch: 20 [120320/151166 (80%)]\tLoss: 0.000268\n","Train Epoch: 20 [120960/151166 (80%)]\tLoss: 0.000166\n","Train Epoch: 20 [121600/151166 (80%)]\tLoss: 0.000046\n","Train Epoch: 20 [122240/151166 (81%)]\tLoss: 0.000399\n","Train Epoch: 20 [122880/151166 (81%)]\tLoss: 0.001029\n","Train Epoch: 20 [123520/151166 (82%)]\tLoss: 0.000341\n","Train Epoch: 20 [124160/151166 (82%)]\tLoss: 0.000792\n","Train Epoch: 20 [124800/151166 (83%)]\tLoss: 0.000658\n","Train Epoch: 20 [125440/151166 (83%)]\tLoss: 0.000122\n","Train Epoch: 20 [126080/151166 (83%)]\tLoss: 0.000394\n","Train Epoch: 20 [126720/151166 (84%)]\tLoss: 0.000387\n","Train Epoch: 20 [127360/151166 (84%)]\tLoss: 0.000897\n","Train Epoch: 20 [128000/151166 (85%)]\tLoss: 0.003706\n","Train Epoch: 20 [128640/151166 (85%)]\tLoss: 0.000261\n","Train Epoch: 20 [129280/151166 (86%)]\tLoss: 0.000909\n","Train Epoch: 20 [129920/151166 (86%)]\tLoss: 0.000776\n","Train Epoch: 20 [130560/151166 (86%)]\tLoss: 0.000235\n","Train Epoch: 20 [131200/151166 (87%)]\tLoss: 0.000165\n","Train Epoch: 20 [131840/151166 (87%)]\tLoss: 0.000770\n","Train Epoch: 20 [132480/151166 (88%)]\tLoss: 0.000421\n","Train Epoch: 20 [133120/151166 (88%)]\tLoss: 0.000110\n","Train Epoch: 20 [133760/151166 (88%)]\tLoss: 0.000417\n","Train Epoch: 20 [134400/151166 (89%)]\tLoss: 0.000929\n","Train Epoch: 20 [135040/151166 (89%)]\tLoss: 0.000415\n","Train Epoch: 20 [135680/151166 (90%)]\tLoss: 0.000222\n","Train Epoch: 20 [136320/151166 (90%)]\tLoss: 0.000809\n","Train Epoch: 20 [136960/151166 (91%)]\tLoss: 0.000700\n","Train Epoch: 20 [137600/151166 (91%)]\tLoss: 0.000225\n","Train Epoch: 20 [138240/151166 (91%)]\tLoss: 0.000942\n","Train Epoch: 20 [138880/151166 (92%)]\tLoss: 0.000124\n","Train Epoch: 20 [139520/151166 (92%)]\tLoss: 0.000156\n","Train Epoch: 20 [140160/151166 (93%)]\tLoss: 0.000530\n","Train Epoch: 20 [140800/151166 (93%)]\tLoss: 0.001682\n","Train Epoch: 20 [141440/151166 (94%)]\tLoss: 0.001885\n","Train Epoch: 20 [142080/151166 (94%)]\tLoss: 0.000104\n","Train Epoch: 20 [142720/151166 (94%)]\tLoss: 0.001919\n","Train Epoch: 20 [143360/151166 (95%)]\tLoss: 0.000675\n","Train Epoch: 20 [144000/151166 (95%)]\tLoss: 0.000241\n","Train Epoch: 20 [144640/151166 (96%)]\tLoss: 0.000589\n","Train Epoch: 20 [145280/151166 (96%)]\tLoss: 0.000254\n","Train Epoch: 20 [145920/151166 (97%)]\tLoss: 0.000149\n","Train Epoch: 20 [146560/151166 (97%)]\tLoss: 0.000521\n","Train Epoch: 20 [147200/151166 (97%)]\tLoss: 0.000840\n","Train Epoch: 20 [147840/151166 (98%)]\tLoss: 0.000393\n","Train Epoch: 20 [148480/151166 (98%)]\tLoss: 0.000846\n","Train Epoch: 20 [149120/151166 (99%)]\tLoss: 0.000612\n","Train Epoch: 20 [149760/151166 (99%)]\tLoss: 0.000226\n","Train Epoch: 20 [150400/151166 (99%)]\tLoss: 0.000988\n","Train Epoch: 20 [151040/151166 (100%)]\tLoss: 0.000125\n","Sample outputs (log probs): tensor([[-2.6235e+01, -2.0174e+01, -1.3247e+01, -1.1956e+01, -1.3060e+01,\n","         -1.2639e+01, -1.8739e+01, -2.9371e+01, -3.5852e-04, -8.1360e+00,\n","         -2.4630e+01, -1.3062e+01, -2.7322e+01, -2.2592e+01, -1.7845e+01,\n","         -2.3348e+01, -1.9563e+01, -3.0101e+01, -1.0143e+01, -1.2574e+01,\n","         -1.7270e+01, -2.2352e+01, -2.0514e+01, -1.9461e+01, -1.7710e+01,\n","         -1.1848e+01],\n","        [-2.7094e+01, -1.8348e+01, -1.4773e+01, -1.7247e+01, -9.4896e+00,\n","         -7.8581e+00, -1.6712e+01, -3.3303e+01, -1.2795e+01, -9.8145e+00,\n","         -2.6135e+01, -1.9158e+01, -2.8868e+01, -2.9362e+01, -1.6734e+01,\n","         -2.1166e+01, -2.0709e+01, -3.3367e+01, -5.2033e-04, -1.6931e+01,\n","         -2.8365e+01, -2.5973e+01, -3.0131e+01, -2.7186e+01, -1.8021e+01,\n","         -2.3090e+01],\n","        [-2.3350e+01, -1.9557e+01, -1.2536e+01, -1.1488e+01, -2.6276e+01,\n","         -2.4407e+01, -1.8998e+01, -2.8032e+01, -2.0092e+01, -1.6755e+01,\n","         -3.2782e+01, -2.4142e+01, -2.2617e+01, -1.8624e+01, -1.7762e-05,\n","         -1.7387e+01, -1.3255e+01, -2.8450e+01, -1.6844e+01, -2.1733e+01,\n","         -1.3129e+01, -2.2344e+01, -2.2927e+01, -3.5290e+01, -2.0613e+01,\n","         -2.8343e+01],\n","        [-8.1341e+00, -6.8652e+00, -8.6777e+00, -4.3876e+00, -1.2067e+01,\n","         -3.5148e+00, -7.2911e+00, -8.0899e+00, -1.5720e+00, -1.7412e+00,\n","         -9.6012e+00, -1.6693e+00, -1.2333e+01, -5.6919e+00, -9.7508e+00,\n","         -8.1061e+00, -6.5650e+00, -1.3372e+01, -2.7012e+00, -6.5197e+00,\n","         -5.8040e+00, -7.7357e+00, -7.3779e+00, -1.3061e+00, -3.5194e+00,\n","         -5.1854e+00],\n","        [-3.5726e+01, -2.0790e+01, -1.8967e+01, -2.3576e+01, -1.7424e+01,\n","         -1.3267e+01, -1.6768e+01, -3.8994e+01, -1.6846e+01, -1.2516e+01,\n","         -3.2222e+01, -2.2507e+01, -3.9717e+01, -3.5720e+01, -2.4261e+01,\n","         -3.0664e+01, -2.6252e+01, -4.3779e+01, -5.4836e-06, -2.4532e+01,\n","         -3.4865e+01, -3.4827e+01, -3.4423e+01, -3.2859e+01, -2.1720e+01,\n","         -2.7828e+01]], device='cuda:0')\n","Predicted classes: tensor([ 8, 18, 14, 23, 18], device='cuda:0')\n","Target classes: tensor([ 8, 18, 14, 18, 18], device='cuda:0')\n","\n","Test set: Average loss: 0.001557, Total sum loss: 0.460973, Accuracy: 36933/37792 (98%)\n","\n","Class A: 1227/1247 (98%)\n","Class B: 803/816 (98%)\n","Class C: 1921/1965 (98%)\n","Class D: 811/868 (93%)\n","Class E: 1010/1024 (99%)\n","Class F: 1833/1869 (98%)\n","Class G: 504/519 (97%)\n","Class H: 605/621 (97%)\n","Class I: 2380/2410 (99%)\n","Class J: 732/754 (97%)\n","Class K: 490/502 (98%)\n","Class L: 968/987 (98%)\n","Class M: 1746/1774 (98%)\n","Class N: 1585/1622 (98%)\n","Class O: 4909/5064 (97%)\n","Class P: 1587/1615 (98%)\n","Class Q: 515/536 (96%)\n","Class R: 972/992 (98%)\n","Class S: 4186/4228 (99%)\n","Class T: 1914/1932 (99%)\n","Class U: 2489/2598 (96%)\n","Class V: 867/904 (96%)\n","Class W: 918/938 (98%)\n","Class X: 547/560 (98%)\n","Class Y: 900/924 (97%)\n","Class Z: 514/523 (98%)\n","Train Epoch: 21 [0/151166 (0%)]\tLoss: 0.001828\n","Train Epoch: 21 [640/151166 (0%)]\tLoss: 0.000689\n","Train Epoch: 21 [1280/151166 (1%)]\tLoss: 0.000081\n","Train Epoch: 21 [1920/151166 (1%)]\tLoss: 0.000454\n","Train Epoch: 21 [2560/151166 (2%)]\tLoss: 0.001238\n","Train Epoch: 21 [3200/151166 (2%)]\tLoss: 0.000154\n","Train Epoch: 21 [3840/151166 (3%)]\tLoss: 0.000187\n","Train Epoch: 21 [4480/151166 (3%)]\tLoss: 0.000278\n","Train Epoch: 21 [5120/151166 (3%)]\tLoss: 0.001609\n","Train Epoch: 21 [5760/151166 (4%)]\tLoss: 0.001391\n","Train Epoch: 21 [6400/151166 (4%)]\tLoss: 0.000120\n","Train Epoch: 21 [7040/151166 (5%)]\tLoss: 0.000390\n","Train Epoch: 21 [7680/151166 (5%)]\tLoss: 0.001213\n","Train Epoch: 21 [8320/151166 (6%)]\tLoss: 0.000428\n","Train Epoch: 21 [8960/151166 (6%)]\tLoss: 0.000660\n","Train Epoch: 21 [9600/151166 (6%)]\tLoss: 0.000320\n","Train Epoch: 21 [10240/151166 (7%)]\tLoss: 0.000176\n","Train Epoch: 21 [10880/151166 (7%)]\tLoss: 0.000163\n","Train Epoch: 21 [11520/151166 (8%)]\tLoss: 0.001619\n","Train Epoch: 21 [12160/151166 (8%)]\tLoss: 0.000568\n","Train Epoch: 21 [12800/151166 (8%)]\tLoss: 0.000255\n","Train Epoch: 21 [13440/151166 (9%)]\tLoss: 0.000298\n","Train Epoch: 21 [14080/151166 (9%)]\tLoss: 0.000380\n","Train Epoch: 21 [14720/151166 (10%)]\tLoss: 0.000466\n","Train Epoch: 21 [15360/151166 (10%)]\tLoss: 0.000586\n","Train Epoch: 21 [16000/151166 (11%)]\tLoss: 0.000120\n","Train Epoch: 21 [16640/151166 (11%)]\tLoss: 0.000459\n","Train Epoch: 21 [17280/151166 (11%)]\tLoss: 0.000153\n","Train Epoch: 21 [17920/151166 (12%)]\tLoss: 0.000290\n","Train Epoch: 21 [18560/151166 (12%)]\tLoss: 0.000384\n","Train Epoch: 21 [19200/151166 (13%)]\tLoss: 0.001070\n","Train Epoch: 21 [19840/151166 (13%)]\tLoss: 0.000485\n","Train Epoch: 21 [20480/151166 (14%)]\tLoss: 0.000967\n","Train Epoch: 21 [21120/151166 (14%)]\tLoss: 0.000344\n","Train Epoch: 21 [21760/151166 (14%)]\tLoss: 0.000472\n","Train Epoch: 21 [22400/151166 (15%)]\tLoss: 0.001416\n","Train Epoch: 21 [23040/151166 (15%)]\tLoss: 0.000686\n","Train Epoch: 21 [23680/151166 (16%)]\tLoss: 0.000184\n","Train Epoch: 21 [24320/151166 (16%)]\tLoss: 0.000563\n","Train Epoch: 21 [24960/151166 (17%)]\tLoss: 0.000579\n","Train Epoch: 21 [25600/151166 (17%)]\tLoss: 0.000262\n","Train Epoch: 21 [26240/151166 (17%)]\tLoss: 0.000152\n","Train Epoch: 21 [26880/151166 (18%)]\tLoss: 0.001333\n","Train Epoch: 21 [27520/151166 (18%)]\tLoss: 0.000201\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-2bfe8fac28d3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-2bfe8fac28d3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     train_losses, train_accuracies, test_losses, test_accuracies = train_and_evaluate(\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     )\n","\u001b[0;32m<ipython-input-6-2bfe8fac28d3>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(args, model, device, train_loader, test_loader, optimizer, scheduler, criterion)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-2bfe8fac28d3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch, criterion)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## Add the custom dataset"],"metadata":{"id":"KBnzUvVc4l_3"}},{"cell_type":"code","source":["import os\n","import random\n","import argparse\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, random_split, ConcatDataset\n","from torch.optim.lr_scheduler import StepLR\n","import matplotlib.pyplot as plt\n","\n","# Define the neural network (unchanged)\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 64, 3, 1)\n","        self.conv2 = nn.Conv2d(64, 128, 3, 1)\n","        self.conv3 = nn.Conv2d(128, 256, 3, 1)\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.dropout2 = nn.Dropout(0.4)\n","        self.fc1 = nn.Linear(256 * 5 * 5, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 26)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.conv3(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        output = F.log_softmax(x, dim=1)\n","        return output\n","\n","# Custom transformation to add Salt-and-Pepper noise (unchanged)\n","class AddSaltPepperNoise:\n","    def __init__(self, salt_prob=0.01, pepper_prob=0.01):\n","        self.salt_prob = salt_prob\n","        self.pepper_prob = pepper_prob\n","\n","    def __call__(self, tensor):\n","        img = tensor.numpy()\n","        noise = np.random.random(img.shape)\n","        img[noise < self.salt_prob] = 1.0\n","        img[noise > (1 - self.pepper_prob)] = 0.0\n","        return torch.from_numpy(img)\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + '(salt_prob={0}, pepper_prob={1})'.format(self.salt_prob, self.pepper_prob)\n","\n","# Training Function (unchanged)\n","def train(args, model, device, train_loader, optimizer, epoch, criterion):\n","    model.train()\n","    train_loss = 0\n","    correct = 0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        pred = output.argmax(dim=1, keepdim=True)\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","        if batch_idx % args.log_interval == 0:\n","            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n","\n","    train_loss /= len(train_loader)\n","    accuracy = 100. * correct / len(train_loader.dataset)\n","    return train_loss, accuracy\n","\n","# Testing Function (unchanged)\n","def test(model, device, test_loader, criterion):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    class_correct = [0] * 26\n","    class_total = [0] * 26\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(test_loader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            batch_loss = criterion(output, target).item()\n","            test_loss += batch_loss\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","            if batch_idx == 0:\n","                print(f\"Sample outputs (log probs): {output[:5]}\")\n","                print(f\"Predicted classes: {pred[:5].view(-1)}\")\n","                print(f\"Target classes: {target[:5]}\")\n","\n","            for t, p in zip(target, pred):\n","                class_correct[t.item()] += (t == p).item()\n","                class_total[t.item()] += 1\n","\n","    avg_test_loss = test_loss / len(test_loader)\n","    accuracy = 100. * correct / len(test_loader.dataset)\n","\n","    print(f'\\nTest set: Average loss: {avg_test_loss:.6f}, Total sum loss: {test_loss:.6f}, '\n","          f'Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n')\n","    for i, char in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n","        if class_total[i] > 0:\n","            print(f'Class {char}: {class_correct[i]}/{class_total[i]} ({100. * class_correct[i] / class_total[i]:.0f}%)')\n","\n","    return avg_test_loss, accuracy\n","\n","# Train and Evaluate (unchanged)\n","def train_and_evaluate(args, model, device, train_loader, test_loader, optimizer, scheduler, criterion):\n","    test_losses = []\n","    test_accuracies = []\n","    train_losses = []\n","    train_accuracies = []\n","\n","    best_test_loss = float('inf')\n","    patience = 8\n","    no_improvement_count = 0\n","\n","    model_dir = f\"/content/drive/MyDrive/Capitals_Model_seed_{args.seed}\"\n","    if not os.path.exists(model_dir):\n","        os.makedirs(model_dir)\n","\n","    for epoch in range(1, args.epochs + 1):\n","        train_loss, train_accuracy = train(args, model, device, train_loader, optimizer, epoch, criterion)\n","        test_loss, test_accuracy = test(model, device, test_loader, criterion)\n","\n","        train_losses.append(train_loss)\n","        train_accuracies.append(train_accuracy)\n","        test_losses.append(test_loss)\n","        test_accuracies.append(test_accuracy)\n","\n","        if test_loss < best_test_loss:\n","            best_test_loss = test_loss\n","            no_improvement_count = 0\n","            if args.save_model and epoch > 1:\n","                model_filename = f\"capitals_cnn_epoch:{epoch}_test-accuracy:{test_accuracy:.4f}_test-loss:{test_loss:.4f}.pt\"\n","                model_path = os.path.join(model_dir, model_filename)\n","                try:\n","                    torch.save(model.state_dict(), model_path)\n","                    print(f\"Model saved with new best test loss: {best_test_loss:.4f} \\n\")\n","                except Exception as e:\n","                    print(f\"Error saving model: {e}\")\n","        else:\n","            no_improvement_count += 1\n","\n","        if no_improvement_count >= patience:\n","            print(f\"\\nEarly stopping triggered after {epoch} epochs. No improvement in test loss for {patience} consecutive epochs.\")\n","            break\n","\n","        scheduler.step()\n","\n","    return train_losses, train_accuracies, test_losses, test_accuracies\n","\n","# Plot results (unchanged)\n","def plot_results(train_losses, train_accuracies, test_losses, test_accuracies):\n","    epochs = range(1, len(train_losses) + 1)\n","    plt.figure(figsize=(12, 5))\n","\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, train_losses, 'o-', label='Train Loss')\n","    plt.plot(epochs, test_losses, 'o-', label='Test Loss')\n","    plt.title('Loss vs. Epoch')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, train_accuracies, 'o-', label='Train Accuracy')\n","    plt.plot(epochs, test_accuracies, 'o-', label='Test Accuracy')\n","    plt.title('Accuracy vs. Epoch')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy (%)')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Main function (modified)\n","def main():\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    random_seed = random.randint(0, 100000)\n","    print(f\"Using random seed: {random_seed}\")\n","\n","    torch.manual_seed(random_seed)\n","    random.seed(random_seed)\n","\n","    args = argparse.Namespace(\n","        batch_size=64,\n","        test_batch_size=128,\n","        epochs=100,\n","        lr=1,\n","        gamma=0.9,\n","        no_cuda=False,\n","        no_mps=False,\n","        dry_run=False,\n","        seed=random_seed,\n","        log_interval=10,\n","        save_model=True\n","    )\n","\n","    use_cuda = not args.no_cuda and torch.cuda.is_available()\n","    use_mps = not args.no_mps and torch.backends.mps.is_available()\n","\n","    torch.manual_seed(args.seed)\n","\n","    if use_cuda:\n","        device = torch.device(\"cuda\")\n","    elif use_mps:\n","        device = torch.device(\"mps\")\n","    else:\n","        device = torch.device(\"cpu\")\n","\n","    train_kwargs = {'batch_size': args.batch_size}\n","    test_kwargs = {'batch_size': args.test_batch_size}\n","\n","    if use_cuda:\n","        cuda_kwargs = {'num_workers': 1, 'pin_memory': True, 'shuffle': True}\n","        train_kwargs.update(cuda_kwargs)\n","        test_kwargs.update(cuda_kwargs)\n","\n","    transform_train = transforms.Compose([\n","        transforms.Grayscale(),\n","        transforms.Resize((28, 28)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,)),\n","        transforms.RandomAffine(degrees=(-5, 5), translate=(0.1, 0.1), scale=(0.9, 1.1), shear=5),\n","        transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1)], p=0.3),\n","        transforms.RandomApply([AddSaltPepperNoise(salt_prob=0.01, pepper_prob=0.01)], p=0.2)\n","    ])\n","\n","    transform_test = transforms.Compose([\n","        transforms.Grayscale(),\n","        transforms.Resize((28, 28)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,))\n","    ])\n","\n","    # Load both datasets\n","    emnist_data_path = '/content/emnist_capitals_dataset'\n","    letters_data_path = '/content/letters'\n","\n","    emnist_dataset = datasets.ImageFolder(root=emnist_data_path, transform=transform_train)\n","    letters_dataset = datasets.ImageFolder(root=letters_data_path, transform=transform_train)\n","\n","    # Combine the datasets\n","    combined_dataset = ConcatDataset([emnist_dataset, letters_dataset])\n","\n","    # Split into train and test\n","    train_size = int(0.8 * len(combined_dataset))\n","    test_size = len(combined_dataset) - train_size\n","    train_dataset, test_dataset = random_split(combined_dataset, [train_size, test_size])\n","\n","    # Apply test transform to test dataset\n","    test_dataset.dataset.datasets[0].transform = transform_test  # EMNIST\n","    test_dataset.dataset.datasets[1].transform = transform_test  # Letters\n","\n","    # Class counts: EMNIST + Letters (200 images per class for Letters)\n","    emnist_class_counts = [6407, 3878, 10094, 4562, 4934, 9182, 2517, 3152, 11946, 3762, 2468, 5076,\n","                           9002, 8237, 24983, 8347, 2605, 5073, 20764, 9820, 12602, 4637, 4695, 2771, 4743, 2701]\n","    letters_class_counts = [200] * 26  # 200 images per class\n","    combined_class_counts = [emnist + letters for emnist, letters in zip(emnist_class_counts, letters_class_counts)]\n","\n","    # Calculate class weights\n","    class_weights = torch.tensor([1.0 / count for count in combined_class_counts], dtype=torch.float).to(device)\n","    criterion = nn.NLLLoss(weight=class_weights, reduction='sum')\n","\n","    # Data loaders\n","    train_loader = DataLoader(train_dataset, **train_kwargs)\n","    test_loader = DataLoader(test_dataset, **test_kwargs)\n","\n","    # Model, optimizer, and scheduler\n","    model = Net().to(device)\n","    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n","    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n","\n","    # Train and evaluate\n","    train_losses, train_accuracies, test_losses, test_accuracies = train_and_evaluate(\n","        args, model, device, train_loader, test_loader, optimizer, scheduler, criterion\n","    )\n","\n","    # Plot results\n","    plot_results(train_losses, train_accuracies, test_losses, test_accuracies)\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-f0G7fe6-HUC","executionInfo":{"status":"error","timestamp":1743438427799,"user_tz":-480,"elapsed":958341,"user":{"displayName":"Ryan R","userId":"16966029236028814230"}},"outputId":"31c63f18-b768-4032-ea73-4b9c08b5be69"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Using random seed: 13692\n","Train Epoch: 1 [0/155326 (0%)]\tLoss: 0.028068\n","Train Epoch: 1 [640/155326 (0%)]\tLoss: 0.029251\n","Train Epoch: 1 [1280/155326 (1%)]\tLoss: 0.024318\n","Train Epoch: 1 [1920/155326 (1%)]\tLoss: 0.027063\n","Train Epoch: 1 [2560/155326 (2%)]\tLoss: 0.027753\n","Train Epoch: 1 [3200/155326 (2%)]\tLoss: 0.030128\n","Train Epoch: 1 [3840/155326 (2%)]\tLoss: 0.028360\n","Train Epoch: 1 [4480/155326 (3%)]\tLoss: 0.030302\n","Train Epoch: 1 [5120/155326 (3%)]\tLoss: 0.029721\n","Train Epoch: 1 [5760/155326 (4%)]\tLoss: 0.026208\n","Train Epoch: 1 [6400/155326 (4%)]\tLoss: 0.026670\n","Train Epoch: 1 [7040/155326 (5%)]\tLoss: 0.026726\n","Train Epoch: 1 [7680/155326 (5%)]\tLoss: 0.025078\n","Train Epoch: 1 [8320/155326 (5%)]\tLoss: 0.023940\n","Train Epoch: 1 [8960/155326 (6%)]\tLoss: 0.030562\n","Train Epoch: 1 [9600/155326 (6%)]\tLoss: 0.026938\n","Train Epoch: 1 [10240/155326 (7%)]\tLoss: 0.030870\n","Train Epoch: 1 [10880/155326 (7%)]\tLoss: 0.030126\n","Train Epoch: 1 [11520/155326 (7%)]\tLoss: 0.025597\n","Train Epoch: 1 [12160/155326 (8%)]\tLoss: 0.024874\n","Train Epoch: 1 [12800/155326 (8%)]\tLoss: 0.029897\n","Train Epoch: 1 [13440/155326 (9%)]\tLoss: 0.027434\n","Train Epoch: 1 [14080/155326 (9%)]\tLoss: 0.023551\n","Train Epoch: 1 [14720/155326 (9%)]\tLoss: 0.030040\n","Train Epoch: 1 [15360/155326 (10%)]\tLoss: 0.026238\n","Train Epoch: 1 [16000/155326 (10%)]\tLoss: 0.024386\n","Train Epoch: 1 [16640/155326 (11%)]\tLoss: 0.024534\n","Train Epoch: 1 [17280/155326 (11%)]\tLoss: 0.025647\n","Train Epoch: 1 [17920/155326 (12%)]\tLoss: 0.027792\n","Train Epoch: 1 [18560/155326 (12%)]\tLoss: 0.026972\n","Train Epoch: 1 [19200/155326 (12%)]\tLoss: 0.026360\n","Train Epoch: 1 [19840/155326 (13%)]\tLoss: 0.027949\n","Train Epoch: 1 [20480/155326 (13%)]\tLoss: 0.022993\n","Train Epoch: 1 [21120/155326 (14%)]\tLoss: 0.022807\n","Train Epoch: 1 [21760/155326 (14%)]\tLoss: 0.025490\n","Train Epoch: 1 [22400/155326 (14%)]\tLoss: 0.025210\n","Train Epoch: 1 [23040/155326 (15%)]\tLoss: 0.027094\n","Train Epoch: 1 [23680/155326 (15%)]\tLoss: 0.020921\n","Train Epoch: 1 [24320/155326 (16%)]\tLoss: 0.020581\n","Train Epoch: 1 [24960/155326 (16%)]\tLoss: 0.023120\n","Train Epoch: 1 [25600/155326 (16%)]\tLoss: 0.020886\n","Train Epoch: 1 [26240/155326 (17%)]\tLoss: 0.021541\n","Train Epoch: 1 [26880/155326 (17%)]\tLoss: 0.017552\n","Train Epoch: 1 [27520/155326 (18%)]\tLoss: 0.013257\n","Train Epoch: 1 [28160/155326 (18%)]\tLoss: 0.013943\n","Train Epoch: 1 [28800/155326 (19%)]\tLoss: 0.017510\n","Train Epoch: 1 [29440/155326 (19%)]\tLoss: 0.013215\n","Train Epoch: 1 [30080/155326 (19%)]\tLoss: 0.013826\n","Train Epoch: 1 [30720/155326 (20%)]\tLoss: 0.015619\n","Train Epoch: 1 [31360/155326 (20%)]\tLoss: 0.012100\n","Train Epoch: 1 [32000/155326 (21%)]\tLoss: 0.012311\n","Train Epoch: 1 [32640/155326 (21%)]\tLoss: 0.012689\n","Train Epoch: 1 [33280/155326 (21%)]\tLoss: 0.013162\n","Train Epoch: 1 [33920/155326 (22%)]\tLoss: 0.011130\n","Train Epoch: 1 [34560/155326 (22%)]\tLoss: 0.009958\n","Train Epoch: 1 [35200/155326 (23%)]\tLoss: 0.011675\n","Train Epoch: 1 [35840/155326 (23%)]\tLoss: 0.009598\n","Train Epoch: 1 [36480/155326 (23%)]\tLoss: 0.011720\n","Train Epoch: 1 [37120/155326 (24%)]\tLoss: 0.010684\n","Train Epoch: 1 [37760/155326 (24%)]\tLoss: 0.014297\n","Train Epoch: 1 [38400/155326 (25%)]\tLoss: 0.012499\n","Train Epoch: 1 [39040/155326 (25%)]\tLoss: 0.014111\n","Train Epoch: 1 [39680/155326 (26%)]\tLoss: 0.009351\n","Train Epoch: 1 [40320/155326 (26%)]\tLoss: 0.013068\n","Train Epoch: 1 [40960/155326 (26%)]\tLoss: 0.012718\n","Train Epoch: 1 [41600/155326 (27%)]\tLoss: 0.008563\n","Train Epoch: 1 [42240/155326 (27%)]\tLoss: 0.009531\n","Train Epoch: 1 [42880/155326 (28%)]\tLoss: 0.010456\n","Train Epoch: 1 [43520/155326 (28%)]\tLoss: 0.016242\n","Train Epoch: 1 [44160/155326 (28%)]\tLoss: 0.010638\n","Train Epoch: 1 [44800/155326 (29%)]\tLoss: 0.009173\n","Train Epoch: 1 [45440/155326 (29%)]\tLoss: 0.009272\n","Train Epoch: 1 [46080/155326 (30%)]\tLoss: 0.007217\n","Train Epoch: 1 [46720/155326 (30%)]\tLoss: 0.012560\n","Train Epoch: 1 [47360/155326 (30%)]\tLoss: 0.008074\n","Train Epoch: 1 [48000/155326 (31%)]\tLoss: 0.010232\n","Train Epoch: 1 [48640/155326 (31%)]\tLoss: 0.007864\n","Train Epoch: 1 [49280/155326 (32%)]\tLoss: 0.016078\n","Train Epoch: 1 [49920/155326 (32%)]\tLoss: 0.010939\n","Train Epoch: 1 [50560/155326 (33%)]\tLoss: 0.008828\n","Train Epoch: 1 [51200/155326 (33%)]\tLoss: 0.009843\n","Train Epoch: 1 [51840/155326 (33%)]\tLoss: 0.005777\n","Train Epoch: 1 [52480/155326 (34%)]\tLoss: 0.007229\n","Train Epoch: 1 [53120/155326 (34%)]\tLoss: 0.009692\n","Train Epoch: 1 [53760/155326 (35%)]\tLoss: 0.007932\n","Train Epoch: 1 [54400/155326 (35%)]\tLoss: 0.009793\n","Train Epoch: 1 [55040/155326 (35%)]\tLoss: 0.008455\n","Train Epoch: 1 [55680/155326 (36%)]\tLoss: 0.010006\n","Train Epoch: 1 [56320/155326 (36%)]\tLoss: 0.007507\n","Train Epoch: 1 [56960/155326 (37%)]\tLoss: 0.007369\n","Train Epoch: 1 [57600/155326 (37%)]\tLoss: 0.010380\n","Train Epoch: 1 [58240/155326 (37%)]\tLoss: 0.006919\n","Train Epoch: 1 [58880/155326 (38%)]\tLoss: 0.006578\n","Train Epoch: 1 [59520/155326 (38%)]\tLoss: 0.005485\n","Train Epoch: 1 [60160/155326 (39%)]\tLoss: 0.008988\n","Train Epoch: 1 [60800/155326 (39%)]\tLoss: 0.006802\n","Train Epoch: 1 [61440/155326 (40%)]\tLoss: 0.008595\n","Train Epoch: 1 [62080/155326 (40%)]\tLoss: 0.007772\n","Train Epoch: 1 [62720/155326 (40%)]\tLoss: 0.008235\n","Train Epoch: 1 [63360/155326 (41%)]\tLoss: 0.007065\n","Train Epoch: 1 [64000/155326 (41%)]\tLoss: 0.007038\n","Train Epoch: 1 [64640/155326 (42%)]\tLoss: 0.009385\n","Train Epoch: 1 [65280/155326 (42%)]\tLoss: 0.005402\n","Train Epoch: 1 [65920/155326 (42%)]\tLoss: 0.004902\n","Train Epoch: 1 [66560/155326 (43%)]\tLoss: 0.004984\n","Train Epoch: 1 [67200/155326 (43%)]\tLoss: 0.009251\n","Train Epoch: 1 [67840/155326 (44%)]\tLoss: 0.004517\n","Train Epoch: 1 [68480/155326 (44%)]\tLoss: 0.007949\n","Train Epoch: 1 [69120/155326 (44%)]\tLoss: 0.004456\n","Train Epoch: 1 [69760/155326 (45%)]\tLoss: 0.007194\n","Train Epoch: 1 [70400/155326 (45%)]\tLoss: 0.008719\n","Train Epoch: 1 [71040/155326 (46%)]\tLoss: 0.006815\n","Train Epoch: 1 [71680/155326 (46%)]\tLoss: 0.006532\n","Train Epoch: 1 [72320/155326 (47%)]\tLoss: 0.003950\n","Train Epoch: 1 [72960/155326 (47%)]\tLoss: 0.005823\n","Train Epoch: 1 [73600/155326 (47%)]\tLoss: 0.005751\n","Train Epoch: 1 [74240/155326 (48%)]\tLoss: 0.006368\n","Train Epoch: 1 [74880/155326 (48%)]\tLoss: 0.006353\n","Train Epoch: 1 [75520/155326 (49%)]\tLoss: 0.006573\n","Train Epoch: 1 [76160/155326 (49%)]\tLoss: 0.005965\n","Train Epoch: 1 [76800/155326 (49%)]\tLoss: 0.007717\n","Train Epoch: 1 [77440/155326 (50%)]\tLoss: 0.005011\n","Train Epoch: 1 [78080/155326 (50%)]\tLoss: 0.006472\n","Train Epoch: 1 [78720/155326 (51%)]\tLoss: 0.002785\n","Train Epoch: 1 [79360/155326 (51%)]\tLoss: 0.004750\n","Train Epoch: 1 [80000/155326 (52%)]\tLoss: 0.007090\n","Train Epoch: 1 [80640/155326 (52%)]\tLoss: 0.007018\n","Train Epoch: 1 [81280/155326 (52%)]\tLoss: 0.005985\n","Train Epoch: 1 [81920/155326 (53%)]\tLoss: 0.005378\n","Train Epoch: 1 [82560/155326 (53%)]\tLoss: 0.003953\n","Train Epoch: 1 [83200/155326 (54%)]\tLoss: 0.002975\n","Train Epoch: 1 [83840/155326 (54%)]\tLoss: 0.005472\n","Train Epoch: 1 [84480/155326 (54%)]\tLoss: 0.005832\n","Train Epoch: 1 [85120/155326 (55%)]\tLoss: 0.005888\n","Train Epoch: 1 [85760/155326 (55%)]\tLoss: 0.004219\n","Train Epoch: 1 [86400/155326 (56%)]\tLoss: 0.004561\n","Train Epoch: 1 [87040/155326 (56%)]\tLoss: 0.002872\n","Train Epoch: 1 [87680/155326 (56%)]\tLoss: 0.008870\n","Train Epoch: 1 [88320/155326 (57%)]\tLoss: 0.004831\n","Train Epoch: 1 [88960/155326 (57%)]\tLoss: 0.005438\n","Train Epoch: 1 [89600/155326 (58%)]\tLoss: 0.005418\n","Train Epoch: 1 [90240/155326 (58%)]\tLoss: 0.003878\n","Train Epoch: 1 [90880/155326 (59%)]\tLoss: 0.006291\n","Train Epoch: 1 [91520/155326 (59%)]\tLoss: 0.003269\n","Train Epoch: 1 [92160/155326 (59%)]\tLoss: 0.003739\n","Train Epoch: 1 [92800/155326 (60%)]\tLoss: 0.003773\n","Train Epoch: 1 [93440/155326 (60%)]\tLoss: 0.003911\n","Train Epoch: 1 [94080/155326 (61%)]\tLoss: 0.006281\n","Train Epoch: 1 [94720/155326 (61%)]\tLoss: 0.003567\n","Train Epoch: 1 [95360/155326 (61%)]\tLoss: 0.006680\n","Train Epoch: 1 [96000/155326 (62%)]\tLoss: 0.003377\n","Train Epoch: 1 [96640/155326 (62%)]\tLoss: 0.005060\n","Train Epoch: 1 [97280/155326 (63%)]\tLoss: 0.003843\n","Train Epoch: 1 [97920/155326 (63%)]\tLoss: 0.004700\n","Train Epoch: 1 [98560/155326 (63%)]\tLoss: 0.005334\n","Train Epoch: 1 [99200/155326 (64%)]\tLoss: 0.004222\n","Train Epoch: 1 [99840/155326 (64%)]\tLoss: 0.004677\n","Train Epoch: 1 [100480/155326 (65%)]\tLoss: 0.003123\n","Train Epoch: 1 [101120/155326 (65%)]\tLoss: 0.003599\n","Train Epoch: 1 [101760/155326 (66%)]\tLoss: 0.002905\n","Train Epoch: 1 [102400/155326 (66%)]\tLoss: 0.004217\n","Train Epoch: 1 [103040/155326 (66%)]\tLoss: 0.004393\n","Train Epoch: 1 [103680/155326 (67%)]\tLoss: 0.006507\n","Train Epoch: 1 [104320/155326 (67%)]\tLoss: 0.002299\n","Train Epoch: 1 [104960/155326 (68%)]\tLoss: 0.003550\n","Train Epoch: 1 [105600/155326 (68%)]\tLoss: 0.003738\n","Train Epoch: 1 [106240/155326 (68%)]\tLoss: 0.004424\n","Train Epoch: 1 [106880/155326 (69%)]\tLoss: 0.003581\n","Train Epoch: 1 [107520/155326 (69%)]\tLoss: 0.004568\n","Train Epoch: 1 [108160/155326 (70%)]\tLoss: 0.003510\n","Train Epoch: 1 [108800/155326 (70%)]\tLoss: 0.006125\n","Train Epoch: 1 [109440/155326 (70%)]\tLoss: 0.003979\n","Train Epoch: 1 [110080/155326 (71%)]\tLoss: 0.003343\n","Train Epoch: 1 [110720/155326 (71%)]\tLoss: 0.002830\n","Train Epoch: 1 [111360/155326 (72%)]\tLoss: 0.002641\n","Train Epoch: 1 [112000/155326 (72%)]\tLoss: 0.002365\n","Train Epoch: 1 [112640/155326 (73%)]\tLoss: 0.003361\n","Train Epoch: 1 [113280/155326 (73%)]\tLoss: 0.003862\n","Train Epoch: 1 [113920/155326 (73%)]\tLoss: 0.004012\n","Train Epoch: 1 [114560/155326 (74%)]\tLoss: 0.003238\n","Train Epoch: 1 [115200/155326 (74%)]\tLoss: 0.004160\n","Train Epoch: 1 [115840/155326 (75%)]\tLoss: 0.006191\n","Train Epoch: 1 [116480/155326 (75%)]\tLoss: 0.006195\n","Train Epoch: 1 [117120/155326 (75%)]\tLoss: 0.006545\n","Train Epoch: 1 [117760/155326 (76%)]\tLoss: 0.006371\n","Train Epoch: 1 [118400/155326 (76%)]\tLoss: 0.005549\n","Train Epoch: 1 [119040/155326 (77%)]\tLoss: 0.004134\n","Train Epoch: 1 [119680/155326 (77%)]\tLoss: 0.003388\n","Train Epoch: 1 [120320/155326 (77%)]\tLoss: 0.002825\n","Train Epoch: 1 [120960/155326 (78%)]\tLoss: 0.003155\n","Train Epoch: 1 [121600/155326 (78%)]\tLoss: 0.002857\n","Train Epoch: 1 [122240/155326 (79%)]\tLoss: 0.004494\n","Train Epoch: 1 [122880/155326 (79%)]\tLoss: 0.005278\n","Train Epoch: 1 [123520/155326 (80%)]\tLoss: 0.006698\n","Train Epoch: 1 [124160/155326 (80%)]\tLoss: 0.003724\n","Train Epoch: 1 [124800/155326 (80%)]\tLoss: 0.006084\n","Train Epoch: 1 [125440/155326 (81%)]\tLoss: 0.002356\n","Train Epoch: 1 [126080/155326 (81%)]\tLoss: 0.007233\n","Train Epoch: 1 [126720/155326 (82%)]\tLoss: 0.002854\n","Train Epoch: 1 [127360/155326 (82%)]\tLoss: 0.003199\n","Train Epoch: 1 [128000/155326 (82%)]\tLoss: 0.005185\n","Train Epoch: 1 [128640/155326 (83%)]\tLoss: 0.001799\n","Train Epoch: 1 [129280/155326 (83%)]\tLoss: 0.002296\n","Train Epoch: 1 [129920/155326 (84%)]\tLoss: 0.003718\n","Train Epoch: 1 [130560/155326 (84%)]\tLoss: 0.001722\n","Train Epoch: 1 [131200/155326 (84%)]\tLoss: 0.003918\n","Train Epoch: 1 [131840/155326 (85%)]\tLoss: 0.004530\n","Train Epoch: 1 [132480/155326 (85%)]\tLoss: 0.005436\n","Train Epoch: 1 [133120/155326 (86%)]\tLoss: 0.004287\n","Train Epoch: 1 [133760/155326 (86%)]\tLoss: 0.006002\n","Train Epoch: 1 [134400/155326 (87%)]\tLoss: 0.003263\n","Train Epoch: 1 [135040/155326 (87%)]\tLoss: 0.003436\n","Train Epoch: 1 [135680/155326 (87%)]\tLoss: 0.001942\n","Train Epoch: 1 [136320/155326 (88%)]\tLoss: 0.004290\n","Train Epoch: 1 [136960/155326 (88%)]\tLoss: 0.001994\n","Train Epoch: 1 [137600/155326 (89%)]\tLoss: 0.001219\n","Train Epoch: 1 [138240/155326 (89%)]\tLoss: 0.003457\n","Train Epoch: 1 [138880/155326 (89%)]\tLoss: 0.001112\n","Train Epoch: 1 [139520/155326 (90%)]\tLoss: 0.001192\n","Train Epoch: 1 [140160/155326 (90%)]\tLoss: 0.006111\n","Train Epoch: 1 [140800/155326 (91%)]\tLoss: 0.002898\n","Train Epoch: 1 [141440/155326 (91%)]\tLoss: 0.001577\n","Train Epoch: 1 [142080/155326 (91%)]\tLoss: 0.002972\n","Train Epoch: 1 [142720/155326 (92%)]\tLoss: 0.003537\n","Train Epoch: 1 [143360/155326 (92%)]\tLoss: 0.002596\n","Train Epoch: 1 [144000/155326 (93%)]\tLoss: 0.001834\n","Train Epoch: 1 [144640/155326 (93%)]\tLoss: 0.001957\n","Train Epoch: 1 [145280/155326 (94%)]\tLoss: 0.003642\n","Train Epoch: 1 [145920/155326 (94%)]\tLoss: 0.003874\n","Train Epoch: 1 [146560/155326 (94%)]\tLoss: 0.001744\n","Train Epoch: 1 [147200/155326 (95%)]\tLoss: 0.002947\n","Train Epoch: 1 [147840/155326 (95%)]\tLoss: 0.003996\n","Train Epoch: 1 [148480/155326 (96%)]\tLoss: 0.002137\n","Train Epoch: 1 [149120/155326 (96%)]\tLoss: 0.004149\n","Train Epoch: 1 [149760/155326 (96%)]\tLoss: 0.003367\n","Train Epoch: 1 [150400/155326 (97%)]\tLoss: 0.003481\n","Train Epoch: 1 [151040/155326 (97%)]\tLoss: 0.003652\n","Train Epoch: 1 [151680/155326 (98%)]\tLoss: 0.002649\n","Train Epoch: 1 [152320/155326 (98%)]\tLoss: 0.002844\n","Train Epoch: 1 [152960/155326 (98%)]\tLoss: 0.002487\n","Train Epoch: 1 [153600/155326 (99%)]\tLoss: 0.002528\n","Train Epoch: 1 [154240/155326 (99%)]\tLoss: 0.002428\n","Train Epoch: 1 [154880/155326 (100%)]\tLoss: 0.002368\n","Sample outputs (log probs): tensor([[-1.5108e+01, -2.5974e+00, -1.5620e+01, -1.0021e+01, -7.4236e+00,\n","         -1.1533e+01, -1.2701e+01, -1.9663e+01, -1.2358e+01, -1.2934e+01,\n","         -1.7628e+01, -2.2891e+01, -1.9354e+01, -2.0836e+01, -1.4824e+01,\n","         -1.5207e+01, -1.5522e+01, -1.4823e+01, -7.8124e-02, -1.7190e+01,\n","         -2.0662e+01, -2.2309e+01, -2.5052e+01, -1.4730e+01, -1.5373e+01,\n","         -1.0793e+01],\n","        [-1.5738e+01, -1.0254e+01, -9.1543e+00, -5.3420e+00, -4.5942e+00,\n","         -8.2054e+00, -1.4920e+01, -2.3229e+01, -3.9879e-01, -5.5720e+00,\n","         -1.4364e+01, -1.1153e+01, -2.0147e+01, -1.7829e+01, -1.4041e+01,\n","         -1.5231e+01, -1.3639e+01, -1.1668e+01, -6.6818e+00, -8.9389e+00,\n","         -1.6127e+01, -1.6781e+01, -1.9365e+01, -8.9389e+00, -1.4387e+01,\n","         -1.1770e+00],\n","        [-1.1145e+01, -9.8348e+00, -5.5583e+00, -5.3383e+00, -1.3358e+01,\n","         -1.1894e+01, -9.9562e+00, -1.2896e+01, -1.1594e+01, -1.0554e+01,\n","         -1.5489e+01, -1.3044e+01, -1.3798e+01, -9.6742e+00, -1.0084e-02,\n","         -1.2629e+01, -7.7200e+00, -1.3949e+01, -1.0600e+01, -1.5385e+01,\n","         -7.3177e+00, -1.1720e+01, -1.4159e+01, -2.0892e+01, -1.5163e+01,\n","         -1.5207e+01],\n","        [-1.2826e+01, -9.7119e+00, -7.5919e+00, -2.6591e+00, -1.8186e+01,\n","         -1.5954e+01, -1.0130e+01, -1.3792e+01, -1.4482e+01, -8.8577e+00,\n","         -1.9097e+01, -1.4556e+01, -1.3540e+01, -1.1091e+01, -8.7933e-02,\n","         -1.4853e+01, -6.1171e+00, -1.8497e+01, -1.1920e+01, -1.5983e+01,\n","         -4.4934e+00, -1.3604e+01, -1.5604e+01, -2.3869e+01, -1.3754e+01,\n","         -1.6935e+01],\n","        [-2.0105e+01, -1.6889e+01, -1.4724e+01, -1.2036e+01, -2.4257e+01,\n","         -2.3318e+01, -1.6822e+01, -1.3715e+01, -1.8847e+01, -9.7366e+00,\n","         -1.9082e+01, -1.6217e+01, -1.2431e+01, -1.1073e+01, -1.0911e+01,\n","         -1.8479e+01, -1.2404e+01, -2.3781e+01, -1.9123e+01, -1.9534e+01,\n","         -7.9665e-03, -4.9669e+00, -7.0576e+00, -2.0346e+01, -1.3905e+01,\n","         -2.2278e+01]], device='cuda:0')\n","Predicted classes: tensor([18,  8, 14, 14, 20], device='cuda:0')\n","Target classes: tensor([18,  8, 14, 14, 20], device='cuda:0')\n","\n","Test set: Average loss: 0.004759, Total sum loss: 1.446811, Accuracy: 36081/38832 (93%)\n","\n","Class A: 1231/1336 (92%)\n","Class B: 748/819 (91%)\n","Class C: 1953/2059 (95%)\n","Class D: 862/922 (93%)\n","Class E: 955/996 (96%)\n","Class F: 1679/1861 (90%)\n","Class G: 498/551 (90%)\n","Class H: 584/709 (82%)\n","Class I: 2335/2438 (96%)\n","Class J: 710/772 (92%)\n","Class K: 488/566 (86%)\n","Class L: 931/986 (94%)\n","Class M: 1754/1851 (95%)\n","Class N: 1507/1636 (92%)\n","Class O: 4653/5060 (92%)\n","Class P: 1668/1781 (94%)\n","Class Q: 529/589 (90%)\n","Class R: 983/1056 (93%)\n","Class S: 4014/4209 (95%)\n","Class T: 1879/1960 (96%)\n","Class U: 2384/2562 (93%)\n","Class V: 899/988 (91%)\n","Class W: 903/990 (91%)\n","Class X: 538/601 (90%)\n","Class Y: 899/1022 (88%)\n","Class Z: 497/512 (97%)\n","Train Epoch: 2 [0/155326 (0%)]\tLoss: 0.002368\n","Train Epoch: 2 [640/155326 (0%)]\tLoss: 0.004017\n","Train Epoch: 2 [1280/155326 (1%)]\tLoss: 0.002497\n","Train Epoch: 2 [1920/155326 (1%)]\tLoss: 0.003336\n","Train Epoch: 2 [2560/155326 (2%)]\tLoss: 0.004357\n","Train Epoch: 2 [3200/155326 (2%)]\tLoss: 0.004111\n","Train Epoch: 2 [3840/155326 (2%)]\tLoss: 0.002723\n","Train Epoch: 2 [4480/155326 (3%)]\tLoss: 0.001624\n","Train Epoch: 2 [5120/155326 (3%)]\tLoss: 0.001454\n","Train Epoch: 2 [5760/155326 (4%)]\tLoss: 0.001376\n","Train Epoch: 2 [6400/155326 (4%)]\tLoss: 0.003485\n","Train Epoch: 2 [7040/155326 (5%)]\tLoss: 0.003519\n","Train Epoch: 2 [7680/155326 (5%)]\tLoss: 0.006356\n","Train Epoch: 2 [8320/155326 (5%)]\tLoss: 0.002648\n","Train Epoch: 2 [8960/155326 (6%)]\tLoss: 0.001198\n","Train Epoch: 2 [9600/155326 (6%)]\tLoss: 0.002214\n","Train Epoch: 2 [10240/155326 (7%)]\tLoss: 0.002880\n","Train Epoch: 2 [10880/155326 (7%)]\tLoss: 0.001467\n","Train Epoch: 2 [11520/155326 (7%)]\tLoss: 0.002843\n","Train Epoch: 2 [12160/155326 (8%)]\tLoss: 0.004881\n","Train Epoch: 2 [12800/155326 (8%)]\tLoss: 0.003482\n","Train Epoch: 2 [13440/155326 (9%)]\tLoss: 0.003559\n","Train Epoch: 2 [14080/155326 (9%)]\tLoss: 0.002496\n","Train Epoch: 2 [14720/155326 (9%)]\tLoss: 0.002552\n","Train Epoch: 2 [15360/155326 (10%)]\tLoss: 0.002366\n","Train Epoch: 2 [16000/155326 (10%)]\tLoss: 0.001920\n","Train Epoch: 2 [16640/155326 (11%)]\tLoss: 0.001736\n","Train Epoch: 2 [17280/155326 (11%)]\tLoss: 0.001929\n","Train Epoch: 2 [17920/155326 (12%)]\tLoss: 0.003769\n","Train Epoch: 2 [18560/155326 (12%)]\tLoss: 0.002047\n","Train Epoch: 2 [19200/155326 (12%)]\tLoss: 0.003700\n","Train Epoch: 2 [19840/155326 (13%)]\tLoss: 0.003445\n","Train Epoch: 2 [20480/155326 (13%)]\tLoss: 0.004747\n","Train Epoch: 2 [21120/155326 (14%)]\tLoss: 0.005119\n","Train Epoch: 2 [21760/155326 (14%)]\tLoss: 0.002209\n","Train Epoch: 2 [22400/155326 (14%)]\tLoss: 0.002231\n","Train Epoch: 2 [23040/155326 (15%)]\tLoss: 0.001894\n","Train Epoch: 2 [23680/155326 (15%)]\tLoss: 0.002783\n","Train Epoch: 2 [24320/155326 (16%)]\tLoss: 0.002681\n","Train Epoch: 2 [24960/155326 (16%)]\tLoss: 0.003100\n","Train Epoch: 2 [25600/155326 (16%)]\tLoss: 0.003618\n","Train Epoch: 2 [26240/155326 (17%)]\tLoss: 0.002105\n","Train Epoch: 2 [26880/155326 (17%)]\tLoss: 0.001059\n","Train Epoch: 2 [27520/155326 (18%)]\tLoss: 0.002270\n","Train Epoch: 2 [28160/155326 (18%)]\tLoss: 0.001817\n","Train Epoch: 2 [28800/155326 (19%)]\tLoss: 0.003297\n","Train Epoch: 2 [29440/155326 (19%)]\tLoss: 0.002901\n","Train Epoch: 2 [30080/155326 (19%)]\tLoss: 0.003898\n","Train Epoch: 2 [30720/155326 (20%)]\tLoss: 0.002428\n","Train Epoch: 2 [31360/155326 (20%)]\tLoss: 0.003726\n","Train Epoch: 2 [32000/155326 (21%)]\tLoss: 0.003309\n","Train Epoch: 2 [32640/155326 (21%)]\tLoss: 0.002807\n","Train Epoch: 2 [33280/155326 (21%)]\tLoss: 0.002117\n","Train Epoch: 2 [33920/155326 (22%)]\tLoss: 0.001152\n","Train Epoch: 2 [34560/155326 (22%)]\tLoss: 0.001012\n","Train Epoch: 2 [35200/155326 (23%)]\tLoss: 0.001742\n","Train Epoch: 2 [35840/155326 (23%)]\tLoss: 0.001697\n","Train Epoch: 2 [36480/155326 (23%)]\tLoss: 0.004451\n","Train Epoch: 2 [37120/155326 (24%)]\tLoss: 0.001075\n","Train Epoch: 2 [37760/155326 (24%)]\tLoss: 0.001126\n","Train Epoch: 2 [38400/155326 (25%)]\tLoss: 0.005283\n","Train Epoch: 2 [39040/155326 (25%)]\tLoss: 0.004803\n","Train Epoch: 2 [39680/155326 (26%)]\tLoss: 0.002910\n","Train Epoch: 2 [40320/155326 (26%)]\tLoss: 0.000872\n","Train Epoch: 2 [40960/155326 (26%)]\tLoss: 0.002516\n","Train Epoch: 2 [41600/155326 (27%)]\tLoss: 0.002174\n","Train Epoch: 2 [42240/155326 (27%)]\tLoss: 0.003502\n","Train Epoch: 2 [42880/155326 (28%)]\tLoss: 0.004176\n","Train Epoch: 2 [43520/155326 (28%)]\tLoss: 0.001613\n","Train Epoch: 2 [44160/155326 (28%)]\tLoss: 0.002292\n","Train Epoch: 2 [44800/155326 (29%)]\tLoss: 0.002559\n","Train Epoch: 2 [45440/155326 (29%)]\tLoss: 0.002809\n","Train Epoch: 2 [46080/155326 (30%)]\tLoss: 0.001862\n","Train Epoch: 2 [46720/155326 (30%)]\tLoss: 0.002518\n","Train Epoch: 2 [47360/155326 (30%)]\tLoss: 0.000821\n","Train Epoch: 2 [48000/155326 (31%)]\tLoss: 0.002981\n","Train Epoch: 2 [48640/155326 (31%)]\tLoss: 0.001996\n","Train Epoch: 2 [49280/155326 (32%)]\tLoss: 0.002474\n","Train Epoch: 2 [49920/155326 (32%)]\tLoss: 0.004282\n","Train Epoch: 2 [50560/155326 (33%)]\tLoss: 0.003062\n","Train Epoch: 2 [51200/155326 (33%)]\tLoss: 0.005017\n","Train Epoch: 2 [51840/155326 (33%)]\tLoss: 0.002227\n","Train Epoch: 2 [52480/155326 (34%)]\tLoss: 0.001282\n","Train Epoch: 2 [53120/155326 (34%)]\tLoss: 0.002112\n","Train Epoch: 2 [53760/155326 (35%)]\tLoss: 0.001469\n","Train Epoch: 2 [54400/155326 (35%)]\tLoss: 0.002745\n","Train Epoch: 2 [55040/155326 (35%)]\tLoss: 0.001931\n","Train Epoch: 2 [55680/155326 (36%)]\tLoss: 0.001671\n","Train Epoch: 2 [56320/155326 (36%)]\tLoss: 0.001420\n","Train Epoch: 2 [56960/155326 (37%)]\tLoss: 0.003357\n","Train Epoch: 2 [57600/155326 (37%)]\tLoss: 0.001376\n","Train Epoch: 2 [58240/155326 (37%)]\tLoss: 0.004920\n","Train Epoch: 2 [58880/155326 (38%)]\tLoss: 0.003067\n","Train Epoch: 2 [59520/155326 (38%)]\tLoss: 0.002644\n","Train Epoch: 2 [60160/155326 (39%)]\tLoss: 0.003100\n","Train Epoch: 2 [60800/155326 (39%)]\tLoss: 0.001668\n","Train Epoch: 2 [61440/155326 (40%)]\tLoss: 0.001522\n","Train Epoch: 2 [62080/155326 (40%)]\tLoss: 0.001490\n","Train Epoch: 2 [62720/155326 (40%)]\tLoss: 0.001658\n","Train Epoch: 2 [63360/155326 (41%)]\tLoss: 0.004144\n","Train Epoch: 2 [64000/155326 (41%)]\tLoss: 0.002126\n","Train Epoch: 2 [64640/155326 (42%)]\tLoss: 0.005223\n","Train Epoch: 2 [65280/155326 (42%)]\tLoss: 0.002816\n","Train Epoch: 2 [65920/155326 (42%)]\tLoss: 0.003432\n","Train Epoch: 2 [66560/155326 (43%)]\tLoss: 0.001443\n","Train Epoch: 2 [67200/155326 (43%)]\tLoss: 0.001874\n","Train Epoch: 2 [67840/155326 (44%)]\tLoss: 0.002697\n","Train Epoch: 2 [68480/155326 (44%)]\tLoss: 0.003104\n","Train Epoch: 2 [69120/155326 (44%)]\tLoss: 0.002654\n","Train Epoch: 2 [69760/155326 (45%)]\tLoss: 0.001519\n","Train Epoch: 2 [70400/155326 (45%)]\tLoss: 0.000735\n","Train Epoch: 2 [71040/155326 (46%)]\tLoss: 0.000991\n","Train Epoch: 2 [71680/155326 (46%)]\tLoss: 0.001466\n","Train Epoch: 2 [72320/155326 (47%)]\tLoss: 0.003370\n","Train Epoch: 2 [72960/155326 (47%)]\tLoss: 0.001098\n","Train Epoch: 2 [73600/155326 (47%)]\tLoss: 0.001752\n","Train Epoch: 2 [74240/155326 (48%)]\tLoss: 0.002215\n","Train Epoch: 2 [74880/155326 (48%)]\tLoss: 0.001099\n","Train Epoch: 2 [75520/155326 (49%)]\tLoss: 0.001060\n","Train Epoch: 2 [76160/155326 (49%)]\tLoss: 0.000745\n","Train Epoch: 2 [76800/155326 (49%)]\tLoss: 0.003385\n","Train Epoch: 2 [77440/155326 (50%)]\tLoss: 0.002943\n","Train Epoch: 2 [78080/155326 (50%)]\tLoss: 0.002677\n","Train Epoch: 2 [78720/155326 (51%)]\tLoss: 0.001860\n","Train Epoch: 2 [79360/155326 (51%)]\tLoss: 0.001208\n","Train Epoch: 2 [80000/155326 (52%)]\tLoss: 0.002923\n","Train Epoch: 2 [80640/155326 (52%)]\tLoss: 0.001104\n","Train Epoch: 2 [81280/155326 (52%)]\tLoss: 0.003862\n","Train Epoch: 2 [81920/155326 (53%)]\tLoss: 0.001395\n","Train Epoch: 2 [82560/155326 (53%)]\tLoss: 0.002741\n","Train Epoch: 2 [83200/155326 (54%)]\tLoss: 0.003851\n","Train Epoch: 2 [83840/155326 (54%)]\tLoss: 0.001150\n","Train Epoch: 2 [84480/155326 (54%)]\tLoss: 0.001787\n","Train Epoch: 2 [85120/155326 (55%)]\tLoss: 0.003468\n","Train Epoch: 2 [85760/155326 (55%)]\tLoss: 0.002049\n","Train Epoch: 2 [86400/155326 (56%)]\tLoss: 0.000944\n","Train Epoch: 2 [87040/155326 (56%)]\tLoss: 0.002107\n","Train Epoch: 2 [87680/155326 (56%)]\tLoss: 0.003693\n","Train Epoch: 2 [88320/155326 (57%)]\tLoss: 0.001909\n","Train Epoch: 2 [88960/155326 (57%)]\tLoss: 0.005506\n","Train Epoch: 2 [89600/155326 (58%)]\tLoss: 0.002718\n","Train Epoch: 2 [90240/155326 (58%)]\tLoss: 0.001122\n","Train Epoch: 2 [90880/155326 (59%)]\tLoss: 0.001908\n","Train Epoch: 2 [91520/155326 (59%)]\tLoss: 0.000754\n","Train Epoch: 2 [92160/155326 (59%)]\tLoss: 0.003477\n","Train Epoch: 2 [92800/155326 (60%)]\tLoss: 0.005636\n","Train Epoch: 2 [93440/155326 (60%)]\tLoss: 0.000359\n","Train Epoch: 2 [94080/155326 (61%)]\tLoss: 0.001772\n","Train Epoch: 2 [94720/155326 (61%)]\tLoss: 0.002864\n","Train Epoch: 2 [95360/155326 (61%)]\tLoss: 0.000998\n","Train Epoch: 2 [96000/155326 (62%)]\tLoss: 0.001715\n","Train Epoch: 2 [96640/155326 (62%)]\tLoss: 0.001744\n","Train Epoch: 2 [97280/155326 (63%)]\tLoss: 0.002294\n","Train Epoch: 2 [97920/155326 (63%)]\tLoss: 0.002355\n","Train Epoch: 2 [98560/155326 (63%)]\tLoss: 0.001038\n","Train Epoch: 2 [99200/155326 (64%)]\tLoss: 0.001434\n","Train Epoch: 2 [99840/155326 (64%)]\tLoss: 0.002951\n","Train Epoch: 2 [100480/155326 (65%)]\tLoss: 0.001522\n","Train Epoch: 2 [101120/155326 (65%)]\tLoss: 0.003373\n","Train Epoch: 2 [101760/155326 (66%)]\tLoss: 0.001140\n","Train Epoch: 2 [102400/155326 (66%)]\tLoss: 0.002845\n","Train Epoch: 2 [103040/155326 (66%)]\tLoss: 0.002302\n","Train Epoch: 2 [103680/155326 (67%)]\tLoss: 0.001784\n","Train Epoch: 2 [104320/155326 (67%)]\tLoss: 0.001837\n","Train Epoch: 2 [104960/155326 (68%)]\tLoss: 0.001094\n","Train Epoch: 2 [105600/155326 (68%)]\tLoss: 0.001669\n","Train Epoch: 2 [106240/155326 (68%)]\tLoss: 0.002090\n","Train Epoch: 2 [106880/155326 (69%)]\tLoss: 0.001357\n","Train Epoch: 2 [107520/155326 (69%)]\tLoss: 0.001333\n","Train Epoch: 2 [108160/155326 (70%)]\tLoss: 0.002511\n","Train Epoch: 2 [108800/155326 (70%)]\tLoss: 0.002726\n","Train Epoch: 2 [109440/155326 (70%)]\tLoss: 0.001704\n","Train Epoch: 2 [110080/155326 (71%)]\tLoss: 0.002311\n","Train Epoch: 2 [110720/155326 (71%)]\tLoss: 0.004089\n","Train Epoch: 2 [111360/155326 (72%)]\tLoss: 0.002191\n","Train Epoch: 2 [112000/155326 (72%)]\tLoss: 0.000911\n","Train Epoch: 2 [112640/155326 (73%)]\tLoss: 0.000908\n","Train Epoch: 2 [113280/155326 (73%)]\tLoss: 0.003128\n","Train Epoch: 2 [113920/155326 (73%)]\tLoss: 0.001808\n","Train Epoch: 2 [114560/155326 (74%)]\tLoss: 0.002238\n","Train Epoch: 2 [115200/155326 (74%)]\tLoss: 0.001358\n","Train Epoch: 2 [115840/155326 (75%)]\tLoss: 0.002010\n","Train Epoch: 2 [116480/155326 (75%)]\tLoss: 0.002461\n","Train Epoch: 2 [117120/155326 (75%)]\tLoss: 0.002029\n","Train Epoch: 2 [117760/155326 (76%)]\tLoss: 0.003847\n","Train Epoch: 2 [118400/155326 (76%)]\tLoss: 0.001893\n","Train Epoch: 2 [119040/155326 (77%)]\tLoss: 0.002328\n","Train Epoch: 2 [119680/155326 (77%)]\tLoss: 0.003991\n","Train Epoch: 2 [120320/155326 (77%)]\tLoss: 0.003597\n","Train Epoch: 2 [120960/155326 (78%)]\tLoss: 0.001850\n","Train Epoch: 2 [121600/155326 (78%)]\tLoss: 0.002064\n","Train Epoch: 2 [122240/155326 (79%)]\tLoss: 0.000962\n","Train Epoch: 2 [122880/155326 (79%)]\tLoss: 0.001784\n","Train Epoch: 2 [123520/155326 (80%)]\tLoss: 0.001651\n","Train Epoch: 2 [124160/155326 (80%)]\tLoss: 0.001752\n","Train Epoch: 2 [124800/155326 (80%)]\tLoss: 0.001692\n","Train Epoch: 2 [125440/155326 (81%)]\tLoss: 0.002824\n","Train Epoch: 2 [126080/155326 (81%)]\tLoss: 0.004607\n","Train Epoch: 2 [126720/155326 (82%)]\tLoss: 0.002129\n","Train Epoch: 2 [127360/155326 (82%)]\tLoss: 0.002660\n","Train Epoch: 2 [128000/155326 (82%)]\tLoss: 0.004594\n","Train Epoch: 2 [128640/155326 (83%)]\tLoss: 0.003757\n","Train Epoch: 2 [129280/155326 (83%)]\tLoss: 0.001039\n","Train Epoch: 2 [129920/155326 (84%)]\tLoss: 0.001488\n","Train Epoch: 2 [130560/155326 (84%)]\tLoss: 0.001545\n","Train Epoch: 2 [131200/155326 (84%)]\tLoss: 0.002907\n","Train Epoch: 2 [131840/155326 (85%)]\tLoss: 0.000633\n","Train Epoch: 2 [132480/155326 (85%)]\tLoss: 0.003675\n","Train Epoch: 2 [133120/155326 (86%)]\tLoss: 0.001268\n","Train Epoch: 2 [133760/155326 (86%)]\tLoss: 0.000547\n","Train Epoch: 2 [134400/155326 (87%)]\tLoss: 0.003314\n","Train Epoch: 2 [135040/155326 (87%)]\tLoss: 0.002022\n","Train Epoch: 2 [135680/155326 (87%)]\tLoss: 0.002322\n","Train Epoch: 2 [136320/155326 (88%)]\tLoss: 0.003082\n","Train Epoch: 2 [136960/155326 (88%)]\tLoss: 0.003910\n","Train Epoch: 2 [137600/155326 (89%)]\tLoss: 0.002231\n","Train Epoch: 2 [138240/155326 (89%)]\tLoss: 0.000737\n","Train Epoch: 2 [138880/155326 (89%)]\tLoss: 0.003113\n","Train Epoch: 2 [139520/155326 (90%)]\tLoss: 0.002354\n","Train Epoch: 2 [140160/155326 (90%)]\tLoss: 0.002698\n","Train Epoch: 2 [140800/155326 (91%)]\tLoss: 0.002393\n","Train Epoch: 2 [141440/155326 (91%)]\tLoss: 0.002728\n","Train Epoch: 2 [142080/155326 (91%)]\tLoss: 0.001733\n","Train Epoch: 2 [142720/155326 (92%)]\tLoss: 0.001364\n","Train Epoch: 2 [143360/155326 (92%)]\tLoss: 0.002552\n","Train Epoch: 2 [144000/155326 (93%)]\tLoss: 0.001394\n","Train Epoch: 2 [144640/155326 (93%)]\tLoss: 0.005260\n","Train Epoch: 2 [145280/155326 (94%)]\tLoss: 0.002419\n","Train Epoch: 2 [145920/155326 (94%)]\tLoss: 0.000830\n","Train Epoch: 2 [146560/155326 (94%)]\tLoss: 0.001900\n","Train Epoch: 2 [147200/155326 (95%)]\tLoss: 0.006110\n","Train Epoch: 2 [147840/155326 (95%)]\tLoss: 0.001305\n","Train Epoch: 2 [148480/155326 (96%)]\tLoss: 0.002652\n","Train Epoch: 2 [149120/155326 (96%)]\tLoss: 0.001394\n","Train Epoch: 2 [149760/155326 (96%)]\tLoss: 0.001035\n","Train Epoch: 2 [150400/155326 (97%)]\tLoss: 0.001462\n","Train Epoch: 2 [151040/155326 (97%)]\tLoss: 0.001579\n","Train Epoch: 2 [151680/155326 (98%)]\tLoss: 0.002613\n","Train Epoch: 2 [152320/155326 (98%)]\tLoss: 0.001748\n","Train Epoch: 2 [152960/155326 (98%)]\tLoss: 0.001566\n","Train Epoch: 2 [153600/155326 (99%)]\tLoss: 0.001401\n","Train Epoch: 2 [154240/155326 (99%)]\tLoss: 0.003514\n","Train Epoch: 2 [154880/155326 (100%)]\tLoss: 0.002138\n","Sample outputs (log probs): tensor([[-2.4757e+01, -1.1334e+01, -1.4608e+01, -1.4909e+01, -1.0419e+01,\n","         -1.2488e+01, -1.4332e+01, -3.0672e+01, -1.1403e+01, -4.0597e+00,\n","         -2.6120e+01, -2.4766e+01, -3.0885e+01, -2.9964e+01, -1.8790e+01,\n","         -2.2339e+01, -1.5762e+01, -2.6095e+01, -1.7464e-02, -1.8486e+01,\n","         -2.6121e+01, -2.9058e+01, -3.1272e+01, -2.1227e+01, -1.7578e+01,\n","         -1.6538e+01],\n","        [-2.4413e+01, -1.6344e+01, -2.6132e-03, -2.2164e+01, -5.9751e+00,\n","         -1.9789e+01, -1.1347e+01, -2.6052e+01, -1.5840e+01, -1.6960e+01,\n","         -1.0209e+01, -1.0897e+01, -2.8998e+01, -2.5943e+01, -1.5836e+01,\n","         -2.5905e+01, -1.6096e+01, -1.4949e+01, -1.5099e+01, -2.3524e+01,\n","         -1.7148e+01, -2.3376e+01, -2.8089e+01, -2.2949e+01, -2.4243e+01,\n","         -1.5063e+01],\n","        [-7.1292e+00, -1.0253e+01, -1.7439e+01, -1.5952e+01, -1.8085e+01,\n","         -1.8286e+01, -1.2677e+01, -2.9495e-03, -1.7043e+01, -1.6384e+01,\n","         -6.6938e+00, -1.5801e+01, -8.8403e+00, -7.4323e+00, -1.6324e+01,\n","         -1.3621e+01, -1.6484e+01, -1.2252e+01, -1.9694e+01, -1.7733e+01,\n","         -1.1425e+01, -1.2008e+01, -9.7523e+00, -1.2446e+01, -1.0017e+01,\n","         -1.8706e+01],\n","        [-1.6097e+01, -1.6078e+01, -1.3313e+01, -2.6990e+01, -1.1079e+01,\n","         -1.6051e+01, -1.3967e+01, -1.6922e+01, -1.9272e+01, -2.3440e+01,\n","         -2.7915e-04, -1.2016e+01, -1.9828e+01, -1.7963e+01, -2.5352e+01,\n","         -2.2939e+01, -1.9365e+01, -9.3702e+00, -1.5739e+01, -2.2967e+01,\n","         -1.7008e+01, -2.1372e+01, -2.2448e+01, -8.6835e+00, -1.9845e+01,\n","         -1.7502e+01],\n","        [-1.3613e+01, -6.3165e+00, -7.3433e+00, -1.6589e+01, -6.2862e+00,\n","         -1.9659e+01, -1.2618e+01, -1.1202e+01, -1.4578e+01, -2.0070e+01,\n","         -2.3083e-01, -5.2467e+00, -1.2277e+01, -1.0711e+01, -1.6489e+01,\n","         -1.5341e+01, -1.5583e+01, -1.6303e+00, -1.8624e+01, -1.8264e+01,\n","         -1.0832e+01, -1.6262e+01, -1.4017e+01, -7.8546e+00, -1.8615e+01,\n","         -8.4363e+00]], device='cuda:0')\n","Predicted classes: tensor([18,  2,  7, 10, 10], device='cuda:0')\n","Target classes: tensor([18,  2,  7, 10, 10], device='cuda:0')\n","\n","Test set: Average loss: 0.002920, Total sum loss: 0.887786, Accuracy: 37051/38832 (95%)\n","\n","Class A: 1272/1336 (95%)\n","Class B: 787/819 (96%)\n","Class C: 2005/2059 (97%)\n","Class D: 846/922 (92%)\n","Class E: 959/996 (96%)\n","Class F: 1717/1861 (92%)\n","Class G: 521/551 (95%)\n","Class H: 651/709 (92%)\n","Class I: 2346/2438 (96%)\n","Class J: 754/772 (98%)\n","Class K: 552/566 (98%)\n","Class L: 930/986 (94%)\n","Class M: 1777/1851 (96%)\n","Class N: 1579/1636 (97%)\n","Class O: 4889/5060 (97%)\n","Class P: 1698/1781 (95%)\n","Class Q: 560/589 (95%)\n","Class R: 1003/1056 (95%)\n","Class S: 4053/4209 (96%)\n","Class T: 1914/1960 (98%)\n","Class U: 2367/2562 (92%)\n","Class V: 942/988 (95%)\n","Class W: 929/990 (94%)\n","Class X: 561/601 (93%)\n","Class Y: 940/1022 (92%)\n","Class Z: 499/512 (97%)\n","Model saved with new best test loss: 0.0029 \n","\n","Train Epoch: 3 [0/155326 (0%)]\tLoss: 0.004810\n","Train Epoch: 3 [640/155326 (0%)]\tLoss: 0.000645\n","Train Epoch: 3 [1280/155326 (1%)]\tLoss: 0.003167\n","Train Epoch: 3 [1920/155326 (1%)]\tLoss: 0.002505\n","Train Epoch: 3 [2560/155326 (2%)]\tLoss: 0.001854\n","Train Epoch: 3 [3200/155326 (2%)]\tLoss: 0.003028\n","Train Epoch: 3 [3840/155326 (2%)]\tLoss: 0.002335\n","Train Epoch: 3 [4480/155326 (3%)]\tLoss: 0.003093\n","Train Epoch: 3 [5120/155326 (3%)]\tLoss: 0.001377\n","Train Epoch: 3 [5760/155326 (4%)]\tLoss: 0.001179\n","Train Epoch: 3 [6400/155326 (4%)]\tLoss: 0.003655\n","Train Epoch: 3 [7040/155326 (5%)]\tLoss: 0.001107\n","Train Epoch: 3 [7680/155326 (5%)]\tLoss: 0.001761\n","Train Epoch: 3 [8320/155326 (5%)]\tLoss: 0.000642\n","Train Epoch: 3 [8960/155326 (6%)]\tLoss: 0.001750\n","Train Epoch: 3 [9600/155326 (6%)]\tLoss: 0.001195\n","Train Epoch: 3 [10240/155326 (7%)]\tLoss: 0.000317\n","Train Epoch: 3 [10880/155326 (7%)]\tLoss: 0.002164\n","Train Epoch: 3 [11520/155326 (7%)]\tLoss: 0.001660\n","Train Epoch: 3 [12160/155326 (8%)]\tLoss: 0.000875\n","Train Epoch: 3 [12800/155326 (8%)]\tLoss: 0.001309\n","Train Epoch: 3 [13440/155326 (9%)]\tLoss: 0.002330\n","Train Epoch: 3 [14080/155326 (9%)]\tLoss: 0.000790\n","Train Epoch: 3 [14720/155326 (9%)]\tLoss: 0.001706\n","Train Epoch: 3 [15360/155326 (10%)]\tLoss: 0.000872\n","Train Epoch: 3 [16000/155326 (10%)]\tLoss: 0.001829\n","Train Epoch: 3 [16640/155326 (11%)]\tLoss: 0.001812\n","Train Epoch: 3 [17280/155326 (11%)]\tLoss: 0.001529\n","Train Epoch: 3 [17920/155326 (12%)]\tLoss: 0.000851\n","Train Epoch: 3 [18560/155326 (12%)]\tLoss: 0.000287\n","Train Epoch: 3 [19200/155326 (12%)]\tLoss: 0.001965\n","Train Epoch: 3 [19840/155326 (13%)]\tLoss: 0.002322\n","Train Epoch: 3 [20480/155326 (13%)]\tLoss: 0.000883\n","Train Epoch: 3 [21120/155326 (14%)]\tLoss: 0.002311\n","Train Epoch: 3 [21760/155326 (14%)]\tLoss: 0.000969\n","Train Epoch: 3 [22400/155326 (14%)]\tLoss: 0.000768\n","Train Epoch: 3 [23040/155326 (15%)]\tLoss: 0.001010\n","Train Epoch: 3 [23680/155326 (15%)]\tLoss: 0.001399\n","Train Epoch: 3 [24320/155326 (16%)]\tLoss: 0.001116\n","Train Epoch: 3 [24960/155326 (16%)]\tLoss: 0.001013\n","Train Epoch: 3 [25600/155326 (16%)]\tLoss: 0.000824\n","Train Epoch: 3 [26240/155326 (17%)]\tLoss: 0.000947\n","Train Epoch: 3 [26880/155326 (17%)]\tLoss: 0.004673\n","Train Epoch: 3 [27520/155326 (18%)]\tLoss: 0.001718\n","Train Epoch: 3 [28160/155326 (18%)]\tLoss: 0.001679\n","Train Epoch: 3 [28800/155326 (19%)]\tLoss: 0.001270\n","Train Epoch: 3 [29440/155326 (19%)]\tLoss: 0.001485\n","Train Epoch: 3 [30080/155326 (19%)]\tLoss: 0.001243\n","Train Epoch: 3 [30720/155326 (20%)]\tLoss: 0.002339\n","Train Epoch: 3 [31360/155326 (20%)]\tLoss: 0.001895\n","Train Epoch: 3 [32000/155326 (21%)]\tLoss: 0.003783\n","Train Epoch: 3 [32640/155326 (21%)]\tLoss: 0.002028\n","Train Epoch: 3 [33280/155326 (21%)]\tLoss: 0.000995\n","Train Epoch: 3 [33920/155326 (22%)]\tLoss: 0.001605\n","Train Epoch: 3 [34560/155326 (22%)]\tLoss: 0.001228\n","Train Epoch: 3 [35200/155326 (23%)]\tLoss: 0.003131\n","Train Epoch: 3 [35840/155326 (23%)]\tLoss: 0.001262\n","Train Epoch: 3 [36480/155326 (23%)]\tLoss: 0.001199\n","Train Epoch: 3 [37120/155326 (24%)]\tLoss: 0.000725\n","Train Epoch: 3 [37760/155326 (24%)]\tLoss: 0.002489\n","Train Epoch: 3 [38400/155326 (25%)]\tLoss: 0.002651\n","Train Epoch: 3 [39040/155326 (25%)]\tLoss: 0.001465\n","Train Epoch: 3 [39680/155326 (26%)]\tLoss: 0.002329\n","Train Epoch: 3 [40320/155326 (26%)]\tLoss: 0.000875\n","Train Epoch: 3 [40960/155326 (26%)]\tLoss: 0.002441\n","Train Epoch: 3 [41600/155326 (27%)]\tLoss: 0.001550\n","Train Epoch: 3 [42240/155326 (27%)]\tLoss: 0.001436\n","Train Epoch: 3 [42880/155326 (28%)]\tLoss: 0.002088\n","Train Epoch: 3 [43520/155326 (28%)]\tLoss: 0.001107\n","Train Epoch: 3 [44160/155326 (28%)]\tLoss: 0.001468\n","Train Epoch: 3 [44800/155326 (29%)]\tLoss: 0.001908\n","Train Epoch: 3 [45440/155326 (29%)]\tLoss: 0.003183\n","Train Epoch: 3 [46080/155326 (30%)]\tLoss: 0.000222\n","Train Epoch: 3 [46720/155326 (30%)]\tLoss: 0.002127\n","Train Epoch: 3 [47360/155326 (30%)]\tLoss: 0.001397\n","Train Epoch: 3 [48000/155326 (31%)]\tLoss: 0.000935\n","Train Epoch: 3 [48640/155326 (31%)]\tLoss: 0.000910\n","Train Epoch: 3 [49280/155326 (32%)]\tLoss: 0.000832\n","Train Epoch: 3 [49920/155326 (32%)]\tLoss: 0.002113\n","Train Epoch: 3 [50560/155326 (33%)]\tLoss: 0.001918\n","Train Epoch: 3 [51200/155326 (33%)]\tLoss: 0.000670\n","Train Epoch: 3 [51840/155326 (33%)]\tLoss: 0.000803\n","Train Epoch: 3 [52480/155326 (34%)]\tLoss: 0.001113\n","Train Epoch: 3 [53120/155326 (34%)]\tLoss: 0.000839\n","Train Epoch: 3 [53760/155326 (35%)]\tLoss: 0.002020\n","Train Epoch: 3 [54400/155326 (35%)]\tLoss: 0.000867\n","Train Epoch: 3 [55040/155326 (35%)]\tLoss: 0.000605\n","Train Epoch: 3 [55680/155326 (36%)]\tLoss: 0.000690\n","Train Epoch: 3 [56320/155326 (36%)]\tLoss: 0.001235\n","Train Epoch: 3 [56960/155326 (37%)]\tLoss: 0.001912\n","Train Epoch: 3 [57600/155326 (37%)]\tLoss: 0.003658\n","Train Epoch: 3 [58240/155326 (37%)]\tLoss: 0.002073\n","Train Epoch: 3 [58880/155326 (38%)]\tLoss: 0.003467\n","Train Epoch: 3 [59520/155326 (38%)]\tLoss: 0.000653\n","Train Epoch: 3 [60160/155326 (39%)]\tLoss: 0.002670\n","Train Epoch: 3 [60800/155326 (39%)]\tLoss: 0.001156\n","Train Epoch: 3 [61440/155326 (40%)]\tLoss: 0.001877\n","Train Epoch: 3 [62080/155326 (40%)]\tLoss: 0.004689\n","Train Epoch: 3 [62720/155326 (40%)]\tLoss: 0.001317\n","Train Epoch: 3 [63360/155326 (41%)]\tLoss: 0.001643\n","Train Epoch: 3 [64000/155326 (41%)]\tLoss: 0.002052\n","Train Epoch: 3 [64640/155326 (42%)]\tLoss: 0.000819\n","Train Epoch: 3 [65280/155326 (42%)]\tLoss: 0.000915\n","Train Epoch: 3 [65920/155326 (42%)]\tLoss: 0.003624\n","Train Epoch: 3 [66560/155326 (43%)]\tLoss: 0.001372\n","Train Epoch: 3 [67200/155326 (43%)]\tLoss: 0.001269\n","Train Epoch: 3 [67840/155326 (44%)]\tLoss: 0.000936\n","Train Epoch: 3 [68480/155326 (44%)]\tLoss: 0.002603\n","Train Epoch: 3 [69120/155326 (44%)]\tLoss: 0.003301\n","Train Epoch: 3 [69760/155326 (45%)]\tLoss: 0.000668\n","Train Epoch: 3 [70400/155326 (45%)]\tLoss: 0.001646\n","Train Epoch: 3 [71040/155326 (46%)]\tLoss: 0.003908\n","Train Epoch: 3 [71680/155326 (46%)]\tLoss: 0.002183\n","Train Epoch: 3 [72320/155326 (47%)]\tLoss: 0.003092\n","Train Epoch: 3 [72960/155326 (47%)]\tLoss: 0.001517\n","Train Epoch: 3 [73600/155326 (47%)]\tLoss: 0.000671\n","Train Epoch: 3 [74240/155326 (48%)]\tLoss: 0.002406\n","Train Epoch: 3 [74880/155326 (48%)]\tLoss: 0.002119\n","Train Epoch: 3 [75520/155326 (49%)]\tLoss: 0.002382\n","Train Epoch: 3 [76160/155326 (49%)]\tLoss: 0.004262\n","Train Epoch: 3 [76800/155326 (49%)]\tLoss: 0.002896\n","Train Epoch: 3 [77440/155326 (50%)]\tLoss: 0.002077\n","Train Epoch: 3 [78080/155326 (50%)]\tLoss: 0.004510\n","Train Epoch: 3 [78720/155326 (51%)]\tLoss: 0.002008\n","Train Epoch: 3 [79360/155326 (51%)]\tLoss: 0.002215\n","Train Epoch: 3 [80000/155326 (52%)]\tLoss: 0.001050\n","Train Epoch: 3 [80640/155326 (52%)]\tLoss: 0.002554\n","Train Epoch: 3 [81280/155326 (52%)]\tLoss: 0.001081\n","Train Epoch: 3 [81920/155326 (53%)]\tLoss: 0.002228\n","Train Epoch: 3 [82560/155326 (53%)]\tLoss: 0.001352\n","Train Epoch: 3 [83200/155326 (54%)]\tLoss: 0.001219\n","Train Epoch: 3 [83840/155326 (54%)]\tLoss: 0.001354\n","Train Epoch: 3 [84480/155326 (54%)]\tLoss: 0.002834\n","Train Epoch: 3 [85120/155326 (55%)]\tLoss: 0.001580\n","Train Epoch: 3 [85760/155326 (55%)]\tLoss: 0.002534\n","Train Epoch: 3 [86400/155326 (56%)]\tLoss: 0.000933\n","Train Epoch: 3 [87040/155326 (56%)]\tLoss: 0.002047\n","Train Epoch: 3 [87680/155326 (56%)]\tLoss: 0.001579\n","Train Epoch: 3 [88320/155326 (57%)]\tLoss: 0.001617\n","Train Epoch: 3 [88960/155326 (57%)]\tLoss: 0.001098\n","Train Epoch: 3 [89600/155326 (58%)]\tLoss: 0.001953\n","Train Epoch: 3 [90240/155326 (58%)]\tLoss: 0.001787\n","Train Epoch: 3 [90880/155326 (59%)]\tLoss: 0.001679\n","Train Epoch: 3 [91520/155326 (59%)]\tLoss: 0.001159\n","Train Epoch: 3 [92160/155326 (59%)]\tLoss: 0.001128\n","Train Epoch: 3 [92800/155326 (60%)]\tLoss: 0.001638\n","Train Epoch: 3 [93440/155326 (60%)]\tLoss: 0.000575\n","Train Epoch: 3 [94080/155326 (61%)]\tLoss: 0.001199\n","Train Epoch: 3 [94720/155326 (61%)]\tLoss: 0.001346\n","Train Epoch: 3 [95360/155326 (61%)]\tLoss: 0.000447\n","Train Epoch: 3 [96000/155326 (62%)]\tLoss: 0.002082\n","Train Epoch: 3 [96640/155326 (62%)]\tLoss: 0.004062\n","Train Epoch: 3 [97280/155326 (63%)]\tLoss: 0.002775\n","Train Epoch: 3 [97920/155326 (63%)]\tLoss: 0.002188\n","Train Epoch: 3 [98560/155326 (63%)]\tLoss: 0.002070\n","Train Epoch: 3 [99200/155326 (64%)]\tLoss: 0.001168\n","Train Epoch: 3 [99840/155326 (64%)]\tLoss: 0.000786\n","Train Epoch: 3 [100480/155326 (65%)]\tLoss: 0.001936\n","Train Epoch: 3 [101120/155326 (65%)]\tLoss: 0.002160\n","Train Epoch: 3 [101760/155326 (66%)]\tLoss: 0.000387\n","Train Epoch: 3 [102400/155326 (66%)]\tLoss: 0.001803\n","Train Epoch: 3 [103040/155326 (66%)]\tLoss: 0.001264\n","Train Epoch: 3 [103680/155326 (67%)]\tLoss: 0.000482\n","Train Epoch: 3 [104320/155326 (67%)]\tLoss: 0.002419\n","Train Epoch: 3 [104960/155326 (68%)]\tLoss: 0.004180\n","Train Epoch: 3 [105600/155326 (68%)]\tLoss: 0.001802\n","Train Epoch: 3 [106240/155326 (68%)]\tLoss: 0.002786\n","Train Epoch: 3 [106880/155326 (69%)]\tLoss: 0.002412\n","Train Epoch: 3 [107520/155326 (69%)]\tLoss: 0.000730\n","Train Epoch: 3 [108160/155326 (70%)]\tLoss: 0.002524\n","Train Epoch: 3 [108800/155326 (70%)]\tLoss: 0.000601\n","Train Epoch: 3 [109440/155326 (70%)]\tLoss: 0.000650\n","Train Epoch: 3 [110080/155326 (71%)]\tLoss: 0.001347\n","Train Epoch: 3 [110720/155326 (71%)]\tLoss: 0.000655\n","Train Epoch: 3 [111360/155326 (72%)]\tLoss: 0.000623\n","Train Epoch: 3 [112000/155326 (72%)]\tLoss: 0.000432\n","Train Epoch: 3 [112640/155326 (73%)]\tLoss: 0.000798\n","Train Epoch: 3 [113280/155326 (73%)]\tLoss: 0.001576\n","Train Epoch: 3 [113920/155326 (73%)]\tLoss: 0.001198\n","Train Epoch: 3 [114560/155326 (74%)]\tLoss: 0.001137\n","Train Epoch: 3 [115200/155326 (74%)]\tLoss: 0.001347\n","Train Epoch: 3 [115840/155326 (75%)]\tLoss: 0.002110\n","Train Epoch: 3 [116480/155326 (75%)]\tLoss: 0.000737\n","Train Epoch: 3 [117120/155326 (75%)]\tLoss: 0.003650\n","Train Epoch: 3 [117760/155326 (76%)]\tLoss: 0.000237\n","Train Epoch: 3 [118400/155326 (76%)]\tLoss: 0.000851\n","Train Epoch: 3 [119040/155326 (77%)]\tLoss: 0.000774\n","Train Epoch: 3 [119680/155326 (77%)]\tLoss: 0.002026\n","Train Epoch: 3 [120320/155326 (77%)]\tLoss: 0.001991\n","Train Epoch: 3 [120960/155326 (78%)]\tLoss: 0.000630\n","Train Epoch: 3 [121600/155326 (78%)]\tLoss: 0.002817\n","Train Epoch: 3 [122240/155326 (79%)]\tLoss: 0.001849\n","Train Epoch: 3 [122880/155326 (79%)]\tLoss: 0.001394\n","Train Epoch: 3 [123520/155326 (80%)]\tLoss: 0.000619\n","Train Epoch: 3 [124160/155326 (80%)]\tLoss: 0.004302\n","Train Epoch: 3 [124800/155326 (80%)]\tLoss: 0.001067\n","Train Epoch: 3 [125440/155326 (81%)]\tLoss: 0.000933\n","Train Epoch: 3 [126080/155326 (81%)]\tLoss: 0.000700\n","Train Epoch: 3 [126720/155326 (82%)]\tLoss: 0.001250\n","Train Epoch: 3 [127360/155326 (82%)]\tLoss: 0.002145\n","Train Epoch: 3 [128000/155326 (82%)]\tLoss: 0.002429\n","Train Epoch: 3 [128640/155326 (83%)]\tLoss: 0.002252\n","Train Epoch: 3 [129280/155326 (83%)]\tLoss: 0.001233\n","Train Epoch: 3 [129920/155326 (84%)]\tLoss: 0.001882\n","Train Epoch: 3 [130560/155326 (84%)]\tLoss: 0.002748\n","Train Epoch: 3 [131200/155326 (84%)]\tLoss: 0.001111\n","Train Epoch: 3 [131840/155326 (85%)]\tLoss: 0.000633\n","Train Epoch: 3 [132480/155326 (85%)]\tLoss: 0.000764\n","Train Epoch: 3 [133120/155326 (86%)]\tLoss: 0.004129\n","Train Epoch: 3 [133760/155326 (86%)]\tLoss: 0.001349\n","Train Epoch: 3 [134400/155326 (87%)]\tLoss: 0.001627\n","Train Epoch: 3 [135040/155326 (87%)]\tLoss: 0.002379\n","Train Epoch: 3 [135680/155326 (87%)]\tLoss: 0.001660\n","Train Epoch: 3 [136320/155326 (88%)]\tLoss: 0.000960\n","Train Epoch: 3 [136960/155326 (88%)]\tLoss: 0.002925\n","Train Epoch: 3 [137600/155326 (89%)]\tLoss: 0.002094\n","Train Epoch: 3 [138240/155326 (89%)]\tLoss: 0.001010\n","Train Epoch: 3 [138880/155326 (89%)]\tLoss: 0.001262\n","Train Epoch: 3 [139520/155326 (90%)]\tLoss: 0.000506\n","Train Epoch: 3 [140160/155326 (90%)]\tLoss: 0.001289\n","Train Epoch: 3 [140800/155326 (91%)]\tLoss: 0.002265\n","Train Epoch: 3 [141440/155326 (91%)]\tLoss: 0.001653\n","Train Epoch: 3 [142080/155326 (91%)]\tLoss: 0.001960\n","Train Epoch: 3 [142720/155326 (92%)]\tLoss: 0.001467\n","Train Epoch: 3 [143360/155326 (92%)]\tLoss: 0.000720\n","Train Epoch: 3 [144000/155326 (93%)]\tLoss: 0.002225\n","Train Epoch: 3 [144640/155326 (93%)]\tLoss: 0.000710\n","Train Epoch: 3 [145280/155326 (94%)]\tLoss: 0.002110\n","Train Epoch: 3 [145920/155326 (94%)]\tLoss: 0.001970\n","Train Epoch: 3 [146560/155326 (94%)]\tLoss: 0.002764\n","Train Epoch: 3 [147200/155326 (95%)]\tLoss: 0.001180\n","Train Epoch: 3 [147840/155326 (95%)]\tLoss: 0.002947\n","Train Epoch: 3 [148480/155326 (96%)]\tLoss: 0.003556\n","Train Epoch: 3 [149120/155326 (96%)]\tLoss: 0.000797\n","Train Epoch: 3 [149760/155326 (96%)]\tLoss: 0.001460\n","Train Epoch: 3 [150400/155326 (97%)]\tLoss: 0.001764\n","Train Epoch: 3 [151040/155326 (97%)]\tLoss: 0.000715\n","Train Epoch: 3 [151680/155326 (98%)]\tLoss: 0.001783\n","Train Epoch: 3 [152320/155326 (98%)]\tLoss: 0.001164\n","Train Epoch: 3 [152960/155326 (98%)]\tLoss: 0.000589\n","Train Epoch: 3 [153600/155326 (99%)]\tLoss: 0.000461\n","Train Epoch: 3 [154240/155326 (99%)]\tLoss: 0.002312\n","Train Epoch: 3 [154880/155326 (100%)]\tLoss: 0.000803\n","Sample outputs (log probs): tensor([[-3.1308e+01, -2.8546e+01, -2.6292e+01, -1.7197e+01, -2.7354e+01,\n","         -1.6400e+01, -3.6950e+01, -3.4216e+01, -1.2836e+01, -7.5740e+00,\n","         -2.9474e+01, -3.1277e+01, -2.6386e+01, -2.5119e+01, -2.9878e+01,\n","         -1.7608e+01, -3.1211e+01, -2.9872e+01, -2.4775e+01, -5.4750e-04,\n","         -2.6943e+01, -1.6780e+01, -2.9017e+01, -1.7567e+01, -1.0386e+01,\n","         -1.6393e+01],\n","        [-2.5278e+01, -1.3911e+01, -1.9272e+01, -2.2505e+01, -1.1541e+01,\n","         -1.2164e+01, -1.1461e+01, -2.9464e+01, -1.8763e+01, -1.0906e+01,\n","         -2.3736e+01, -2.7708e+01, -3.2962e+01, -3.6964e+01, -2.1804e+01,\n","         -2.9009e+01, -2.0739e+01, -3.1984e+01, -4.4702e-05, -2.4552e+01,\n","         -2.6347e+01, -3.0596e+01, -3.6524e+01, -2.5297e+01, -2.0922e+01,\n","         -1.9757e+01],\n","        [-5.4279e+00, -1.0119e+01, -1.3957e+01, -1.2880e+01, -1.6211e+01,\n","         -1.3456e+01, -1.0242e+01, -1.8781e-02, -1.3031e+01, -1.3073e+01,\n","         -6.4023e+00, -1.4430e+01, -4.6063e+00, -8.4621e+00, -1.2407e+01,\n","         -1.0787e+01, -1.1803e+01, -1.0352e+01, -1.4335e+01, -1.1418e+01,\n","         -8.0563e+00, -9.8393e+00, -6.7330e+00, -1.0321e+01, -7.4199e+00,\n","         -1.4558e+01],\n","        [-1.3717e+01, -1.1502e+01, -1.2110e+01, -7.3152e+00, -1.8071e+01,\n","         -1.4169e+01, -1.3696e+01, -8.0836e+00, -9.2502e+00, -5.9048e+00,\n","         -1.2831e+01, -9.0380e+00, -1.0015e+01, -4.5695e+00, -1.0008e+01,\n","         -9.6697e+00, -1.0018e+01, -1.6605e+01, -1.2718e+01, -9.6956e+00,\n","         -2.8351e+00, -1.0322e-01, -3.7806e+00, -9.6768e+00, -6.2523e+00,\n","         -1.4952e+01],\n","        [-1.9811e+01, -2.3874e+01, -2.9928e+01, -2.8643e+01, -2.5837e+01,\n","         -2.4197e+01, -2.8096e+01, -1.9168e+01, -1.8368e+01, -2.6685e+01,\n","         -9.8573e+00, -1.7695e+01, -2.0859e+01, -2.1416e+01, -3.7966e+01,\n","         -2.6061e+01, -2.9168e+01, -1.8434e+01, -2.5107e+01, -2.2975e+01,\n","         -1.8550e+01, -2.3806e+01, -2.5226e+01, -5.2689e-05, -1.5783e+01,\n","         -1.6721e+01]], device='cuda:0')\n","Predicted classes: tensor([19, 18,  7, 21, 23], device='cuda:0')\n","Target classes: tensor([19, 18,  7, 21, 23], device='cuda:0')\n","\n","Test set: Average loss: 0.002373, Total sum loss: 0.721455, Accuracy: 37363/38832 (96%)\n","\n","Class A: 1273/1336 (95%)\n","Class B: 791/819 (97%)\n","Class C: 1963/2059 (95%)\n","Class D: 860/922 (93%)\n","Class E: 955/996 (96%)\n","Class F: 1786/1861 (96%)\n","Class G: 533/551 (97%)\n","Class H: 677/709 (95%)\n","Class I: 2356/2438 (97%)\n","Class J: 753/772 (98%)\n","Class K: 549/566 (97%)\n","Class L: 963/986 (98%)\n","Class M: 1766/1851 (95%)\n","Class N: 1574/1636 (96%)\n","Class O: 4860/5060 (96%)\n","Class P: 1732/1781 (97%)\n","Class Q: 570/589 (97%)\n","Class R: 976/1056 (92%)\n","Class S: 4131/4209 (98%)\n","Class T: 1913/1960 (98%)\n","Class U: 2447/2562 (96%)\n","Class V: 939/988 (95%)\n","Class W: 958/990 (97%)\n","Class X: 568/601 (95%)\n","Class Y: 966/1022 (95%)\n","Class Z: 504/512 (98%)\n","Model saved with new best test loss: 0.0024 \n","\n","Train Epoch: 4 [0/155326 (0%)]\tLoss: 0.000789\n","Train Epoch: 4 [640/155326 (0%)]\tLoss: 0.002161\n","Train Epoch: 4 [1280/155326 (1%)]\tLoss: 0.001508\n","Train Epoch: 4 [1920/155326 (1%)]\tLoss: 0.000638\n","Train Epoch: 4 [2560/155326 (2%)]\tLoss: 0.000923\n","Train Epoch: 4 [3200/155326 (2%)]\tLoss: 0.001499\n","Train Epoch: 4 [3840/155326 (2%)]\tLoss: 0.001068\n","Train Epoch: 4 [4480/155326 (3%)]\tLoss: 0.001755\n","Train Epoch: 4 [5120/155326 (3%)]\tLoss: 0.002363\n","Train Epoch: 4 [5760/155326 (4%)]\tLoss: 0.001451\n","Train Epoch: 4 [6400/155326 (4%)]\tLoss: 0.000746\n","Train Epoch: 4 [7040/155326 (5%)]\tLoss: 0.000959\n","Train Epoch: 4 [7680/155326 (5%)]\tLoss: 0.000604\n","Train Epoch: 4 [8320/155326 (5%)]\tLoss: 0.000248\n","Train Epoch: 4 [8960/155326 (6%)]\tLoss: 0.000475\n","Train Epoch: 4 [9600/155326 (6%)]\tLoss: 0.002514\n","Train Epoch: 4 [10240/155326 (7%)]\tLoss: 0.002339\n","Train Epoch: 4 [10880/155326 (7%)]\tLoss: 0.001257\n","Train Epoch: 4 [11520/155326 (7%)]\tLoss: 0.000734\n","Train Epoch: 4 [12160/155326 (8%)]\tLoss: 0.000285\n","Train Epoch: 4 [12800/155326 (8%)]\tLoss: 0.000851\n","Train Epoch: 4 [13440/155326 (9%)]\tLoss: 0.001882\n","Train Epoch: 4 [14080/155326 (9%)]\tLoss: 0.002129\n","Train Epoch: 4 [14720/155326 (9%)]\tLoss: 0.000996\n","Train Epoch: 4 [15360/155326 (10%)]\tLoss: 0.000857\n","Train Epoch: 4 [16000/155326 (10%)]\tLoss: 0.002258\n","Train Epoch: 4 [16640/155326 (11%)]\tLoss: 0.001022\n","Train Epoch: 4 [17280/155326 (11%)]\tLoss: 0.005331\n","Train Epoch: 4 [17920/155326 (12%)]\tLoss: 0.002364\n","Train Epoch: 4 [18560/155326 (12%)]\tLoss: 0.000851\n","Train Epoch: 4 [19200/155326 (12%)]\tLoss: 0.002005\n","Train Epoch: 4 [19840/155326 (13%)]\tLoss: 0.000843\n","Train Epoch: 4 [20480/155326 (13%)]\tLoss: 0.001284\n","Train Epoch: 4 [21120/155326 (14%)]\tLoss: 0.000599\n","Train Epoch: 4 [21760/155326 (14%)]\tLoss: 0.000527\n","Train Epoch: 4 [22400/155326 (14%)]\tLoss: 0.001395\n","Train Epoch: 4 [23040/155326 (15%)]\tLoss: 0.000865\n","Train Epoch: 4 [23680/155326 (15%)]\tLoss: 0.000940\n","Train Epoch: 4 [24320/155326 (16%)]\tLoss: 0.000506\n","Train Epoch: 4 [24960/155326 (16%)]\tLoss: 0.002952\n","Train Epoch: 4 [25600/155326 (16%)]\tLoss: 0.001517\n","Train Epoch: 4 [26240/155326 (17%)]\tLoss: 0.001301\n","Train Epoch: 4 [26880/155326 (17%)]\tLoss: 0.001256\n","Train Epoch: 4 [27520/155326 (18%)]\tLoss: 0.000734\n","Train Epoch: 4 [28160/155326 (18%)]\tLoss: 0.001851\n","Train Epoch: 4 [28800/155326 (19%)]\tLoss: 0.002973\n","Train Epoch: 4 [29440/155326 (19%)]\tLoss: 0.000760\n","Train Epoch: 4 [30080/155326 (19%)]\tLoss: 0.001362\n","Train Epoch: 4 [30720/155326 (20%)]\tLoss: 0.005185\n","Train Epoch: 4 [31360/155326 (20%)]\tLoss: 0.000847\n","Train Epoch: 4 [32000/155326 (21%)]\tLoss: 0.000802\n","Train Epoch: 4 [32640/155326 (21%)]\tLoss: 0.001554\n","Train Epoch: 4 [33280/155326 (21%)]\tLoss: 0.001145\n","Train Epoch: 4 [33920/155326 (22%)]\tLoss: 0.001438\n","Train Epoch: 4 [34560/155326 (22%)]\tLoss: 0.001014\n","Train Epoch: 4 [35200/155326 (23%)]\tLoss: 0.000557\n","Train Epoch: 4 [35840/155326 (23%)]\tLoss: 0.001782\n","Train Epoch: 4 [36480/155326 (23%)]\tLoss: 0.002454\n","Train Epoch: 4 [37120/155326 (24%)]\tLoss: 0.000983\n","Train Epoch: 4 [37760/155326 (24%)]\tLoss: 0.000782\n","Train Epoch: 4 [38400/155326 (25%)]\tLoss: 0.000713\n","Train Epoch: 4 [39040/155326 (25%)]\tLoss: 0.000813\n","Train Epoch: 4 [39680/155326 (26%)]\tLoss: 0.001295\n","Train Epoch: 4 [40320/155326 (26%)]\tLoss: 0.001251\n","Train Epoch: 4 [40960/155326 (26%)]\tLoss: 0.000915\n","Train Epoch: 4 [41600/155326 (27%)]\tLoss: 0.001174\n","Train Epoch: 4 [42240/155326 (27%)]\tLoss: 0.001670\n","Train Epoch: 4 [42880/155326 (28%)]\tLoss: 0.001068\n","Train Epoch: 4 [43520/155326 (28%)]\tLoss: 0.001064\n","Train Epoch: 4 [44160/155326 (28%)]\tLoss: 0.001008\n","Train Epoch: 4 [44800/155326 (29%)]\tLoss: 0.001958\n","Train Epoch: 4 [45440/155326 (29%)]\tLoss: 0.003782\n","Train Epoch: 4 [46080/155326 (30%)]\tLoss: 0.001769\n","Train Epoch: 4 [46720/155326 (30%)]\tLoss: 0.000482\n","Train Epoch: 4 [47360/155326 (30%)]\tLoss: 0.001801\n","Train Epoch: 4 [48000/155326 (31%)]\tLoss: 0.000454\n","Train Epoch: 4 [48640/155326 (31%)]\tLoss: 0.001481\n","Train Epoch: 4 [49280/155326 (32%)]\tLoss: 0.001148\n","Train Epoch: 4 [49920/155326 (32%)]\tLoss: 0.001157\n","Train Epoch: 4 [50560/155326 (33%)]\tLoss: 0.000505\n","Train Epoch: 4 [51200/155326 (33%)]\tLoss: 0.002421\n","Train Epoch: 4 [51840/155326 (33%)]\tLoss: 0.000873\n","Train Epoch: 4 [52480/155326 (34%)]\tLoss: 0.000908\n","Train Epoch: 4 [53120/155326 (34%)]\tLoss: 0.000892\n","Train Epoch: 4 [53760/155326 (35%)]\tLoss: 0.000817\n","Train Epoch: 4 [54400/155326 (35%)]\tLoss: 0.002171\n","Train Epoch: 4 [55040/155326 (35%)]\tLoss: 0.001845\n","Train Epoch: 4 [55680/155326 (36%)]\tLoss: 0.002251\n","Train Epoch: 4 [56320/155326 (36%)]\tLoss: 0.001556\n","Train Epoch: 4 [56960/155326 (37%)]\tLoss: 0.001080\n","Train Epoch: 4 [57600/155326 (37%)]\tLoss: 0.000400\n","Train Epoch: 4 [58240/155326 (37%)]\tLoss: 0.001521\n","Train Epoch: 4 [58880/155326 (38%)]\tLoss: 0.000629\n","Train Epoch: 4 [59520/155326 (38%)]\tLoss: 0.000384\n","Train Epoch: 4 [60160/155326 (39%)]\tLoss: 0.002592\n","Train Epoch: 4 [60800/155326 (39%)]\tLoss: 0.000506\n","Train Epoch: 4 [61440/155326 (40%)]\tLoss: 0.000968\n","Train Epoch: 4 [62080/155326 (40%)]\tLoss: 0.001242\n","Train Epoch: 4 [62720/155326 (40%)]\tLoss: 0.002016\n","Train Epoch: 4 [63360/155326 (41%)]\tLoss: 0.001503\n","Train Epoch: 4 [64000/155326 (41%)]\tLoss: 0.000746\n","Train Epoch: 4 [64640/155326 (42%)]\tLoss: 0.001794\n","Train Epoch: 4 [65280/155326 (42%)]\tLoss: 0.000842\n","Train Epoch: 4 [65920/155326 (42%)]\tLoss: 0.001053\n","Train Epoch: 4 [66560/155326 (43%)]\tLoss: 0.000905\n","Train Epoch: 4 [67200/155326 (43%)]\tLoss: 0.001653\n","Train Epoch: 4 [67840/155326 (44%)]\tLoss: 0.001619\n","Train Epoch: 4 [68480/155326 (44%)]\tLoss: 0.002352\n","Train Epoch: 4 [69120/155326 (44%)]\tLoss: 0.000677\n","Train Epoch: 4 [69760/155326 (45%)]\tLoss: 0.000789\n","Train Epoch: 4 [70400/155326 (45%)]\tLoss: 0.001529\n","Train Epoch: 4 [71040/155326 (46%)]\tLoss: 0.000694\n","Train Epoch: 4 [71680/155326 (46%)]\tLoss: 0.003022\n","Train Epoch: 4 [72320/155326 (47%)]\tLoss: 0.000512\n","Train Epoch: 4 [72960/155326 (47%)]\tLoss: 0.001753\n","Train Epoch: 4 [73600/155326 (47%)]\tLoss: 0.002761\n","Train Epoch: 4 [74240/155326 (48%)]\tLoss: 0.000678\n","Train Epoch: 4 [74880/155326 (48%)]\tLoss: 0.001493\n","Train Epoch: 4 [75520/155326 (49%)]\tLoss: 0.000910\n","Train Epoch: 4 [76160/155326 (49%)]\tLoss: 0.001190\n","Train Epoch: 4 [76800/155326 (49%)]\tLoss: 0.000714\n","Train Epoch: 4 [77440/155326 (50%)]\tLoss: 0.000794\n","Train Epoch: 4 [78080/155326 (50%)]\tLoss: 0.000725\n","Train Epoch: 4 [78720/155326 (51%)]\tLoss: 0.000810\n","Train Epoch: 4 [79360/155326 (51%)]\tLoss: 0.002338\n","Train Epoch: 4 [80000/155326 (52%)]\tLoss: 0.003528\n","Train Epoch: 4 [80640/155326 (52%)]\tLoss: 0.000791\n","Train Epoch: 4 [81280/155326 (52%)]\tLoss: 0.000428\n","Train Epoch: 4 [81920/155326 (53%)]\tLoss: 0.000843\n","Train Epoch: 4 [82560/155326 (53%)]\tLoss: 0.001188\n","Train Epoch: 4 [83200/155326 (54%)]\tLoss: 0.002902\n","Train Epoch: 4 [83840/155326 (54%)]\tLoss: 0.003906\n","Train Epoch: 4 [84480/155326 (54%)]\tLoss: 0.001481\n","Train Epoch: 4 [85120/155326 (55%)]\tLoss: 0.002824\n","Train Epoch: 4 [85760/155326 (55%)]\tLoss: 0.002863\n","Train Epoch: 4 [86400/155326 (56%)]\tLoss: 0.000770\n","Train Epoch: 4 [87040/155326 (56%)]\tLoss: 0.000900\n","Train Epoch: 4 [87680/155326 (56%)]\tLoss: 0.000600\n","Train Epoch: 4 [88320/155326 (57%)]\tLoss: 0.002501\n","Train Epoch: 4 [88960/155326 (57%)]\tLoss: 0.001153\n","Train Epoch: 4 [89600/155326 (58%)]\tLoss: 0.000805\n","Train Epoch: 4 [90240/155326 (58%)]\tLoss: 0.001351\n","Train Epoch: 4 [90880/155326 (59%)]\tLoss: 0.000809\n","Train Epoch: 4 [91520/155326 (59%)]\tLoss: 0.001155\n","Train Epoch: 4 [92160/155326 (59%)]\tLoss: 0.001196\n","Train Epoch: 4 [92800/155326 (60%)]\tLoss: 0.001258\n","Train Epoch: 4 [93440/155326 (60%)]\tLoss: 0.001546\n","Train Epoch: 4 [94080/155326 (61%)]\tLoss: 0.002117\n","Train Epoch: 4 [94720/155326 (61%)]\tLoss: 0.001914\n","Train Epoch: 4 [95360/155326 (61%)]\tLoss: 0.001023\n","Train Epoch: 4 [96000/155326 (62%)]\tLoss: 0.001125\n","Train Epoch: 4 [96640/155326 (62%)]\tLoss: 0.001223\n","Train Epoch: 4 [97280/155326 (63%)]\tLoss: 0.001025\n","Train Epoch: 4 [97920/155326 (63%)]\tLoss: 0.000150\n","Train Epoch: 4 [98560/155326 (63%)]\tLoss: 0.003014\n","Train Epoch: 4 [99200/155326 (64%)]\tLoss: 0.000894\n","Train Epoch: 4 [99840/155326 (64%)]\tLoss: 0.000427\n","Train Epoch: 4 [100480/155326 (65%)]\tLoss: 0.000652\n","Train Epoch: 4 [101120/155326 (65%)]\tLoss: 0.001668\n","Train Epoch: 4 [101760/155326 (66%)]\tLoss: 0.004614\n","Train Epoch: 4 [102400/155326 (66%)]\tLoss: 0.001961\n","Train Epoch: 4 [103040/155326 (66%)]\tLoss: 0.001571\n","Train Epoch: 4 [103680/155326 (67%)]\tLoss: 0.000905\n","Train Epoch: 4 [104320/155326 (67%)]\tLoss: 0.000870\n","Train Epoch: 4 [104960/155326 (68%)]\tLoss: 0.000888\n","Train Epoch: 4 [105600/155326 (68%)]\tLoss: 0.000537\n","Train Epoch: 4 [106240/155326 (68%)]\tLoss: 0.000400\n","Train Epoch: 4 [106880/155326 (69%)]\tLoss: 0.000889\n","Train Epoch: 4 [107520/155326 (69%)]\tLoss: 0.000631\n","Train Epoch: 4 [108160/155326 (70%)]\tLoss: 0.002336\n","Train Epoch: 4 [108800/155326 (70%)]\tLoss: 0.001739\n","Train Epoch: 4 [109440/155326 (70%)]\tLoss: 0.001923\n","Train Epoch: 4 [110080/155326 (71%)]\tLoss: 0.000273\n","Train Epoch: 4 [110720/155326 (71%)]\tLoss: 0.001347\n","Train Epoch: 4 [111360/155326 (72%)]\tLoss: 0.001693\n","Train Epoch: 4 [112000/155326 (72%)]\tLoss: 0.002497\n","Train Epoch: 4 [112640/155326 (73%)]\tLoss: 0.000523\n","Train Epoch: 4 [113280/155326 (73%)]\tLoss: 0.001319\n","Train Epoch: 4 [113920/155326 (73%)]\tLoss: 0.001467\n","Train Epoch: 4 [114560/155326 (74%)]\tLoss: 0.001683\n","Train Epoch: 4 [115200/155326 (74%)]\tLoss: 0.000326\n","Train Epoch: 4 [115840/155326 (75%)]\tLoss: 0.001285\n","Train Epoch: 4 [116480/155326 (75%)]\tLoss: 0.000909\n","Train Epoch: 4 [117120/155326 (75%)]\tLoss: 0.001154\n","Train Epoch: 4 [117760/155326 (76%)]\tLoss: 0.003567\n","Train Epoch: 4 [118400/155326 (76%)]\tLoss: 0.000300\n","Train Epoch: 4 [119040/155326 (77%)]\tLoss: 0.000417\n","Train Epoch: 4 [119680/155326 (77%)]\tLoss: 0.000702\n","Train Epoch: 4 [120320/155326 (77%)]\tLoss: 0.001438\n","Train Epoch: 4 [120960/155326 (78%)]\tLoss: 0.000715\n","Train Epoch: 4 [121600/155326 (78%)]\tLoss: 0.000756\n","Train Epoch: 4 [122240/155326 (79%)]\tLoss: 0.000590\n","Train Epoch: 4 [122880/155326 (79%)]\tLoss: 0.001016\n","Train Epoch: 4 [123520/155326 (80%)]\tLoss: 0.000672\n","Train Epoch: 4 [124160/155326 (80%)]\tLoss: 0.001845\n","Train Epoch: 4 [124800/155326 (80%)]\tLoss: 0.001361\n","Train Epoch: 4 [125440/155326 (81%)]\tLoss: 0.000555\n","Train Epoch: 4 [126080/155326 (81%)]\tLoss: 0.000962\n","Train Epoch: 4 [126720/155326 (82%)]\tLoss: 0.000205\n","Train Epoch: 4 [127360/155326 (82%)]\tLoss: 0.000742\n","Train Epoch: 4 [128000/155326 (82%)]\tLoss: 0.000790\n","Train Epoch: 4 [128640/155326 (83%)]\tLoss: 0.001134\n","Train Epoch: 4 [129280/155326 (83%)]\tLoss: 0.000494\n","Train Epoch: 4 [129920/155326 (84%)]\tLoss: 0.000703\n","Train Epoch: 4 [130560/155326 (84%)]\tLoss: 0.001326\n","Train Epoch: 4 [131200/155326 (84%)]\tLoss: 0.001572\n","Train Epoch: 4 [131840/155326 (85%)]\tLoss: 0.002228\n","Train Epoch: 4 [132480/155326 (85%)]\tLoss: 0.000753\n","Train Epoch: 4 [133120/155326 (86%)]\tLoss: 0.000641\n","Train Epoch: 4 [133760/155326 (86%)]\tLoss: 0.003240\n","Train Epoch: 4 [134400/155326 (87%)]\tLoss: 0.000660\n","Train Epoch: 4 [135040/155326 (87%)]\tLoss: 0.002801\n","Train Epoch: 4 [135680/155326 (87%)]\tLoss: 0.000414\n","Train Epoch: 4 [136320/155326 (88%)]\tLoss: 0.001169\n","Train Epoch: 4 [136960/155326 (88%)]\tLoss: 0.001620\n","Train Epoch: 4 [137600/155326 (89%)]\tLoss: 0.000575\n","Train Epoch: 4 [138240/155326 (89%)]\tLoss: 0.000517\n","Train Epoch: 4 [138880/155326 (89%)]\tLoss: 0.000845\n","Train Epoch: 4 [139520/155326 (90%)]\tLoss: 0.001216\n","Train Epoch: 4 [140160/155326 (90%)]\tLoss: 0.001071\n","Train Epoch: 4 [140800/155326 (91%)]\tLoss: 0.002901\n","Train Epoch: 4 [141440/155326 (91%)]\tLoss: 0.001296\n","Train Epoch: 4 [142080/155326 (91%)]\tLoss: 0.000400\n","Train Epoch: 4 [142720/155326 (92%)]\tLoss: 0.000610\n","Train Epoch: 4 [143360/155326 (92%)]\tLoss: 0.001186\n","Train Epoch: 4 [144000/155326 (93%)]\tLoss: 0.000692\n","Train Epoch: 4 [144640/155326 (93%)]\tLoss: 0.002461\n","Train Epoch: 4 [145280/155326 (94%)]\tLoss: 0.001038\n","Train Epoch: 4 [145920/155326 (94%)]\tLoss: 0.001985\n","Train Epoch: 4 [146560/155326 (94%)]\tLoss: 0.000972\n","Train Epoch: 4 [147200/155326 (95%)]\tLoss: 0.001078\n","Train Epoch: 4 [147840/155326 (95%)]\tLoss: 0.001414\n","Train Epoch: 4 [148480/155326 (96%)]\tLoss: 0.001003\n","Train Epoch: 4 [149120/155326 (96%)]\tLoss: 0.000711\n","Train Epoch: 4 [149760/155326 (96%)]\tLoss: 0.000447\n","Train Epoch: 4 [150400/155326 (97%)]\tLoss: 0.000739\n","Train Epoch: 4 [151040/155326 (97%)]\tLoss: 0.000818\n","Train Epoch: 4 [151680/155326 (98%)]\tLoss: 0.000825\n","Train Epoch: 4 [152320/155326 (98%)]\tLoss: 0.000831\n","Train Epoch: 4 [152960/155326 (98%)]\tLoss: 0.002001\n","Train Epoch: 4 [153600/155326 (99%)]\tLoss: 0.002260\n","Train Epoch: 4 [154240/155326 (99%)]\tLoss: 0.000796\n","Train Epoch: 4 [154880/155326 (100%)]\tLoss: 0.001910\n","Sample outputs (log probs): tensor([[-1.2989e+01, -1.7998e+01, -1.4560e+01, -1.9904e+01, -1.2783e+01,\n","         -2.1206e-03, -1.1966e+01, -1.6371e+01, -9.6077e+00, -9.5717e+00,\n","         -1.3487e+01, -1.6652e+01, -2.0548e+01, -2.0042e+01, -1.9449e+01,\n","         -1.2547e+01, -1.4456e+01, -1.6729e+01, -8.1842e+00, -6.4007e+00,\n","         -1.8484e+01, -1.4013e+01, -2.0099e+01, -1.2825e+01, -1.0780e+01,\n","         -1.5527e+01],\n","        [-7.4555e+00, -8.7752e+00, -9.9645e+00, -1.4974e+01, -8.9473e+00,\n","         -6.3177e+00, -7.5830e+00, -6.4094e+00, -1.1605e+01, -1.4721e+01,\n","         -2.4050e-02, -6.9879e+00, -1.0412e+01, -1.1144e+01, -1.6509e+01,\n","         -1.0222e+01, -1.2158e+01, -4.1594e+00, -9.8011e+00, -1.2439e+01,\n","         -1.0456e+01, -1.1641e+01, -1.0729e+01, -6.2046e+00, -9.1574e+00,\n","         -1.1146e+01],\n","        [-1.2701e+01, -1.7338e+01, -1.1138e+01, -1.0805e+01, -1.6461e+01,\n","         -8.3523e+00, -1.4298e+01, -1.2707e+01, -5.0536e-03, -1.1128e+01,\n","         -1.3517e+01, -5.4726e+00, -1.8531e+01, -1.1166e+01, -1.3681e+01,\n","         -8.3842e+00, -1.3885e+01, -1.3093e+01, -1.4010e+01, -9.2664e+00,\n","         -1.1765e+01, -8.7320e+00, -1.3320e+01, -1.1636e+01, -1.0663e+01,\n","         -1.3238e+01],\n","        [-2.3516e+01, -1.2325e+01, -1.7132e+01, -1.4088e+01, -1.4337e+01,\n","         -1.2913e+01, -1.5209e+01, -2.5324e+01, -1.5683e+01, -7.4784e+00,\n","         -2.6092e+01, -2.6448e+01, -2.7208e+01, -2.5895e+01, -1.3249e+01,\n","         -1.9720e+01, -1.5169e+01, -2.8681e+01, -5.7633e-04, -1.9487e+01,\n","         -2.2081e+01, -2.3491e+01, -2.8426e+01, -2.5056e+01, -1.4890e+01,\n","         -2.3206e+01],\n","        [-1.6208e+01, -2.0332e+01, -1.9675e+01, -2.4208e+01, -1.1696e+01,\n","         -1.0454e-04, -1.6804e+01, -2.3548e+01, -2.1239e+01, -2.0704e+01,\n","         -1.8897e+01, -2.5681e+01, -2.9325e+01, -2.9402e+01, -2.6037e+01,\n","         -9.2914e+00, -2.0865e+01, -1.4844e+01, -1.5801e+01, -1.2647e+01,\n","         -3.0913e+01, -2.3180e+01, -2.5774e+01, -2.2686e+01, -1.8402e+01,\n","         -1.6386e+01]], device='cuda:0')\n","Predicted classes: tensor([ 5, 10,  8, 18,  5], device='cuda:0')\n","Target classes: tensor([ 5, 10,  8, 18,  5], device='cuda:0')\n","\n","Test set: Average loss: 0.002160, Total sum loss: 0.656718, Accuracy: 37596/38832 (97%)\n","\n","Class A: 1290/1336 (97%)\n","Class B: 795/819 (97%)\n","Class C: 1996/2059 (97%)\n","Class D: 848/922 (92%)\n","Class E: 960/996 (96%)\n","Class F: 1800/1861 (97%)\n","Class G: 537/551 (97%)\n","Class H: 674/709 (95%)\n","Class I: 2364/2438 (97%)\n","Class J: 745/772 (97%)\n","Class K: 537/566 (95%)\n","Class L: 964/986 (98%)\n","Class M: 1816/1851 (98%)\n","Class N: 1565/1636 (96%)\n","Class O: 4941/5060 (98%)\n","Class P: 1736/1781 (97%)\n","Class Q: 559/589 (95%)\n","Class R: 1028/1056 (97%)\n","Class S: 4152/4209 (99%)\n","Class T: 1915/1960 (98%)\n","Class U: 2431/2562 (95%)\n","Class V: 939/988 (95%)\n","Class W: 964/990 (97%)\n","Class X: 568/601 (95%)\n","Class Y: 965/1022 (94%)\n","Class Z: 507/512 (99%)\n","Model saved with new best test loss: 0.0022 \n","\n","Train Epoch: 5 [0/155326 (0%)]\tLoss: 0.000986\n","Train Epoch: 5 [640/155326 (0%)]\tLoss: 0.000846\n","Train Epoch: 5 [1280/155326 (1%)]\tLoss: 0.001683\n","Train Epoch: 5 [1920/155326 (1%)]\tLoss: 0.000949\n","Train Epoch: 5 [2560/155326 (2%)]\tLoss: 0.002017\n","Train Epoch: 5 [3200/155326 (2%)]\tLoss: 0.001147\n","Train Epoch: 5 [3840/155326 (2%)]\tLoss: 0.000401\n","Train Epoch: 5 [4480/155326 (3%)]\tLoss: 0.001767\n","Train Epoch: 5 [5120/155326 (3%)]\tLoss: 0.003884\n","Train Epoch: 5 [5760/155326 (4%)]\tLoss: 0.000940\n","Train Epoch: 5 [6400/155326 (4%)]\tLoss: 0.000668\n","Train Epoch: 5 [7040/155326 (5%)]\tLoss: 0.002835\n","Train Epoch: 5 [7680/155326 (5%)]\tLoss: 0.000418\n","Train Epoch: 5 [8320/155326 (5%)]\tLoss: 0.001324\n","Train Epoch: 5 [8960/155326 (6%)]\tLoss: 0.000783\n","Train Epoch: 5 [9600/155326 (6%)]\tLoss: 0.000632\n","Train Epoch: 5 [10240/155326 (7%)]\tLoss: 0.000478\n","Train Epoch: 5 [10880/155326 (7%)]\tLoss: 0.001000\n","Train Epoch: 5 [11520/155326 (7%)]\tLoss: 0.000970\n","Train Epoch: 5 [12160/155326 (8%)]\tLoss: 0.001652\n","Train Epoch: 5 [12800/155326 (8%)]\tLoss: 0.000523\n","Train Epoch: 5 [13440/155326 (9%)]\tLoss: 0.001179\n","Train Epoch: 5 [14080/155326 (9%)]\tLoss: 0.000432\n","Train Epoch: 5 [14720/155326 (9%)]\tLoss: 0.000831\n","Train Epoch: 5 [15360/155326 (10%)]\tLoss: 0.002565\n","Train Epoch: 5 [16000/155326 (10%)]\tLoss: 0.001597\n","Train Epoch: 5 [16640/155326 (11%)]\tLoss: 0.001532\n","Train Epoch: 5 [17280/155326 (11%)]\tLoss: 0.000562\n","Train Epoch: 5 [17920/155326 (12%)]\tLoss: 0.000739\n","Train Epoch: 5 [18560/155326 (12%)]\tLoss: 0.000207\n","Train Epoch: 5 [19200/155326 (12%)]\tLoss: 0.001835\n","Train Epoch: 5 [19840/155326 (13%)]\tLoss: 0.002898\n","Train Epoch: 5 [20480/155326 (13%)]\tLoss: 0.000369\n","Train Epoch: 5 [21120/155326 (14%)]\tLoss: 0.001558\n","Train Epoch: 5 [21760/155326 (14%)]\tLoss: 0.000689\n","Train Epoch: 5 [22400/155326 (14%)]\tLoss: 0.000540\n","Train Epoch: 5 [23040/155326 (15%)]\tLoss: 0.001544\n","Train Epoch: 5 [23680/155326 (15%)]\tLoss: 0.000445\n","Train Epoch: 5 [24320/155326 (16%)]\tLoss: 0.001291\n","Train Epoch: 5 [24960/155326 (16%)]\tLoss: 0.001528\n","Train Epoch: 5 [25600/155326 (16%)]\tLoss: 0.001536\n","Train Epoch: 5 [26240/155326 (17%)]\tLoss: 0.002341\n","Train Epoch: 5 [26880/155326 (17%)]\tLoss: 0.001460\n","Train Epoch: 5 [27520/155326 (18%)]\tLoss: 0.001208\n","Train Epoch: 5 [28160/155326 (18%)]\tLoss: 0.000739\n","Train Epoch: 5 [28800/155326 (19%)]\tLoss: 0.000720\n","Train Epoch: 5 [29440/155326 (19%)]\tLoss: 0.000996\n","Train Epoch: 5 [30080/155326 (19%)]\tLoss: 0.001902\n","Train Epoch: 5 [30720/155326 (20%)]\tLoss: 0.001145\n","Train Epoch: 5 [31360/155326 (20%)]\tLoss: 0.001137\n","Train Epoch: 5 [32000/155326 (21%)]\tLoss: 0.000839\n","Train Epoch: 5 [32640/155326 (21%)]\tLoss: 0.003647\n","Train Epoch: 5 [33280/155326 (21%)]\tLoss: 0.001793\n","Train Epoch: 5 [33920/155326 (22%)]\tLoss: 0.001538\n","Train Epoch: 5 [34560/155326 (22%)]\tLoss: 0.001898\n","Train Epoch: 5 [35200/155326 (23%)]\tLoss: 0.002305\n","Train Epoch: 5 [35840/155326 (23%)]\tLoss: 0.001866\n","Train Epoch: 5 [36480/155326 (23%)]\tLoss: 0.002614\n","Train Epoch: 5 [37120/155326 (24%)]\tLoss: 0.004039\n","Train Epoch: 5 [37760/155326 (24%)]\tLoss: 0.000586\n","Train Epoch: 5 [38400/155326 (25%)]\tLoss: 0.000485\n","Train Epoch: 5 [39040/155326 (25%)]\tLoss: 0.001857\n","Train Epoch: 5 [39680/155326 (26%)]\tLoss: 0.001251\n","Train Epoch: 5 [40320/155326 (26%)]\tLoss: 0.001914\n","Train Epoch: 5 [40960/155326 (26%)]\tLoss: 0.001349\n","Train Epoch: 5 [41600/155326 (27%)]\tLoss: 0.002323\n","Train Epoch: 5 [42240/155326 (27%)]\tLoss: 0.000339\n","Train Epoch: 5 [42880/155326 (28%)]\tLoss: 0.000882\n","Train Epoch: 5 [43520/155326 (28%)]\tLoss: 0.000510\n","Train Epoch: 5 [44160/155326 (28%)]\tLoss: 0.000728\n","Train Epoch: 5 [44800/155326 (29%)]\tLoss: 0.000208\n","Train Epoch: 5 [45440/155326 (29%)]\tLoss: 0.000637\n","Train Epoch: 5 [46080/155326 (30%)]\tLoss: 0.001706\n","Train Epoch: 5 [46720/155326 (30%)]\tLoss: 0.001141\n","Train Epoch: 5 [47360/155326 (30%)]\tLoss: 0.001565\n","Train Epoch: 5 [48000/155326 (31%)]\tLoss: 0.001522\n","Train Epoch: 5 [48640/155326 (31%)]\tLoss: 0.001359\n","Train Epoch: 5 [49280/155326 (32%)]\tLoss: 0.000587\n","Train Epoch: 5 [49920/155326 (32%)]\tLoss: 0.001044\n","Train Epoch: 5 [50560/155326 (33%)]\tLoss: 0.004330\n","Train Epoch: 5 [51200/155326 (33%)]\tLoss: 0.000932\n","Train Epoch: 5 [51840/155326 (33%)]\tLoss: 0.000780\n","Train Epoch: 5 [52480/155326 (34%)]\tLoss: 0.000453\n","Train Epoch: 5 [53120/155326 (34%)]\tLoss: 0.000554\n","Train Epoch: 5 [53760/155326 (35%)]\tLoss: 0.002806\n","Train Epoch: 5 [54400/155326 (35%)]\tLoss: 0.000409\n","Train Epoch: 5 [55040/155326 (35%)]\tLoss: 0.000957\n","Train Epoch: 5 [55680/155326 (36%)]\tLoss: 0.001888\n","Train Epoch: 5 [56320/155326 (36%)]\tLoss: 0.001708\n","Train Epoch: 5 [56960/155326 (37%)]\tLoss: 0.001464\n","Train Epoch: 5 [57600/155326 (37%)]\tLoss: 0.000794\n","Train Epoch: 5 [58240/155326 (37%)]\tLoss: 0.000471\n","Train Epoch: 5 [58880/155326 (38%)]\tLoss: 0.003997\n","Train Epoch: 5 [59520/155326 (38%)]\tLoss: 0.000309\n","Train Epoch: 5 [60160/155326 (39%)]\tLoss: 0.000568\n","Train Epoch: 5 [60800/155326 (39%)]\tLoss: 0.000174\n","Train Epoch: 5 [61440/155326 (40%)]\tLoss: 0.000534\n","Train Epoch: 5 [62080/155326 (40%)]\tLoss: 0.000759\n","Train Epoch: 5 [62720/155326 (40%)]\tLoss: 0.001397\n","Train Epoch: 5 [63360/155326 (41%)]\tLoss: 0.000509\n","Train Epoch: 5 [64000/155326 (41%)]\tLoss: 0.000565\n","Train Epoch: 5 [64640/155326 (42%)]\tLoss: 0.002654\n","Train Epoch: 5 [65280/155326 (42%)]\tLoss: 0.000677\n","Train Epoch: 5 [65920/155326 (42%)]\tLoss: 0.000910\n","Train Epoch: 5 [66560/155326 (43%)]\tLoss: 0.001655\n","Train Epoch: 5 [67200/155326 (43%)]\tLoss: 0.000364\n","Train Epoch: 5 [67840/155326 (44%)]\tLoss: 0.000585\n","Train Epoch: 5 [68480/155326 (44%)]\tLoss: 0.000499\n","Train Epoch: 5 [69120/155326 (44%)]\tLoss: 0.000217\n","Train Epoch: 5 [69760/155326 (45%)]\tLoss: 0.001487\n","Train Epoch: 5 [70400/155326 (45%)]\tLoss: 0.000823\n","Train Epoch: 5 [71040/155326 (46%)]\tLoss: 0.000856\n","Train Epoch: 5 [71680/155326 (46%)]\tLoss: 0.000702\n","Train Epoch: 5 [72320/155326 (47%)]\tLoss: 0.001134\n","Train Epoch: 5 [72960/155326 (47%)]\tLoss: 0.000562\n","Train Epoch: 5 [73600/155326 (47%)]\tLoss: 0.001070\n","Train Epoch: 5 [74240/155326 (48%)]\tLoss: 0.001202\n","Train Epoch: 5 [74880/155326 (48%)]\tLoss: 0.001095\n","Train Epoch: 5 [75520/155326 (49%)]\tLoss: 0.001630\n","Train Epoch: 5 [76160/155326 (49%)]\tLoss: 0.002240\n","Train Epoch: 5 [76800/155326 (49%)]\tLoss: 0.000631\n","Train Epoch: 5 [77440/155326 (50%)]\tLoss: 0.001122\n","Train Epoch: 5 [78080/155326 (50%)]\tLoss: 0.000418\n","Train Epoch: 5 [78720/155326 (51%)]\tLoss: 0.002086\n","Train Epoch: 5 [79360/155326 (51%)]\tLoss: 0.000266\n","Train Epoch: 5 [80000/155326 (52%)]\tLoss: 0.001126\n","Train Epoch: 5 [80640/155326 (52%)]\tLoss: 0.000969\n","Train Epoch: 5 [81280/155326 (52%)]\tLoss: 0.002323\n","Train Epoch: 5 [81920/155326 (53%)]\tLoss: 0.000734\n","Train Epoch: 5 [82560/155326 (53%)]\tLoss: 0.000698\n","Train Epoch: 5 [83200/155326 (54%)]\tLoss: 0.000361\n","Train Epoch: 5 [83840/155326 (54%)]\tLoss: 0.000971\n","Train Epoch: 5 [84480/155326 (54%)]\tLoss: 0.000311\n","Train Epoch: 5 [85120/155326 (55%)]\tLoss: 0.000530\n","Train Epoch: 5 [85760/155326 (55%)]\tLoss: 0.001843\n","Train Epoch: 5 [86400/155326 (56%)]\tLoss: 0.001012\n","Train Epoch: 5 [87040/155326 (56%)]\tLoss: 0.001187\n","Train Epoch: 5 [87680/155326 (56%)]\tLoss: 0.000656\n","Train Epoch: 5 [88320/155326 (57%)]\tLoss: 0.000545\n","Train Epoch: 5 [88960/155326 (57%)]\tLoss: 0.000351\n","Train Epoch: 5 [89600/155326 (58%)]\tLoss: 0.000650\n","Train Epoch: 5 [90240/155326 (58%)]\tLoss: 0.001463\n","Train Epoch: 5 [90880/155326 (59%)]\tLoss: 0.001198\n","Train Epoch: 5 [91520/155326 (59%)]\tLoss: 0.001283\n","Train Epoch: 5 [92160/155326 (59%)]\tLoss: 0.000315\n","Train Epoch: 5 [92800/155326 (60%)]\tLoss: 0.000882\n","Train Epoch: 5 [93440/155326 (60%)]\tLoss: 0.000758\n","Train Epoch: 5 [94080/155326 (61%)]\tLoss: 0.000466\n","Train Epoch: 5 [94720/155326 (61%)]\tLoss: 0.000242\n","Train Epoch: 5 [95360/155326 (61%)]\tLoss: 0.000634\n","Train Epoch: 5 [96000/155326 (62%)]\tLoss: 0.000804\n","Train Epoch: 5 [96640/155326 (62%)]\tLoss: 0.001467\n","Train Epoch: 5 [97280/155326 (63%)]\tLoss: 0.000669\n","Train Epoch: 5 [97920/155326 (63%)]\tLoss: 0.004522\n","Train Epoch: 5 [98560/155326 (63%)]\tLoss: 0.001204\n","Train Epoch: 5 [99200/155326 (64%)]\tLoss: 0.002210\n","Train Epoch: 5 [99840/155326 (64%)]\tLoss: 0.000811\n","Train Epoch: 5 [100480/155326 (65%)]\tLoss: 0.000635\n","Train Epoch: 5 [101120/155326 (65%)]\tLoss: 0.000767\n","Train Epoch: 5 [101760/155326 (66%)]\tLoss: 0.001412\n","Train Epoch: 5 [102400/155326 (66%)]\tLoss: 0.003955\n","Train Epoch: 5 [103040/155326 (66%)]\tLoss: 0.001211\n","Train Epoch: 5 [103680/155326 (67%)]\tLoss: 0.000509\n","Train Epoch: 5 [104320/155326 (67%)]\tLoss: 0.000757\n","Train Epoch: 5 [104960/155326 (68%)]\tLoss: 0.001537\n","Train Epoch: 5 [105600/155326 (68%)]\tLoss: 0.001308\n","Train Epoch: 5 [106240/155326 (68%)]\tLoss: 0.001166\n","Train Epoch: 5 [106880/155326 (69%)]\tLoss: 0.001618\n","Train Epoch: 5 [107520/155326 (69%)]\tLoss: 0.000947\n","Train Epoch: 5 [108160/155326 (70%)]\tLoss: 0.001233\n","Train Epoch: 5 [108800/155326 (70%)]\tLoss: 0.001358\n","Train Epoch: 5 [109440/155326 (70%)]\tLoss: 0.000934\n","Train Epoch: 5 [110080/155326 (71%)]\tLoss: 0.000974\n","Train Epoch: 5 [110720/155326 (71%)]\tLoss: 0.002119\n","Train Epoch: 5 [111360/155326 (72%)]\tLoss: 0.001025\n","Train Epoch: 5 [112000/155326 (72%)]\tLoss: 0.001534\n","Train Epoch: 5 [112640/155326 (73%)]\tLoss: 0.001237\n","Train Epoch: 5 [113280/155326 (73%)]\tLoss: 0.001111\n","Train Epoch: 5 [113920/155326 (73%)]\tLoss: 0.001853\n","Train Epoch: 5 [114560/155326 (74%)]\tLoss: 0.002138\n","Train Epoch: 5 [115200/155326 (74%)]\tLoss: 0.000952\n","Train Epoch: 5 [115840/155326 (75%)]\tLoss: 0.000616\n","Train Epoch: 5 [116480/155326 (75%)]\tLoss: 0.001959\n","Train Epoch: 5 [117120/155326 (75%)]\tLoss: 0.003838\n","Train Epoch: 5 [117760/155326 (76%)]\tLoss: 0.000835\n","Train Epoch: 5 [118400/155326 (76%)]\tLoss: 0.000711\n","Train Epoch: 5 [119040/155326 (77%)]\tLoss: 0.000386\n","Train Epoch: 5 [119680/155326 (77%)]\tLoss: 0.000801\n","Train Epoch: 5 [120320/155326 (77%)]\tLoss: 0.001519\n","Train Epoch: 5 [120960/155326 (78%)]\tLoss: 0.001587\n","Train Epoch: 5 [121600/155326 (78%)]\tLoss: 0.000746\n","Train Epoch: 5 [122240/155326 (79%)]\tLoss: 0.000498\n","Train Epoch: 5 [122880/155326 (79%)]\tLoss: 0.002338\n","Train Epoch: 5 [123520/155326 (80%)]\tLoss: 0.000640\n","Train Epoch: 5 [124160/155326 (80%)]\tLoss: 0.001596\n","Train Epoch: 5 [124800/155326 (80%)]\tLoss: 0.000522\n","Train Epoch: 5 [125440/155326 (81%)]\tLoss: 0.000972\n","Train Epoch: 5 [126080/155326 (81%)]\tLoss: 0.000438\n","Train Epoch: 5 [126720/155326 (82%)]\tLoss: 0.003948\n","Train Epoch: 5 [127360/155326 (82%)]\tLoss: 0.000795\n","Train Epoch: 5 [128000/155326 (82%)]\tLoss: 0.000369\n","Train Epoch: 5 [128640/155326 (83%)]\tLoss: 0.000298\n","Train Epoch: 5 [129280/155326 (83%)]\tLoss: 0.003133\n","Train Epoch: 5 [129920/155326 (84%)]\tLoss: 0.001065\n","Train Epoch: 5 [130560/155326 (84%)]\tLoss: 0.002399\n","Train Epoch: 5 [131200/155326 (84%)]\tLoss: 0.001759\n","Train Epoch: 5 [131840/155326 (85%)]\tLoss: 0.001390\n","Train Epoch: 5 [132480/155326 (85%)]\tLoss: 0.000503\n","Train Epoch: 5 [133120/155326 (86%)]\tLoss: 0.001625\n","Train Epoch: 5 [133760/155326 (86%)]\tLoss: 0.000611\n","Train Epoch: 5 [134400/155326 (87%)]\tLoss: 0.000811\n","Train Epoch: 5 [135040/155326 (87%)]\tLoss: 0.000826\n","Train Epoch: 5 [135680/155326 (87%)]\tLoss: 0.001120\n","Train Epoch: 5 [136320/155326 (88%)]\tLoss: 0.000663\n","Train Epoch: 5 [136960/155326 (88%)]\tLoss: 0.001774\n","Train Epoch: 5 [137600/155326 (89%)]\tLoss: 0.001252\n","Train Epoch: 5 [138240/155326 (89%)]\tLoss: 0.000966\n","Train Epoch: 5 [138880/155326 (89%)]\tLoss: 0.001516\n","Train Epoch: 5 [139520/155326 (90%)]\tLoss: 0.001611\n","Train Epoch: 5 [140160/155326 (90%)]\tLoss: 0.000725\n","Train Epoch: 5 [140800/155326 (91%)]\tLoss: 0.000823\n","Train Epoch: 5 [141440/155326 (91%)]\tLoss: 0.000287\n","Train Epoch: 5 [142080/155326 (91%)]\tLoss: 0.002290\n","Train Epoch: 5 [142720/155326 (92%)]\tLoss: 0.002452\n","Train Epoch: 5 [143360/155326 (92%)]\tLoss: 0.000755\n","Train Epoch: 5 [144000/155326 (93%)]\tLoss: 0.000560\n","Train Epoch: 5 [144640/155326 (93%)]\tLoss: 0.000692\n","Train Epoch: 5 [145280/155326 (94%)]\tLoss: 0.000242\n","Train Epoch: 5 [145920/155326 (94%)]\tLoss: 0.000167\n","Train Epoch: 5 [146560/155326 (94%)]\tLoss: 0.001238\n","Train Epoch: 5 [147200/155326 (95%)]\tLoss: 0.001528\n","Train Epoch: 5 [147840/155326 (95%)]\tLoss: 0.000675\n","Train Epoch: 5 [148480/155326 (96%)]\tLoss: 0.000975\n","Train Epoch: 5 [149120/155326 (96%)]\tLoss: 0.001650\n","Train Epoch: 5 [149760/155326 (96%)]\tLoss: 0.000349\n","Train Epoch: 5 [150400/155326 (97%)]\tLoss: 0.000858\n","Train Epoch: 5 [151040/155326 (97%)]\tLoss: 0.001029\n","Train Epoch: 5 [151680/155326 (98%)]\tLoss: 0.000798\n","Train Epoch: 5 [152320/155326 (98%)]\tLoss: 0.001336\n","Train Epoch: 5 [152960/155326 (98%)]\tLoss: 0.001245\n","Train Epoch: 5 [153600/155326 (99%)]\tLoss: 0.001420\n","Train Epoch: 5 [154240/155326 (99%)]\tLoss: 0.001698\n","Train Epoch: 5 [154880/155326 (100%)]\tLoss: 0.001541\n","Sample outputs (log probs): tensor([[-1.5654e+01, -1.1824e+01, -9.9550e+00, -6.1898e+00, -1.7107e+01,\n","         -1.8409e+01, -1.4895e+01, -1.9207e+01, -1.5467e+01, -1.3631e+01,\n","         -2.4313e+01, -2.1022e+01, -1.7018e+01, -1.8199e+01, -2.1560e-03,\n","         -1.3603e+01, -1.0214e+01, -2.1399e+01, -1.4293e+01, -1.7153e+01,\n","         -1.1765e+01, -1.5318e+01, -1.9630e+01, -2.7338e+01, -1.7106e+01,\n","         -1.9968e+01],\n","        [-1.9357e+01, -1.8321e+01, -1.1471e+01, -1.4878e+01, -2.2259e+01,\n","         -2.3634e+01, -1.5294e+01, -1.2719e+01, -1.3438e+01, -1.1436e+01,\n","         -1.2594e+01, -1.0067e+01, -1.3613e+01, -9.2281e+00, -1.4848e+01,\n","         -2.0445e+01, -9.5692e+00, -1.9442e+01, -2.0762e+01, -1.7602e+01,\n","         -3.6340e-04, -9.6974e+00, -9.7367e+00, -1.4954e+01, -1.4224e+01,\n","         -1.8849e+01],\n","        [-1.1386e+01, -1.4919e+01, -1.0700e+01, -8.5790e+00, -1.3009e+01,\n","         -7.1375e+00, -1.5372e+01, -1.4004e+01, -3.2766e-03, -7.2770e+00,\n","         -1.7753e+01, -7.8378e+00, -1.8309e+01, -1.1727e+01, -9.3657e+00,\n","         -8.1969e+00, -1.4788e+01, -1.5283e+01, -1.0634e+01, -8.8860e+00,\n","         -1.2350e+01, -7.6137e+00, -1.7300e+01, -1.3601e+01, -8.9721e+00,\n","         -1.1897e+01],\n","        [-1.4601e+01, -9.0494e+00, -9.7668e+00, -2.9954e+00, -1.8401e+01,\n","         -1.7339e+01, -1.4540e+01, -1.7418e+01, -1.4573e+01, -1.2104e+01,\n","         -2.2959e+01, -1.8764e+01, -1.5615e+01, -1.4410e+01, -5.1688e-02,\n","         -1.1825e+01, -8.9082e+00, -1.9579e+01, -1.3702e+01, -1.6002e+01,\n","         -1.0393e+01, -1.4370e+01, -1.7596e+01, -2.5463e+01, -1.5760e+01,\n","         -1.8310e+01],\n","        [-1.9932e+01, -1.2961e+01, -9.3299e+00, -6.2444e+00, -1.8773e+01,\n","         -2.0583e+01, -1.6920e+01, -2.3005e+01, -1.7098e+01, -1.3601e+01,\n","         -2.4442e+01, -2.2387e+01, -1.6070e+01, -1.8247e+01, -2.0626e-03,\n","         -1.6203e+01, -1.0713e+01, -2.3398e+01, -1.2528e+01, -1.7412e+01,\n","         -1.4034e+01, -1.9339e+01, -1.9806e+01, -2.9154e+01, -1.7386e+01,\n","         -2.1395e+01]], device='cuda:0')\n","Predicted classes: tensor([14, 20,  8, 14, 14], device='cuda:0')\n","Target classes: tensor([14, 20,  8, 14, 14], device='cuda:0')\n","\n","Test set: Average loss: 0.002099, Total sum loss: 0.638049, Accuracy: 37526/38832 (97%)\n","\n","Class A: 1310/1336 (98%)\n","Class B: 801/819 (98%)\n","Class C: 2018/2059 (98%)\n","Class D: 888/922 (96%)\n","Class E: 981/996 (98%)\n","Class F: 1786/1861 (96%)\n","Class G: 512/551 (93%)\n","Class H: 661/709 (93%)\n","Class I: 2369/2438 (97%)\n","Class J: 745/772 (97%)\n","Class K: 547/566 (97%)\n","Class L: 948/986 (96%)\n","Class M: 1809/1851 (98%)\n","Class N: 1590/1636 (97%)\n","Class O: 4772/5060 (94%)\n","Class P: 1740/1781 (98%)\n","Class Q: 566/589 (96%)\n","Class R: 1021/1056 (97%)\n","Class S: 4155/4209 (99%)\n","Class T: 1930/1960 (98%)\n","Class U: 2481/2562 (97%)\n","Class V: 904/988 (91%)\n","Class W: 962/990 (97%)\n","Class X: 574/601 (96%)\n","Class Y: 950/1022 (93%)\n","Class Z: 506/512 (99%)\n","Model saved with new best test loss: 0.0021 \n","\n","Train Epoch: 6 [0/155326 (0%)]\tLoss: 0.002543\n","Train Epoch: 6 [640/155326 (0%)]\tLoss: 0.000619\n","Train Epoch: 6 [1280/155326 (1%)]\tLoss: 0.000785\n","Train Epoch: 6 [1920/155326 (1%)]\tLoss: 0.000278\n","Train Epoch: 6 [2560/155326 (2%)]\tLoss: 0.000917\n","Train Epoch: 6 [3200/155326 (2%)]\tLoss: 0.000203\n","Train Epoch: 6 [3840/155326 (2%)]\tLoss: 0.001159\n","Train Epoch: 6 [4480/155326 (3%)]\tLoss: 0.001263\n","Train Epoch: 6 [5120/155326 (3%)]\tLoss: 0.001237\n","Train Epoch: 6 [5760/155326 (4%)]\tLoss: 0.001743\n","Train Epoch: 6 [6400/155326 (4%)]\tLoss: 0.000898\n","Train Epoch: 6 [7040/155326 (5%)]\tLoss: 0.000749\n","Train Epoch: 6 [7680/155326 (5%)]\tLoss: 0.001242\n","Train Epoch: 6 [8320/155326 (5%)]\tLoss: 0.000428\n","Train Epoch: 6 [8960/155326 (6%)]\tLoss: 0.000829\n","Train Epoch: 6 [9600/155326 (6%)]\tLoss: 0.000798\n","Train Epoch: 6 [10240/155326 (7%)]\tLoss: 0.001129\n","Train Epoch: 6 [10880/155326 (7%)]\tLoss: 0.001113\n","Train Epoch: 6 [11520/155326 (7%)]\tLoss: 0.000503\n","Train Epoch: 6 [12160/155326 (8%)]\tLoss: 0.002351\n","Train Epoch: 6 [12800/155326 (8%)]\tLoss: 0.000942\n","Train Epoch: 6 [13440/155326 (9%)]\tLoss: 0.000764\n","Train Epoch: 6 [14080/155326 (9%)]\tLoss: 0.001007\n","Train Epoch: 6 [14720/155326 (9%)]\tLoss: 0.001742\n","Train Epoch: 6 [15360/155326 (10%)]\tLoss: 0.001819\n","Train Epoch: 6 [16000/155326 (10%)]\tLoss: 0.000879\n","Train Epoch: 6 [16640/155326 (11%)]\tLoss: 0.002812\n","Train Epoch: 6 [17280/155326 (11%)]\tLoss: 0.001174\n","Train Epoch: 6 [17920/155326 (12%)]\tLoss: 0.000363\n","Train Epoch: 6 [18560/155326 (12%)]\tLoss: 0.001203\n","Train Epoch: 6 [19200/155326 (12%)]\tLoss: 0.000259\n","Train Epoch: 6 [19840/155326 (13%)]\tLoss: 0.001197\n","Train Epoch: 6 [20480/155326 (13%)]\tLoss: 0.001767\n","Train Epoch: 6 [21120/155326 (14%)]\tLoss: 0.000257\n","Train Epoch: 6 [21760/155326 (14%)]\tLoss: 0.000460\n","Train Epoch: 6 [22400/155326 (14%)]\tLoss: 0.000637\n","Train Epoch: 6 [23040/155326 (15%)]\tLoss: 0.000637\n","Train Epoch: 6 [23680/155326 (15%)]\tLoss: 0.000278\n","Train Epoch: 6 [24320/155326 (16%)]\tLoss: 0.001193\n","Train Epoch: 6 [24960/155326 (16%)]\tLoss: 0.001396\n","Train Epoch: 6 [25600/155326 (16%)]\tLoss: 0.002355\n","Train Epoch: 6 [26240/155326 (17%)]\tLoss: 0.000595\n","Train Epoch: 6 [26880/155326 (17%)]\tLoss: 0.001252\n","Train Epoch: 6 [27520/155326 (18%)]\tLoss: 0.000734\n","Train Epoch: 6 [28160/155326 (18%)]\tLoss: 0.000462\n","Train Epoch: 6 [28800/155326 (19%)]\tLoss: 0.002053\n","Train Epoch: 6 [29440/155326 (19%)]\tLoss: 0.001888\n","Train Epoch: 6 [30080/155326 (19%)]\tLoss: 0.001403\n","Train Epoch: 6 [30720/155326 (20%)]\tLoss: 0.001177\n","Train Epoch: 6 [31360/155326 (20%)]\tLoss: 0.000874\n","Train Epoch: 6 [32000/155326 (21%)]\tLoss: 0.001533\n","Train Epoch: 6 [32640/155326 (21%)]\tLoss: 0.001649\n","Train Epoch: 6 [33280/155326 (21%)]\tLoss: 0.000537\n","Train Epoch: 6 [33920/155326 (22%)]\tLoss: 0.001178\n","Train Epoch: 6 [34560/155326 (22%)]\tLoss: 0.000642\n","Train Epoch: 6 [35200/155326 (23%)]\tLoss: 0.001434\n","Train Epoch: 6 [35840/155326 (23%)]\tLoss: 0.000531\n","Train Epoch: 6 [36480/155326 (23%)]\tLoss: 0.000691\n","Train Epoch: 6 [37120/155326 (24%)]\tLoss: 0.000655\n","Train Epoch: 6 [37760/155326 (24%)]\tLoss: 0.001570\n","Train Epoch: 6 [38400/155326 (25%)]\tLoss: 0.001800\n","Train Epoch: 6 [39040/155326 (25%)]\tLoss: 0.000525\n","Train Epoch: 6 [39680/155326 (26%)]\tLoss: 0.000480\n","Train Epoch: 6 [40320/155326 (26%)]\tLoss: 0.001327\n","Train Epoch: 6 [40960/155326 (26%)]\tLoss: 0.000298\n","Train Epoch: 6 [41600/155326 (27%)]\tLoss: 0.000857\n","Train Epoch: 6 [42240/155326 (27%)]\tLoss: 0.000324\n","Train Epoch: 6 [42880/155326 (28%)]\tLoss: 0.003007\n","Train Epoch: 6 [43520/155326 (28%)]\tLoss: 0.000362\n","Train Epoch: 6 [44160/155326 (28%)]\tLoss: 0.000505\n","Train Epoch: 6 [44800/155326 (29%)]\tLoss: 0.001266\n","Train Epoch: 6 [45440/155326 (29%)]\tLoss: 0.000765\n","Train Epoch: 6 [46080/155326 (30%)]\tLoss: 0.001402\n","Train Epoch: 6 [46720/155326 (30%)]\tLoss: 0.001413\n","Train Epoch: 6 [47360/155326 (30%)]\tLoss: 0.001479\n","Train Epoch: 6 [48000/155326 (31%)]\tLoss: 0.000758\n","Train Epoch: 6 [48640/155326 (31%)]\tLoss: 0.000963\n","Train Epoch: 6 [49280/155326 (32%)]\tLoss: 0.000768\n","Train Epoch: 6 [49920/155326 (32%)]\tLoss: 0.000685\n","Train Epoch: 6 [50560/155326 (33%)]\tLoss: 0.000875\n","Train Epoch: 6 [51200/155326 (33%)]\tLoss: 0.000517\n","Train Epoch: 6 [51840/155326 (33%)]\tLoss: 0.000895\n","Train Epoch: 6 [52480/155326 (34%)]\tLoss: 0.001551\n","Train Epoch: 6 [53120/155326 (34%)]\tLoss: 0.000654\n","Train Epoch: 6 [53760/155326 (35%)]\tLoss: 0.000521\n","Train Epoch: 6 [54400/155326 (35%)]\tLoss: 0.001179\n","Train Epoch: 6 [55040/155326 (35%)]\tLoss: 0.000614\n","Train Epoch: 6 [55680/155326 (36%)]\tLoss: 0.001847\n","Train Epoch: 6 [56320/155326 (36%)]\tLoss: 0.001355\n","Train Epoch: 6 [56960/155326 (37%)]\tLoss: 0.000341\n","Train Epoch: 6 [57600/155326 (37%)]\tLoss: 0.000564\n","Train Epoch: 6 [58240/155326 (37%)]\tLoss: 0.002056\n","Train Epoch: 6 [58880/155326 (38%)]\tLoss: 0.001940\n","Train Epoch: 6 [59520/155326 (38%)]\tLoss: 0.000877\n","Train Epoch: 6 [60160/155326 (39%)]\tLoss: 0.001413\n","Train Epoch: 6 [60800/155326 (39%)]\tLoss: 0.000905\n","Train Epoch: 6 [61440/155326 (40%)]\tLoss: 0.000540\n","Train Epoch: 6 [62080/155326 (40%)]\tLoss: 0.000780\n","Train Epoch: 6 [62720/155326 (40%)]\tLoss: 0.000295\n","Train Epoch: 6 [63360/155326 (41%)]\tLoss: 0.000723\n","Train Epoch: 6 [64000/155326 (41%)]\tLoss: 0.003145\n","Train Epoch: 6 [64640/155326 (42%)]\tLoss: 0.000790\n","Train Epoch: 6 [65280/155326 (42%)]\tLoss: 0.000272\n","Train Epoch: 6 [65920/155326 (42%)]\tLoss: 0.001636\n","Train Epoch: 6 [66560/155326 (43%)]\tLoss: 0.001275\n","Train Epoch: 6 [67200/155326 (43%)]\tLoss: 0.000850\n","Train Epoch: 6 [67840/155326 (44%)]\tLoss: 0.002609\n","Train Epoch: 6 [68480/155326 (44%)]\tLoss: 0.001856\n","Train Epoch: 6 [69120/155326 (44%)]\tLoss: 0.001469\n","Train Epoch: 6 [69760/155326 (45%)]\tLoss: 0.001033\n","Train Epoch: 6 [70400/155326 (45%)]\tLoss: 0.000332\n","Train Epoch: 6 [71040/155326 (46%)]\tLoss: 0.000419\n","Train Epoch: 6 [71680/155326 (46%)]\tLoss: 0.000819\n","Train Epoch: 6 [72320/155326 (47%)]\tLoss: 0.000422\n","Train Epoch: 6 [72960/155326 (47%)]\tLoss: 0.000830\n","Train Epoch: 6 [73600/155326 (47%)]\tLoss: 0.001689\n","Train Epoch: 6 [74240/155326 (48%)]\tLoss: 0.000326\n","Train Epoch: 6 [74880/155326 (48%)]\tLoss: 0.000483\n","Train Epoch: 6 [75520/155326 (49%)]\tLoss: 0.000903\n","Train Epoch: 6 [76160/155326 (49%)]\tLoss: 0.000706\n","Train Epoch: 6 [76800/155326 (49%)]\tLoss: 0.003026\n","Train Epoch: 6 [77440/155326 (50%)]\tLoss: 0.002229\n","Train Epoch: 6 [78080/155326 (50%)]\tLoss: 0.001423\n","Train Epoch: 6 [78720/155326 (51%)]\tLoss: 0.001463\n","Train Epoch: 6 [79360/155326 (51%)]\tLoss: 0.000266\n","Train Epoch: 6 [80000/155326 (52%)]\tLoss: 0.000442\n","Train Epoch: 6 [80640/155326 (52%)]\tLoss: 0.000348\n","Train Epoch: 6 [81280/155326 (52%)]\tLoss: 0.001815\n","Train Epoch: 6 [81920/155326 (53%)]\tLoss: 0.001615\n","Train Epoch: 6 [82560/155326 (53%)]\tLoss: 0.001525\n","Train Epoch: 6 [83200/155326 (54%)]\tLoss: 0.001122\n","Train Epoch: 6 [83840/155326 (54%)]\tLoss: 0.000608\n","Train Epoch: 6 [84480/155326 (54%)]\tLoss: 0.001305\n","Train Epoch: 6 [85120/155326 (55%)]\tLoss: 0.000932\n","Train Epoch: 6 [85760/155326 (55%)]\tLoss: 0.001147\n","Train Epoch: 6 [86400/155326 (56%)]\tLoss: 0.001128\n","Train Epoch: 6 [87040/155326 (56%)]\tLoss: 0.000954\n","Train Epoch: 6 [87680/155326 (56%)]\tLoss: 0.001102\n","Train Epoch: 6 [88320/155326 (57%)]\tLoss: 0.002002\n","Train Epoch: 6 [88960/155326 (57%)]\tLoss: 0.001535\n","Train Epoch: 6 [89600/155326 (58%)]\tLoss: 0.000673\n","Train Epoch: 6 [90240/155326 (58%)]\tLoss: 0.000593\n","Train Epoch: 6 [90880/155326 (59%)]\tLoss: 0.001408\n","Train Epoch: 6 [91520/155326 (59%)]\tLoss: 0.001499\n","Train Epoch: 6 [92160/155326 (59%)]\tLoss: 0.000298\n","Train Epoch: 6 [92800/155326 (60%)]\tLoss: 0.000508\n","Train Epoch: 6 [93440/155326 (60%)]\tLoss: 0.001459\n","Train Epoch: 6 [94080/155326 (61%)]\tLoss: 0.000558\n","Train Epoch: 6 [94720/155326 (61%)]\tLoss: 0.000363\n","Train Epoch: 6 [95360/155326 (61%)]\tLoss: 0.000883\n","Train Epoch: 6 [96000/155326 (62%)]\tLoss: 0.001696\n","Train Epoch: 6 [96640/155326 (62%)]\tLoss: 0.000681\n","Train Epoch: 6 [97280/155326 (63%)]\tLoss: 0.001480\n","Train Epoch: 6 [97920/155326 (63%)]\tLoss: 0.000810\n","Train Epoch: 6 [98560/155326 (63%)]\tLoss: 0.000469\n","Train Epoch: 6 [99200/155326 (64%)]\tLoss: 0.001152\n","Train Epoch: 6 [99840/155326 (64%)]\tLoss: 0.000387\n","Train Epoch: 6 [100480/155326 (65%)]\tLoss: 0.000436\n","Train Epoch: 6 [101120/155326 (65%)]\tLoss: 0.002807\n","Train Epoch: 6 [101760/155326 (66%)]\tLoss: 0.000823\n","Train Epoch: 6 [102400/155326 (66%)]\tLoss: 0.001596\n","Train Epoch: 6 [103040/155326 (66%)]\tLoss: 0.000163\n","Train Epoch: 6 [103680/155326 (67%)]\tLoss: 0.001452\n","Train Epoch: 6 [104320/155326 (67%)]\tLoss: 0.000519\n","Train Epoch: 6 [104960/155326 (68%)]\tLoss: 0.000582\n","Train Epoch: 6 [105600/155326 (68%)]\tLoss: 0.001445\n","Train Epoch: 6 [106240/155326 (68%)]\tLoss: 0.002251\n","Train Epoch: 6 [106880/155326 (69%)]\tLoss: 0.001351\n","Train Epoch: 6 [107520/155326 (69%)]\tLoss: 0.000577\n","Train Epoch: 6 [108160/155326 (70%)]\tLoss: 0.000759\n","Train Epoch: 6 [108800/155326 (70%)]\tLoss: 0.000642\n","Train Epoch: 6 [109440/155326 (70%)]\tLoss: 0.000752\n","Train Epoch: 6 [110080/155326 (71%)]\tLoss: 0.001114\n","Train Epoch: 6 [110720/155326 (71%)]\tLoss: 0.000631\n","Train Epoch: 6 [111360/155326 (72%)]\tLoss: 0.001674\n","Train Epoch: 6 [112000/155326 (72%)]\tLoss: 0.000618\n","Train Epoch: 6 [112640/155326 (73%)]\tLoss: 0.000894\n","Train Epoch: 6 [113280/155326 (73%)]\tLoss: 0.003214\n","Train Epoch: 6 [113920/155326 (73%)]\tLoss: 0.000477\n","Train Epoch: 6 [114560/155326 (74%)]\tLoss: 0.001535\n","Train Epoch: 6 [115200/155326 (74%)]\tLoss: 0.002109\n","Train Epoch: 6 [115840/155326 (75%)]\tLoss: 0.000677\n","Train Epoch: 6 [116480/155326 (75%)]\tLoss: 0.000408\n","Train Epoch: 6 [117120/155326 (75%)]\tLoss: 0.000230\n","Train Epoch: 6 [117760/155326 (76%)]\tLoss: 0.000776\n","Train Epoch: 6 [118400/155326 (76%)]\tLoss: 0.000583\n","Train Epoch: 6 [119040/155326 (77%)]\tLoss: 0.000654\n","Train Epoch: 6 [119680/155326 (77%)]\tLoss: 0.000708\n","Train Epoch: 6 [120320/155326 (77%)]\tLoss: 0.001411\n","Train Epoch: 6 [120960/155326 (78%)]\tLoss: 0.000406\n","Train Epoch: 6 [121600/155326 (78%)]\tLoss: 0.001119\n","Train Epoch: 6 [122240/155326 (79%)]\tLoss: 0.000501\n","Train Epoch: 6 [122880/155326 (79%)]\tLoss: 0.000441\n","Train Epoch: 6 [123520/155326 (80%)]\tLoss: 0.002440\n","Train Epoch: 6 [124160/155326 (80%)]\tLoss: 0.001496\n","Train Epoch: 6 [124800/155326 (80%)]\tLoss: 0.001177\n","Train Epoch: 6 [125440/155326 (81%)]\tLoss: 0.000587\n","Train Epoch: 6 [126080/155326 (81%)]\tLoss: 0.000956\n","Train Epoch: 6 [126720/155326 (82%)]\tLoss: 0.000767\n","Train Epoch: 6 [127360/155326 (82%)]\tLoss: 0.002994\n","Train Epoch: 6 [128000/155326 (82%)]\tLoss: 0.000471\n","Train Epoch: 6 [128640/155326 (83%)]\tLoss: 0.000301\n","Train Epoch: 6 [129280/155326 (83%)]\tLoss: 0.000464\n","Train Epoch: 6 [129920/155326 (84%)]\tLoss: 0.000626\n","Train Epoch: 6 [130560/155326 (84%)]\tLoss: 0.000642\n","Train Epoch: 6 [131200/155326 (84%)]\tLoss: 0.000682\n","Train Epoch: 6 [131840/155326 (85%)]\tLoss: 0.001717\n","Train Epoch: 6 [132480/155326 (85%)]\tLoss: 0.001593\n","Train Epoch: 6 [133120/155326 (86%)]\tLoss: 0.002036\n","Train Epoch: 6 [133760/155326 (86%)]\tLoss: 0.000851\n","Train Epoch: 6 [134400/155326 (87%)]\tLoss: 0.002317\n","Train Epoch: 6 [135040/155326 (87%)]\tLoss: 0.000909\n","Train Epoch: 6 [135680/155326 (87%)]\tLoss: 0.000659\n","Train Epoch: 6 [136320/155326 (88%)]\tLoss: 0.000365\n","Train Epoch: 6 [136960/155326 (88%)]\tLoss: 0.000295\n","Train Epoch: 6 [137600/155326 (89%)]\tLoss: 0.000228\n","Train Epoch: 6 [138240/155326 (89%)]\tLoss: 0.000598\n","Train Epoch: 6 [138880/155326 (89%)]\tLoss: 0.001621\n","Train Epoch: 6 [139520/155326 (90%)]\tLoss: 0.001768\n","Train Epoch: 6 [140160/155326 (90%)]\tLoss: 0.001524\n","Train Epoch: 6 [140800/155326 (91%)]\tLoss: 0.000867\n","Train Epoch: 6 [141440/155326 (91%)]\tLoss: 0.000380\n","Train Epoch: 6 [142080/155326 (91%)]\tLoss: 0.001016\n","Train Epoch: 6 [142720/155326 (92%)]\tLoss: 0.000561\n","Train Epoch: 6 [143360/155326 (92%)]\tLoss: 0.000564\n","Train Epoch: 6 [144000/155326 (93%)]\tLoss: 0.000880\n","Train Epoch: 6 [144640/155326 (93%)]\tLoss: 0.001643\n","Train Epoch: 6 [145280/155326 (94%)]\tLoss: 0.000797\n","Train Epoch: 6 [145920/155326 (94%)]\tLoss: 0.000726\n","Train Epoch: 6 [146560/155326 (94%)]\tLoss: 0.001871\n","Train Epoch: 6 [147200/155326 (95%)]\tLoss: 0.002072\n","Train Epoch: 6 [147840/155326 (95%)]\tLoss: 0.000536\n","Train Epoch: 6 [148480/155326 (96%)]\tLoss: 0.000441\n","Train Epoch: 6 [149120/155326 (96%)]\tLoss: 0.000370\n","Train Epoch: 6 [149760/155326 (96%)]\tLoss: 0.000956\n","Train Epoch: 6 [150400/155326 (97%)]\tLoss: 0.000240\n","Train Epoch: 6 [151040/155326 (97%)]\tLoss: 0.000984\n","Train Epoch: 6 [151680/155326 (98%)]\tLoss: 0.001177\n","Train Epoch: 6 [152320/155326 (98%)]\tLoss: 0.001241\n","Train Epoch: 6 [152960/155326 (98%)]\tLoss: 0.001477\n","Train Epoch: 6 [153600/155326 (99%)]\tLoss: 0.001556\n","Train Epoch: 6 [154240/155326 (99%)]\tLoss: 0.001214\n","Train Epoch: 6 [154880/155326 (100%)]\tLoss: 0.000531\n","Sample outputs (log probs): tensor([[-2.0920e+01, -1.6639e+01, -1.1805e+01, -1.2450e+01, -1.9622e+01,\n","         -2.0266e+01, -1.2272e+01, -1.4535e+01, -1.4684e+01, -8.1266e+00,\n","         -1.7859e+01, -1.2815e+01, -1.4639e+01, -1.6127e+01, -1.2797e+01,\n","         -1.8481e+01, -1.2750e+01, -2.3835e+01, -1.6696e+01, -1.6572e+01,\n","         -1.3419e-02, -4.5465e+00, -6.0319e+00, -1.8467e+01, -1.3271e+01,\n","         -1.9003e+01],\n","        [-1.1181e+01, -9.3035e-04, -1.2718e+01, -1.1476e+01, -7.1965e+00,\n","         -1.4944e+01, -1.0558e+01, -1.7120e+01, -1.9686e+01, -2.1064e+01,\n","         -1.9422e+01, -2.2378e+01, -1.7355e+01, -2.2128e+01, -9.6792e+00,\n","         -1.3255e+01, -1.3502e+01, -9.7699e+00, -1.3487e+01, -2.1685e+01,\n","         -1.9716e+01, -2.3059e+01, -2.0492e+01, -2.2983e+01, -2.2811e+01,\n","         -1.2806e+01],\n","        [-1.0671e+01, -1.7031e+01, -1.1402e+01, -1.2284e+01, -1.4973e+01,\n","         -2.9011e+00, -1.6046e+01, -1.2569e+01, -4.0060e+00, -1.3136e+01,\n","         -1.6397e+01, -1.1128e+01, -1.9172e+01, -1.1449e+01, -1.2598e+01,\n","         -8.0535e-02, -1.4867e+01, -1.2460e+01, -1.5494e+01, -7.5591e+00,\n","         -1.6591e+01, -8.4814e+00, -1.7628e+01, -1.4152e+01, -5.6840e+00,\n","         -1.3745e+01],\n","        [-1.4180e+01, -1.1157e+01, -7.1039e+00, -6.4878e+00, -1.6645e+01,\n","         -1.5443e+01, -1.0995e+01, -1.8312e+01, -1.3588e+01, -1.0270e+01,\n","         -2.2822e+01, -1.9392e+01, -1.5262e+01, -1.6713e+01, -6.8330e-03,\n","         -1.2410e+01, -5.4337e+00, -1.9639e+01, -1.2293e+01, -1.3471e+01,\n","         -1.0848e+01, -1.4612e+01, -1.8663e+01, -2.5259e+01, -1.4259e+01,\n","         -1.7302e+01],\n","        [-2.1883e+01, -1.1916e+01, -1.2548e+01, -1.7457e+01, -1.0785e+01,\n","         -1.0737e+01, -9.4356e+00, -2.2755e+01, -1.4125e+01, -6.0997e+00,\n","         -2.1082e+01, -2.2236e+01, -2.6029e+01, -2.6711e+01, -1.1874e+01,\n","         -2.0493e+01, -1.2085e+01, -2.8416e+01, -2.3931e-03, -1.7681e+01,\n","         -1.7315e+01, -2.2791e+01, -2.7364e+01, -2.4263e+01, -1.4277e+01,\n","         -1.8970e+01]], device='cuda:0')\n","Predicted classes: tensor([20,  1, 15, 14, 18], device='cuda:0')\n","Target classes: tensor([20,  1, 15, 14, 18], device='cuda:0')\n","\n","Test set: Average loss: 0.001868, Total sum loss: 0.567998, Accuracy: 37739/38832 (97%)\n","\n","Class A: 1306/1336 (98%)\n","Class B: 805/819 (98%)\n","Class C: 2008/2059 (98%)\n","Class D: 865/922 (94%)\n","Class E: 982/996 (99%)\n","Class F: 1808/1861 (97%)\n","Class G: 535/551 (97%)\n","Class H: 679/709 (96%)\n","Class I: 2379/2438 (98%)\n","Class J: 753/772 (98%)\n","Class K: 540/566 (95%)\n","Class L: 965/986 (98%)\n","Class M: 1808/1851 (98%)\n","Class N: 1585/1636 (97%)\n","Class O: 4912/5060 (97%)\n","Class P: 1721/1781 (97%)\n","Class Q: 570/589 (97%)\n","Class R: 1018/1056 (96%)\n","Class S: 4160/4209 (99%)\n","Class T: 1926/1960 (98%)\n","Class U: 2445/2562 (95%)\n","Class V: 950/988 (96%)\n","Class W: 959/990 (97%)\n","Class X: 583/601 (97%)\n","Class Y: 968/1022 (95%)\n","Class Z: 509/512 (99%)\n","Model saved with new best test loss: 0.0019 \n","\n","Train Epoch: 7 [0/155326 (0%)]\tLoss: 0.000516\n","Train Epoch: 7 [640/155326 (0%)]\tLoss: 0.000729\n","Train Epoch: 7 [1280/155326 (1%)]\tLoss: 0.000370\n","Train Epoch: 7 [1920/155326 (1%)]\tLoss: 0.000928\n","Train Epoch: 7 [2560/155326 (2%)]\tLoss: 0.001717\n","Train Epoch: 7 [3200/155326 (2%)]\tLoss: 0.000164\n","Train Epoch: 7 [3840/155326 (2%)]\tLoss: 0.001464\n","Train Epoch: 7 [4480/155326 (3%)]\tLoss: 0.000691\n","Train Epoch: 7 [5120/155326 (3%)]\tLoss: 0.001318\n","Train Epoch: 7 [5760/155326 (4%)]\tLoss: 0.003753\n","Train Epoch: 7 [6400/155326 (4%)]\tLoss: 0.000441\n","Train Epoch: 7 [7040/155326 (5%)]\tLoss: 0.000872\n","Train Epoch: 7 [7680/155326 (5%)]\tLoss: 0.001052\n","Train Epoch: 7 [8320/155326 (5%)]\tLoss: 0.001149\n","Train Epoch: 7 [8960/155326 (6%)]\tLoss: 0.000670\n","Train Epoch: 7 [9600/155326 (6%)]\tLoss: 0.001140\n","Train Epoch: 7 [10240/155326 (7%)]\tLoss: 0.000750\n","Train Epoch: 7 [10880/155326 (7%)]\tLoss: 0.000278\n","Train Epoch: 7 [11520/155326 (7%)]\tLoss: 0.001564\n","Train Epoch: 7 [12160/155326 (8%)]\tLoss: 0.000691\n","Train Epoch: 7 [12800/155326 (8%)]\tLoss: 0.000480\n","Train Epoch: 7 [13440/155326 (9%)]\tLoss: 0.002820\n","Train Epoch: 7 [14080/155326 (9%)]\tLoss: 0.000685\n","Train Epoch: 7 [14720/155326 (9%)]\tLoss: 0.001810\n","Train Epoch: 7 [15360/155326 (10%)]\tLoss: 0.001148\n","Train Epoch: 7 [16000/155326 (10%)]\tLoss: 0.000884\n","Train Epoch: 7 [16640/155326 (11%)]\tLoss: 0.000597\n","Train Epoch: 7 [17280/155326 (11%)]\tLoss: 0.001022\n","Train Epoch: 7 [17920/155326 (12%)]\tLoss: 0.000460\n","Train Epoch: 7 [18560/155326 (12%)]\tLoss: 0.000615\n","Train Epoch: 7 [19200/155326 (12%)]\tLoss: 0.000588\n","Train Epoch: 7 [19840/155326 (13%)]\tLoss: 0.001102\n","Train Epoch: 7 [20480/155326 (13%)]\tLoss: 0.001691\n","Train Epoch: 7 [21120/155326 (14%)]\tLoss: 0.000173\n","Train Epoch: 7 [21760/155326 (14%)]\tLoss: 0.001552\n","Train Epoch: 7 [22400/155326 (14%)]\tLoss: 0.007318\n","Train Epoch: 7 [23040/155326 (15%)]\tLoss: 0.000705\n","Train Epoch: 7 [23680/155326 (15%)]\tLoss: 0.000867\n","Train Epoch: 7 [24320/155326 (16%)]\tLoss: 0.000953\n","Train Epoch: 7 [24960/155326 (16%)]\tLoss: 0.002244\n","Train Epoch: 7 [25600/155326 (16%)]\tLoss: 0.000670\n","Train Epoch: 7 [26240/155326 (17%)]\tLoss: 0.000873\n","Train Epoch: 7 [26880/155326 (17%)]\tLoss: 0.001419\n","Train Epoch: 7 [27520/155326 (18%)]\tLoss: 0.000562\n","Train Epoch: 7 [28160/155326 (18%)]\tLoss: 0.000416\n","Train Epoch: 7 [28800/155326 (19%)]\tLoss: 0.002839\n","Train Epoch: 7 [29440/155326 (19%)]\tLoss: 0.001034\n","Train Epoch: 7 [30080/155326 (19%)]\tLoss: 0.000686\n","Train Epoch: 7 [30720/155326 (20%)]\tLoss: 0.000278\n","Train Epoch: 7 [31360/155326 (20%)]\tLoss: 0.000487\n","Train Epoch: 7 [32000/155326 (21%)]\tLoss: 0.002011\n","Train Epoch: 7 [32640/155326 (21%)]\tLoss: 0.000240\n","Train Epoch: 7 [33280/155326 (21%)]\tLoss: 0.000523\n","Train Epoch: 7 [33920/155326 (22%)]\tLoss: 0.001891\n","Train Epoch: 7 [34560/155326 (22%)]\tLoss: 0.000925\n","Train Epoch: 7 [35200/155326 (23%)]\tLoss: 0.000449\n","Train Epoch: 7 [35840/155326 (23%)]\tLoss: 0.000600\n","Train Epoch: 7 [36480/155326 (23%)]\tLoss: 0.000342\n","Train Epoch: 7 [37120/155326 (24%)]\tLoss: 0.001345\n","Train Epoch: 7 [37760/155326 (24%)]\tLoss: 0.001228\n","Train Epoch: 7 [38400/155326 (25%)]\tLoss: 0.000972\n","Train Epoch: 7 [39040/155326 (25%)]\tLoss: 0.000364\n","Train Epoch: 7 [39680/155326 (26%)]\tLoss: 0.000277\n","Train Epoch: 7 [40320/155326 (26%)]\tLoss: 0.000700\n","Train Epoch: 7 [40960/155326 (26%)]\tLoss: 0.002806\n","Train Epoch: 7 [41600/155326 (27%)]\tLoss: 0.000498\n","Train Epoch: 7 [42240/155326 (27%)]\tLoss: 0.000362\n","Train Epoch: 7 [42880/155326 (28%)]\tLoss: 0.000347\n","Train Epoch: 7 [43520/155326 (28%)]\tLoss: 0.001341\n","Train Epoch: 7 [44160/155326 (28%)]\tLoss: 0.000537\n","Train Epoch: 7 [44800/155326 (29%)]\tLoss: 0.000464\n","Train Epoch: 7 [45440/155326 (29%)]\tLoss: 0.001028\n","Train Epoch: 7 [46080/155326 (30%)]\tLoss: 0.000308\n","Train Epoch: 7 [46720/155326 (30%)]\tLoss: 0.001351\n","Train Epoch: 7 [47360/155326 (30%)]\tLoss: 0.002081\n","Train Epoch: 7 [48000/155326 (31%)]\tLoss: 0.001006\n","Train Epoch: 7 [48640/155326 (31%)]\tLoss: 0.000629\n","Train Epoch: 7 [49280/155326 (32%)]\tLoss: 0.001066\n","Train Epoch: 7 [49920/155326 (32%)]\tLoss: 0.001776\n","Train Epoch: 7 [50560/155326 (33%)]\tLoss: 0.000486\n","Train Epoch: 7 [51200/155326 (33%)]\tLoss: 0.001287\n","Train Epoch: 7 [51840/155326 (33%)]\tLoss: 0.000392\n","Train Epoch: 7 [52480/155326 (34%)]\tLoss: 0.001199\n","Train Epoch: 7 [53120/155326 (34%)]\tLoss: 0.000723\n","Train Epoch: 7 [53760/155326 (35%)]\tLoss: 0.000954\n","Train Epoch: 7 [54400/155326 (35%)]\tLoss: 0.002184\n","Train Epoch: 7 [55040/155326 (35%)]\tLoss: 0.000348\n","Train Epoch: 7 [55680/155326 (36%)]\tLoss: 0.000575\n","Train Epoch: 7 [56320/155326 (36%)]\tLoss: 0.000537\n","Train Epoch: 7 [56960/155326 (37%)]\tLoss: 0.000176\n","Train Epoch: 7 [57600/155326 (37%)]\tLoss: 0.000692\n","Train Epoch: 7 [58240/155326 (37%)]\tLoss: 0.001282\n","Train Epoch: 7 [58880/155326 (38%)]\tLoss: 0.001180\n","Train Epoch: 7 [59520/155326 (38%)]\tLoss: 0.000828\n","Train Epoch: 7 [60160/155326 (39%)]\tLoss: 0.000789\n","Train Epoch: 7 [60800/155326 (39%)]\tLoss: 0.001618\n","Train Epoch: 7 [61440/155326 (40%)]\tLoss: 0.001874\n","Train Epoch: 7 [62080/155326 (40%)]\tLoss: 0.000613\n","Train Epoch: 7 [62720/155326 (40%)]\tLoss: 0.003643\n","Train Epoch: 7 [63360/155326 (41%)]\tLoss: 0.001820\n","Train Epoch: 7 [64000/155326 (41%)]\tLoss: 0.000304\n","Train Epoch: 7 [64640/155326 (42%)]\tLoss: 0.000887\n","Train Epoch: 7 [65280/155326 (42%)]\tLoss: 0.001392\n","Train Epoch: 7 [65920/155326 (42%)]\tLoss: 0.000511\n","Train Epoch: 7 [66560/155326 (43%)]\tLoss: 0.000421\n","Train Epoch: 7 [67200/155326 (43%)]\tLoss: 0.000861\n","Train Epoch: 7 [67840/155326 (44%)]\tLoss: 0.000471\n","Train Epoch: 7 [68480/155326 (44%)]\tLoss: 0.001351\n","Train Epoch: 7 [69120/155326 (44%)]\tLoss: 0.000841\n","Train Epoch: 7 [69760/155326 (45%)]\tLoss: 0.000950\n","Train Epoch: 7 [70400/155326 (45%)]\tLoss: 0.001256\n","Train Epoch: 7 [71040/155326 (46%)]\tLoss: 0.000345\n","Train Epoch: 7 [71680/155326 (46%)]\tLoss: 0.000361\n","Train Epoch: 7 [72320/155326 (47%)]\tLoss: 0.000716\n","Train Epoch: 7 [72960/155326 (47%)]\tLoss: 0.000694\n","Train Epoch: 7 [73600/155326 (47%)]\tLoss: 0.000293\n","Train Epoch: 7 [74240/155326 (48%)]\tLoss: 0.000495\n","Train Epoch: 7 [74880/155326 (48%)]\tLoss: 0.002382\n","Train Epoch: 7 [75520/155326 (49%)]\tLoss: 0.001282\n","Train Epoch: 7 [76160/155326 (49%)]\tLoss: 0.002637\n","Train Epoch: 7 [76800/155326 (49%)]\tLoss: 0.000797\n","Train Epoch: 7 [77440/155326 (50%)]\tLoss: 0.000650\n","Train Epoch: 7 [78080/155326 (50%)]\tLoss: 0.000888\n","Train Epoch: 7 [78720/155326 (51%)]\tLoss: 0.001902\n","Train Epoch: 7 [79360/155326 (51%)]\tLoss: 0.001438\n","Train Epoch: 7 [80000/155326 (52%)]\tLoss: 0.000553\n","Train Epoch: 7 [80640/155326 (52%)]\tLoss: 0.000453\n","Train Epoch: 7 [81280/155326 (52%)]\tLoss: 0.001298\n","Train Epoch: 7 [81920/155326 (53%)]\tLoss: 0.000455\n","Train Epoch: 7 [82560/155326 (53%)]\tLoss: 0.000665\n","Train Epoch: 7 [83200/155326 (54%)]\tLoss: 0.001482\n","Train Epoch: 7 [83840/155326 (54%)]\tLoss: 0.001007\n","Train Epoch: 7 [84480/155326 (54%)]\tLoss: 0.000826\n","Train Epoch: 7 [85120/155326 (55%)]\tLoss: 0.000826\n","Train Epoch: 7 [85760/155326 (55%)]\tLoss: 0.001485\n","Train Epoch: 7 [86400/155326 (56%)]\tLoss: 0.000177\n","Train Epoch: 7 [87040/155326 (56%)]\tLoss: 0.001349\n","Train Epoch: 7 [87680/155326 (56%)]\tLoss: 0.000646\n","Train Epoch: 7 [88320/155326 (57%)]\tLoss: 0.000744\n","Train Epoch: 7 [88960/155326 (57%)]\tLoss: 0.001267\n","Train Epoch: 7 [89600/155326 (58%)]\tLoss: 0.001528\n","Train Epoch: 7 [90240/155326 (58%)]\tLoss: 0.001015\n","Train Epoch: 7 [90880/155326 (59%)]\tLoss: 0.000197\n","Train Epoch: 7 [91520/155326 (59%)]\tLoss: 0.000682\n","Train Epoch: 7 [92160/155326 (59%)]\tLoss: 0.001385\n","Train Epoch: 7 [92800/155326 (60%)]\tLoss: 0.002057\n","Train Epoch: 7 [93440/155326 (60%)]\tLoss: 0.000649\n","Train Epoch: 7 [94080/155326 (61%)]\tLoss: 0.000883\n","Train Epoch: 7 [94720/155326 (61%)]\tLoss: 0.003070\n","Train Epoch: 7 [95360/155326 (61%)]\tLoss: 0.000590\n","Train Epoch: 7 [96000/155326 (62%)]\tLoss: 0.000479\n","Train Epoch: 7 [96640/155326 (62%)]\tLoss: 0.001704\n","Train Epoch: 7 [97280/155326 (63%)]\tLoss: 0.000875\n","Train Epoch: 7 [97920/155326 (63%)]\tLoss: 0.000671\n","Train Epoch: 7 [98560/155326 (63%)]\tLoss: 0.000491\n","Train Epoch: 7 [99200/155326 (64%)]\tLoss: 0.000685\n","Train Epoch: 7 [99840/155326 (64%)]\tLoss: 0.002008\n","Train Epoch: 7 [100480/155326 (65%)]\tLoss: 0.000519\n","Train Epoch: 7 [101120/155326 (65%)]\tLoss: 0.000538\n","Train Epoch: 7 [101760/155326 (66%)]\tLoss: 0.000628\n","Train Epoch: 7 [102400/155326 (66%)]\tLoss: 0.000931\n","Train Epoch: 7 [103040/155326 (66%)]\tLoss: 0.000685\n","Train Epoch: 7 [103680/155326 (67%)]\tLoss: 0.001069\n","Train Epoch: 7 [104320/155326 (67%)]\tLoss: 0.000823\n","Train Epoch: 7 [104960/155326 (68%)]\tLoss: 0.001652\n","Train Epoch: 7 [105600/155326 (68%)]\tLoss: 0.000504\n","Train Epoch: 7 [106240/155326 (68%)]\tLoss: 0.000664\n","Train Epoch: 7 [106880/155326 (69%)]\tLoss: 0.001920\n","Train Epoch: 7 [107520/155326 (69%)]\tLoss: 0.000543\n","Train Epoch: 7 [108160/155326 (70%)]\tLoss: 0.000329\n","Train Epoch: 7 [108800/155326 (70%)]\tLoss: 0.003977\n","Train Epoch: 7 [109440/155326 (70%)]\tLoss: 0.000646\n","Train Epoch: 7 [110080/155326 (71%)]\tLoss: 0.000456\n","Train Epoch: 7 [110720/155326 (71%)]\tLoss: 0.000645\n","Train Epoch: 7 [111360/155326 (72%)]\tLoss: 0.000304\n","Train Epoch: 7 [112000/155326 (72%)]\tLoss: 0.000290\n","Train Epoch: 7 [112640/155326 (73%)]\tLoss: 0.000284\n","Train Epoch: 7 [113280/155326 (73%)]\tLoss: 0.001255\n","Train Epoch: 7 [113920/155326 (73%)]\tLoss: 0.002291\n","Train Epoch: 7 [114560/155326 (74%)]\tLoss: 0.001429\n","Train Epoch: 7 [115200/155326 (74%)]\tLoss: 0.001435\n","Train Epoch: 7 [115840/155326 (75%)]\tLoss: 0.000670\n","Train Epoch: 7 [116480/155326 (75%)]\tLoss: 0.000790\n","Train Epoch: 7 [117120/155326 (75%)]\tLoss: 0.001422\n","Train Epoch: 7 [117760/155326 (76%)]\tLoss: 0.000843\n","Train Epoch: 7 [118400/155326 (76%)]\tLoss: 0.000594\n","Train Epoch: 7 [119040/155326 (77%)]\tLoss: 0.000382\n","Train Epoch: 7 [119680/155326 (77%)]\tLoss: 0.000257\n","Train Epoch: 7 [120320/155326 (77%)]\tLoss: 0.000784\n","Train Epoch: 7 [120960/155326 (78%)]\tLoss: 0.003250\n","Train Epoch: 7 [121600/155326 (78%)]\tLoss: 0.000266\n","Train Epoch: 7 [122240/155326 (79%)]\tLoss: 0.002621\n","Train Epoch: 7 [122880/155326 (79%)]\tLoss: 0.000323\n","Train Epoch: 7 [123520/155326 (80%)]\tLoss: 0.004954\n","Train Epoch: 7 [124160/155326 (80%)]\tLoss: 0.000454\n","Train Epoch: 7 [124800/155326 (80%)]\tLoss: 0.000903\n","Train Epoch: 7 [125440/155326 (81%)]\tLoss: 0.002187\n","Train Epoch: 7 [126080/155326 (81%)]\tLoss: 0.001667\n","Train Epoch: 7 [126720/155326 (82%)]\tLoss: 0.001750\n","Train Epoch: 7 [127360/155326 (82%)]\tLoss: 0.000582\n","Train Epoch: 7 [128000/155326 (82%)]\tLoss: 0.000829\n","Train Epoch: 7 [128640/155326 (83%)]\tLoss: 0.000468\n","Train Epoch: 7 [129280/155326 (83%)]\tLoss: 0.000729\n","Train Epoch: 7 [129920/155326 (84%)]\tLoss: 0.000219\n","Train Epoch: 7 [130560/155326 (84%)]\tLoss: 0.000733\n","Train Epoch: 7 [131200/155326 (84%)]\tLoss: 0.003083\n","Train Epoch: 7 [131840/155326 (85%)]\tLoss: 0.003629\n","Train Epoch: 7 [132480/155326 (85%)]\tLoss: 0.000342\n","Train Epoch: 7 [133120/155326 (86%)]\tLoss: 0.001837\n","Train Epoch: 7 [133760/155326 (86%)]\tLoss: 0.001046\n","Train Epoch: 7 [134400/155326 (87%)]\tLoss: 0.000696\n","Train Epoch: 7 [135040/155326 (87%)]\tLoss: 0.002694\n","Train Epoch: 7 [135680/155326 (87%)]\tLoss: 0.000696\n","Train Epoch: 7 [136320/155326 (88%)]\tLoss: 0.000207\n","Train Epoch: 7 [136960/155326 (88%)]\tLoss: 0.001339\n","Train Epoch: 7 [137600/155326 (89%)]\tLoss: 0.001521\n","Train Epoch: 7 [138240/155326 (89%)]\tLoss: 0.000487\n","Train Epoch: 7 [138880/155326 (89%)]\tLoss: 0.000531\n","Train Epoch: 7 [139520/155326 (90%)]\tLoss: 0.002103\n","Train Epoch: 7 [140160/155326 (90%)]\tLoss: 0.001875\n","Train Epoch: 7 [140800/155326 (91%)]\tLoss: 0.000730\n","Train Epoch: 7 [141440/155326 (91%)]\tLoss: 0.001449\n","Train Epoch: 7 [142080/155326 (91%)]\tLoss: 0.000515\n","Train Epoch: 7 [142720/155326 (92%)]\tLoss: 0.000717\n","Train Epoch: 7 [143360/155326 (92%)]\tLoss: 0.000396\n","Train Epoch: 7 [144000/155326 (93%)]\tLoss: 0.000496\n","Train Epoch: 7 [144640/155326 (93%)]\tLoss: 0.000402\n","Train Epoch: 7 [145280/155326 (94%)]\tLoss: 0.000717\n","Train Epoch: 7 [145920/155326 (94%)]\tLoss: 0.000112\n","Train Epoch: 7 [146560/155326 (94%)]\tLoss: 0.002809\n","Train Epoch: 7 [147200/155326 (95%)]\tLoss: 0.000855\n","Train Epoch: 7 [147840/155326 (95%)]\tLoss: 0.001476\n","Train Epoch: 7 [148480/155326 (96%)]\tLoss: 0.000570\n","Train Epoch: 7 [149120/155326 (96%)]\tLoss: 0.002418\n","Train Epoch: 7 [149760/155326 (96%)]\tLoss: 0.000797\n","Train Epoch: 7 [150400/155326 (97%)]\tLoss: 0.000358\n","Train Epoch: 7 [151040/155326 (97%)]\tLoss: 0.000636\n","Train Epoch: 7 [151680/155326 (98%)]\tLoss: 0.000799\n","Train Epoch: 7 [152320/155326 (98%)]\tLoss: 0.001375\n","Train Epoch: 7 [152960/155326 (98%)]\tLoss: 0.000627\n","Train Epoch: 7 [153600/155326 (99%)]\tLoss: 0.001050\n","Train Epoch: 7 [154240/155326 (99%)]\tLoss: 0.001840\n","Train Epoch: 7 [154880/155326 (100%)]\tLoss: 0.000461\n","Sample outputs (log probs): tensor([[-2.1500e+01, -2.4795e+01, -1.9169e+01, -3.0150e+01, -1.1336e+01,\n","         -2.7775e-05, -1.4680e+01, -2.6225e+01, -2.1171e+01, -1.9385e+01,\n","         -1.8342e+01, -2.5035e+01, -3.4156e+01, -3.3009e+01, -2.9808e+01,\n","         -1.1360e+01, -2.3109e+01, -1.9667e+01, -1.6254e+01, -1.2547e+01,\n","         -3.0607e+01, -2.3378e+01, -2.9201e+01, -2.3519e+01, -1.7092e+01,\n","         -1.7728e+01],\n","        [-2.1579e+01, -2.1110e+01, -1.8263e+01, -1.1763e+01, -2.0372e+01,\n","         -1.0993e+01, -2.5604e+01, -2.3406e+01, -6.0380e+00, -6.5373e+00,\n","         -2.0476e+01, -1.9005e+01, -1.9389e+01, -1.7184e+01, -1.8539e+01,\n","         -1.0484e+01, -2.1717e+01, -2.3125e+01, -1.4138e+01, -7.3947e-03,\n","         -1.7267e+01, -1.0593e+01, -2.2138e+01, -1.3485e+01, -5.6687e+00,\n","         -1.5619e+01],\n","        [-2.0103e+01, -2.0047e+01, -1.5752e+01, -1.3476e+01, -2.3044e+01,\n","         -2.3450e+01, -1.6847e+01, -1.1162e+01, -1.3661e+01, -1.2079e+01,\n","         -1.3853e+01, -1.1653e+01, -9.9194e+00, -8.0256e+00, -1.4168e+01,\n","         -1.9391e+01, -1.4403e+01, -2.3698e+01, -1.9646e+01, -1.7315e+01,\n","         -1.1643e-02, -4.6462e+00, -6.4679e+00, -1.4244e+01, -1.1170e+01,\n","         -2.0875e+01],\n","        [-1.7084e+01, -2.1458e+01, -2.8184e+01, -1.9315e+01, -3.3885e+01,\n","         -3.3367e+01, -2.4222e+01, -1.4674e+01, -2.5295e+01, -2.8078e+01,\n","         -1.8683e+01, -3.2301e+01, -9.7370e-04, -1.0205e+01, -2.2179e+01,\n","         -2.2591e+01, -2.1521e+01, -1.9363e+01, -3.4226e+01, -2.4588e+01,\n","         -1.3046e+01, -1.5928e+01, -6.9765e+00, -2.1497e+01, -2.2177e+01,\n","         -2.9102e+01],\n","        [-9.4861e+00, -1.8504e+01, -2.2814e+01, -2.1071e+01, -2.4276e+01,\n","         -2.1693e+01, -1.4725e+01, -2.1336e-04, -1.9102e+01, -1.9891e+01,\n","         -9.6362e+00, -1.7018e+01, -1.0306e+01, -1.4605e+01, -2.3107e+01,\n","         -1.8336e+01, -2.2742e+01, -1.9084e+01, -2.3538e+01, -1.8575e+01,\n","         -1.3076e+01, -1.6550e+01, -1.4402e+01, -1.5540e+01, -1.0260e+01,\n","         -2.1831e+01]], device='cuda:0')\n","Predicted classes: tensor([ 5, 19, 20, 12,  7], device='cuda:0')\n","Target classes: tensor([ 5, 19, 20, 12,  7], device='cuda:0')\n","\n","Test set: Average loss: 0.001800, Total sum loss: 0.547290, Accuracy: 37741/38832 (97%)\n","\n","Class A: 1287/1336 (96%)\n","Class B: 801/819 (98%)\n","Class C: 2013/2059 (98%)\n","Class D: 869/922 (94%)\n","Class E: 975/996 (98%)\n","Class F: 1773/1861 (95%)\n","Class G: 538/551 (98%)\n","Class H: 680/709 (96%)\n","Class I: 2401/2438 (98%)\n","Class J: 748/772 (97%)\n","Class K: 555/566 (98%)\n","Class L: 962/986 (98%)\n","Class M: 1817/1851 (98%)\n","Class N: 1589/1636 (97%)\n","Class O: 4905/5060 (97%)\n","Class P: 1759/1781 (99%)\n","Class Q: 568/589 (96%)\n","Class R: 1018/1056 (96%)\n","Class S: 4144/4209 (98%)\n","Class T: 1931/1960 (99%)\n","Class U: 2432/2562 (95%)\n","Class V: 942/988 (95%)\n","Class W: 965/990 (97%)\n","Class X: 569/601 (95%)\n","Class Y: 991/1022 (97%)\n","Class Z: 509/512 (99%)\n","Model saved with new best test loss: 0.0018 \n","\n","Train Epoch: 8 [0/155326 (0%)]\tLoss: 0.001359\n","Train Epoch: 8 [640/155326 (0%)]\tLoss: 0.000221\n","Train Epoch: 8 [1280/155326 (1%)]\tLoss: 0.001203\n","Train Epoch: 8 [1920/155326 (1%)]\tLoss: 0.004119\n","Train Epoch: 8 [2560/155326 (2%)]\tLoss: 0.001596\n","Train Epoch: 8 [3200/155326 (2%)]\tLoss: 0.000409\n","Train Epoch: 8 [3840/155326 (2%)]\tLoss: 0.001007\n","Train Epoch: 8 [4480/155326 (3%)]\tLoss: 0.000973\n","Train Epoch: 8 [5120/155326 (3%)]\tLoss: 0.000700\n","Train Epoch: 8 [5760/155326 (4%)]\tLoss: 0.001025\n","Train Epoch: 8 [6400/155326 (4%)]\tLoss: 0.001238\n","Train Epoch: 8 [7040/155326 (5%)]\tLoss: 0.000874\n","Train Epoch: 8 [7680/155326 (5%)]\tLoss: 0.007585\n","Train Epoch: 8 [8320/155326 (5%)]\tLoss: 0.000524\n","Train Epoch: 8 [8960/155326 (6%)]\tLoss: 0.000511\n","Train Epoch: 8 [9600/155326 (6%)]\tLoss: 0.002336\n","Train Epoch: 8 [10240/155326 (7%)]\tLoss: 0.000305\n","Train Epoch: 8 [10880/155326 (7%)]\tLoss: 0.000419\n","Train Epoch: 8 [11520/155326 (7%)]\tLoss: 0.000943\n","Train Epoch: 8 [12160/155326 (8%)]\tLoss: 0.000764\n","Train Epoch: 8 [12800/155326 (8%)]\tLoss: 0.000751\n","Train Epoch: 8 [13440/155326 (9%)]\tLoss: 0.000436\n","Train Epoch: 8 [14080/155326 (9%)]\tLoss: 0.000206\n","Train Epoch: 8 [14720/155326 (9%)]\tLoss: 0.000346\n","Train Epoch: 8 [15360/155326 (10%)]\tLoss: 0.000225\n","Train Epoch: 8 [16000/155326 (10%)]\tLoss: 0.000682\n","Train Epoch: 8 [16640/155326 (11%)]\tLoss: 0.001266\n","Train Epoch: 8 [17280/155326 (11%)]\tLoss: 0.000966\n","Train Epoch: 8 [17920/155326 (12%)]\tLoss: 0.000598\n","Train Epoch: 8 [18560/155326 (12%)]\tLoss: 0.000181\n","Train Epoch: 8 [19200/155326 (12%)]\tLoss: 0.001949\n","Train Epoch: 8 [19840/155326 (13%)]\tLoss: 0.001105\n","Train Epoch: 8 [20480/155326 (13%)]\tLoss: 0.000931\n","Train Epoch: 8 [21120/155326 (14%)]\tLoss: 0.000442\n","Train Epoch: 8 [21760/155326 (14%)]\tLoss: 0.000497\n","Train Epoch: 8 [22400/155326 (14%)]\tLoss: 0.003996\n","Train Epoch: 8 [23040/155326 (15%)]\tLoss: 0.000378\n","Train Epoch: 8 [23680/155326 (15%)]\tLoss: 0.000641\n","Train Epoch: 8 [24320/155326 (16%)]\tLoss: 0.000241\n","Train Epoch: 8 [24960/155326 (16%)]\tLoss: 0.000528\n","Train Epoch: 8 [25600/155326 (16%)]\tLoss: 0.000201\n","Train Epoch: 8 [26240/155326 (17%)]\tLoss: 0.000297\n","Train Epoch: 8 [26880/155326 (17%)]\tLoss: 0.000208\n","Train Epoch: 8 [27520/155326 (18%)]\tLoss: 0.000966\n","Train Epoch: 8 [28160/155326 (18%)]\tLoss: 0.000148\n","Train Epoch: 8 [28800/155326 (19%)]\tLoss: 0.002231\n","Train Epoch: 8 [29440/155326 (19%)]\tLoss: 0.000207\n","Train Epoch: 8 [30080/155326 (19%)]\tLoss: 0.001532\n","Train Epoch: 8 [30720/155326 (20%)]\tLoss: 0.000328\n","Train Epoch: 8 [31360/155326 (20%)]\tLoss: 0.005338\n","Train Epoch: 8 [32000/155326 (21%)]\tLoss: 0.000554\n","Train Epoch: 8 [32640/155326 (21%)]\tLoss: 0.000438\n","Train Epoch: 8 [33280/155326 (21%)]\tLoss: 0.000524\n","Train Epoch: 8 [33920/155326 (22%)]\tLoss: 0.001347\n","Train Epoch: 8 [34560/155326 (22%)]\tLoss: 0.001269\n","Train Epoch: 8 [35200/155326 (23%)]\tLoss: 0.000645\n","Train Epoch: 8 [35840/155326 (23%)]\tLoss: 0.000376\n","Train Epoch: 8 [36480/155326 (23%)]\tLoss: 0.000807\n","Train Epoch: 8 [37120/155326 (24%)]\tLoss: 0.000838\n","Train Epoch: 8 [37760/155326 (24%)]\tLoss: 0.000827\n","Train Epoch: 8 [38400/155326 (25%)]\tLoss: 0.000493\n","Train Epoch: 8 [39040/155326 (25%)]\tLoss: 0.001502\n","Train Epoch: 8 [39680/155326 (26%)]\tLoss: 0.000973\n","Train Epoch: 8 [40320/155326 (26%)]\tLoss: 0.000701\n","Train Epoch: 8 [40960/155326 (26%)]\tLoss: 0.003284\n","Train Epoch: 8 [41600/155326 (27%)]\tLoss: 0.000526\n","Train Epoch: 8 [42240/155326 (27%)]\tLoss: 0.000410\n","Train Epoch: 8 [42880/155326 (28%)]\tLoss: 0.001090\n","Train Epoch: 8 [43520/155326 (28%)]\tLoss: 0.001732\n","Train Epoch: 8 [44160/155326 (28%)]\tLoss: 0.001613\n","Train Epoch: 8 [44800/155326 (29%)]\tLoss: 0.001651\n","Train Epoch: 8 [45440/155326 (29%)]\tLoss: 0.000328\n","Train Epoch: 8 [46080/155326 (30%)]\tLoss: 0.000565\n","Train Epoch: 8 [46720/155326 (30%)]\tLoss: 0.001955\n","Train Epoch: 8 [47360/155326 (30%)]\tLoss: 0.000703\n","Train Epoch: 8 [48000/155326 (31%)]\tLoss: 0.001861\n","Train Epoch: 8 [48640/155326 (31%)]\tLoss: 0.001888\n","Train Epoch: 8 [49280/155326 (32%)]\tLoss: 0.000357\n","Train Epoch: 8 [49920/155326 (32%)]\tLoss: 0.001082\n","Train Epoch: 8 [50560/155326 (33%)]\tLoss: 0.000894\n","Train Epoch: 8 [51200/155326 (33%)]\tLoss: 0.000669\n","Train Epoch: 8 [51840/155326 (33%)]\tLoss: 0.001408\n","Train Epoch: 8 [52480/155326 (34%)]\tLoss: 0.000587\n","Train Epoch: 8 [53120/155326 (34%)]\tLoss: 0.000869\n","Train Epoch: 8 [53760/155326 (35%)]\tLoss: 0.000775\n","Train Epoch: 8 [54400/155326 (35%)]\tLoss: 0.001949\n","Train Epoch: 8 [55040/155326 (35%)]\tLoss: 0.000531\n","Train Epoch: 8 [55680/155326 (36%)]\tLoss: 0.000795\n","Train Epoch: 8 [56320/155326 (36%)]\tLoss: 0.000607\n","Train Epoch: 8 [56960/155326 (37%)]\tLoss: 0.000434\n","Train Epoch: 8 [57600/155326 (37%)]\tLoss: 0.000544\n","Train Epoch: 8 [58240/155326 (37%)]\tLoss: 0.000797\n","Train Epoch: 8 [58880/155326 (38%)]\tLoss: 0.000144\n","Train Epoch: 8 [59520/155326 (38%)]\tLoss: 0.000804\n","Train Epoch: 8 [60160/155326 (39%)]\tLoss: 0.006587\n","Train Epoch: 8 [60800/155326 (39%)]\tLoss: 0.000960\n","Train Epoch: 8 [61440/155326 (40%)]\tLoss: 0.000255\n","Train Epoch: 8 [62080/155326 (40%)]\tLoss: 0.000286\n","Train Epoch: 8 [62720/155326 (40%)]\tLoss: 0.000494\n","Train Epoch: 8 [63360/155326 (41%)]\tLoss: 0.001483\n","Train Epoch: 8 [64000/155326 (41%)]\tLoss: 0.000928\n","Train Epoch: 8 [64640/155326 (42%)]\tLoss: 0.001063\n","Train Epoch: 8 [65280/155326 (42%)]\tLoss: 0.000344\n","Train Epoch: 8 [65920/155326 (42%)]\tLoss: 0.000727\n","Train Epoch: 8 [66560/155326 (43%)]\tLoss: 0.000364\n","Train Epoch: 8 [67200/155326 (43%)]\tLoss: 0.000209\n","Train Epoch: 8 [67840/155326 (44%)]\tLoss: 0.001088\n","Train Epoch: 8 [68480/155326 (44%)]\tLoss: 0.000513\n","Train Epoch: 8 [69120/155326 (44%)]\tLoss: 0.000313\n","Train Epoch: 8 [69760/155326 (45%)]\tLoss: 0.000308\n","Train Epoch: 8 [70400/155326 (45%)]\tLoss: 0.002062\n","Train Epoch: 8 [71040/155326 (46%)]\tLoss: 0.000588\n","Train Epoch: 8 [71680/155326 (46%)]\tLoss: 0.000645\n","Train Epoch: 8 [72320/155326 (47%)]\tLoss: 0.001063\n","Train Epoch: 8 [72960/155326 (47%)]\tLoss: 0.000537\n","Train Epoch: 8 [73600/155326 (47%)]\tLoss: 0.000358\n","Train Epoch: 8 [74240/155326 (48%)]\tLoss: 0.000253\n","Train Epoch: 8 [74880/155326 (48%)]\tLoss: 0.000304\n","Train Epoch: 8 [75520/155326 (49%)]\tLoss: 0.000422\n","Train Epoch: 8 [76160/155326 (49%)]\tLoss: 0.001042\n","Train Epoch: 8 [76800/155326 (49%)]\tLoss: 0.001307\n","Train Epoch: 8 [77440/155326 (50%)]\tLoss: 0.000384\n","Train Epoch: 8 [78080/155326 (50%)]\tLoss: 0.000723\n","Train Epoch: 8 [78720/155326 (51%)]\tLoss: 0.002270\n","Train Epoch: 8 [79360/155326 (51%)]\tLoss: 0.000770\n","Train Epoch: 8 [80000/155326 (52%)]\tLoss: 0.000184\n","Train Epoch: 8 [80640/155326 (52%)]\tLoss: 0.000395\n","Train Epoch: 8 [81280/155326 (52%)]\tLoss: 0.000690\n","Train Epoch: 8 [81920/155326 (53%)]\tLoss: 0.000652\n","Train Epoch: 8 [82560/155326 (53%)]\tLoss: 0.001563\n","Train Epoch: 8 [83200/155326 (54%)]\tLoss: 0.002205\n","Train Epoch: 8 [83840/155326 (54%)]\tLoss: 0.000599\n","Train Epoch: 8 [84480/155326 (54%)]\tLoss: 0.001306\n","Train Epoch: 8 [85120/155326 (55%)]\tLoss: 0.000954\n","Train Epoch: 8 [85760/155326 (55%)]\tLoss: 0.001575\n","Train Epoch: 8 [86400/155326 (56%)]\tLoss: 0.001322\n","Train Epoch: 8 [87040/155326 (56%)]\tLoss: 0.001192\n","Train Epoch: 8 [87680/155326 (56%)]\tLoss: 0.000589\n","Train Epoch: 8 [88320/155326 (57%)]\tLoss: 0.000390\n","Train Epoch: 8 [88960/155326 (57%)]\tLoss: 0.001081\n","Train Epoch: 8 [89600/155326 (58%)]\tLoss: 0.001721\n","Train Epoch: 8 [90240/155326 (58%)]\tLoss: 0.000743\n","Train Epoch: 8 [90880/155326 (59%)]\tLoss: 0.000316\n","Train Epoch: 8 [91520/155326 (59%)]\tLoss: 0.001060\n","Train Epoch: 8 [92160/155326 (59%)]\tLoss: 0.000263\n","Train Epoch: 8 [92800/155326 (60%)]\tLoss: 0.004593\n","Train Epoch: 8 [93440/155326 (60%)]\tLoss: 0.000636\n","Train Epoch: 8 [94080/155326 (61%)]\tLoss: 0.000692\n","Train Epoch: 8 [94720/155326 (61%)]\tLoss: 0.000821\n","Train Epoch: 8 [95360/155326 (61%)]\tLoss: 0.001359\n","Train Epoch: 8 [96000/155326 (62%)]\tLoss: 0.000784\n","Train Epoch: 8 [96640/155326 (62%)]\tLoss: 0.000550\n","Train Epoch: 8 [97280/155326 (63%)]\tLoss: 0.000605\n","Train Epoch: 8 [97920/155326 (63%)]\tLoss: 0.000508\n","Train Epoch: 8 [98560/155326 (63%)]\tLoss: 0.000385\n","Train Epoch: 8 [99200/155326 (64%)]\tLoss: 0.001129\n","Train Epoch: 8 [99840/155326 (64%)]\tLoss: 0.000841\n","Train Epoch: 8 [100480/155326 (65%)]\tLoss: 0.001459\n","Train Epoch: 8 [101120/155326 (65%)]\tLoss: 0.001252\n","Train Epoch: 8 [101760/155326 (66%)]\tLoss: 0.001433\n","Train Epoch: 8 [102400/155326 (66%)]\tLoss: 0.000755\n","Train Epoch: 8 [103040/155326 (66%)]\tLoss: 0.000709\n","Train Epoch: 8 [103680/155326 (67%)]\tLoss: 0.000396\n","Train Epoch: 8 [104320/155326 (67%)]\tLoss: 0.000512\n","Train Epoch: 8 [104960/155326 (68%)]\tLoss: 0.000769\n","Train Epoch: 8 [105600/155326 (68%)]\tLoss: 0.000565\n","Train Epoch: 8 [106240/155326 (68%)]\tLoss: 0.000209\n","Train Epoch: 8 [106880/155326 (69%)]\tLoss: 0.001695\n","Train Epoch: 8 [107520/155326 (69%)]\tLoss: 0.000422\n","Train Epoch: 8 [108160/155326 (70%)]\tLoss: 0.001217\n","Train Epoch: 8 [108800/155326 (70%)]\tLoss: 0.002781\n","Train Epoch: 8 [109440/155326 (70%)]\tLoss: 0.001006\n","Train Epoch: 8 [110080/155326 (71%)]\tLoss: 0.000528\n","Train Epoch: 8 [110720/155326 (71%)]\tLoss: 0.000299\n","Train Epoch: 8 [111360/155326 (72%)]\tLoss: 0.002007\n","Train Epoch: 8 [112000/155326 (72%)]\tLoss: 0.001728\n","Train Epoch: 8 [112640/155326 (73%)]\tLoss: 0.000253\n","Train Epoch: 8 [113280/155326 (73%)]\tLoss: 0.001244\n","Train Epoch: 8 [113920/155326 (73%)]\tLoss: 0.000416\n","Train Epoch: 8 [114560/155326 (74%)]\tLoss: 0.001268\n","Train Epoch: 8 [115200/155326 (74%)]\tLoss: 0.000918\n","Train Epoch: 8 [115840/155326 (75%)]\tLoss: 0.000757\n","Train Epoch: 8 [116480/155326 (75%)]\tLoss: 0.003692\n","Train Epoch: 8 [117120/155326 (75%)]\tLoss: 0.000196\n","Train Epoch: 8 [117760/155326 (76%)]\tLoss: 0.000727\n","Train Epoch: 8 [118400/155326 (76%)]\tLoss: 0.003235\n","Train Epoch: 8 [119040/155326 (77%)]\tLoss: 0.001624\n","Train Epoch: 8 [119680/155326 (77%)]\tLoss: 0.000813\n","Train Epoch: 8 [120320/155326 (77%)]\tLoss: 0.000588\n","Train Epoch: 8 [120960/155326 (78%)]\tLoss: 0.000261\n","Train Epoch: 8 [121600/155326 (78%)]\tLoss: 0.001402\n","Train Epoch: 8 [122240/155326 (79%)]\tLoss: 0.000263\n","Train Epoch: 8 [122880/155326 (79%)]\tLoss: 0.001881\n","Train Epoch: 8 [123520/155326 (80%)]\tLoss: 0.000165\n","Train Epoch: 8 [124160/155326 (80%)]\tLoss: 0.000426\n","Train Epoch: 8 [124800/155326 (80%)]\tLoss: 0.001190\n","Train Epoch: 8 [125440/155326 (81%)]\tLoss: 0.003628\n","Train Epoch: 8 [126080/155326 (81%)]\tLoss: 0.000523\n","Train Epoch: 8 [126720/155326 (82%)]\tLoss: 0.001631\n","Train Epoch: 8 [127360/155326 (82%)]\tLoss: 0.000691\n","Train Epoch: 8 [128000/155326 (82%)]\tLoss: 0.001100\n","Train Epoch: 8 [128640/155326 (83%)]\tLoss: 0.000369\n","Train Epoch: 8 [129280/155326 (83%)]\tLoss: 0.000281\n","Train Epoch: 8 [129920/155326 (84%)]\tLoss: 0.000194\n","Train Epoch: 8 [130560/155326 (84%)]\tLoss: 0.000881\n","Train Epoch: 8 [131200/155326 (84%)]\tLoss: 0.001626\n","Train Epoch: 8 [131840/155326 (85%)]\tLoss: 0.000585\n","Train Epoch: 8 [132480/155326 (85%)]\tLoss: 0.000828\n","Train Epoch: 8 [133120/155326 (86%)]\tLoss: 0.000104\n","Train Epoch: 8 [133760/155326 (86%)]\tLoss: 0.000987\n","Train Epoch: 8 [134400/155326 (87%)]\tLoss: 0.000593\n","Train Epoch: 8 [135040/155326 (87%)]\tLoss: 0.001130\n","Train Epoch: 8 [135680/155326 (87%)]\tLoss: 0.001122\n","Train Epoch: 8 [136320/155326 (88%)]\tLoss: 0.000474\n","Train Epoch: 8 [136960/155326 (88%)]\tLoss: 0.000379\n","Train Epoch: 8 [137600/155326 (89%)]\tLoss: 0.000810\n","Train Epoch: 8 [138240/155326 (89%)]\tLoss: 0.000363\n","Train Epoch: 8 [138880/155326 (89%)]\tLoss: 0.000669\n","Train Epoch: 8 [139520/155326 (90%)]\tLoss: 0.001059\n","Train Epoch: 8 [140160/155326 (90%)]\tLoss: 0.000661\n","Train Epoch: 8 [140800/155326 (91%)]\tLoss: 0.000541\n","Train Epoch: 8 [141440/155326 (91%)]\tLoss: 0.000106\n","Train Epoch: 8 [142080/155326 (91%)]\tLoss: 0.000307\n","Train Epoch: 8 [142720/155326 (92%)]\tLoss: 0.000274\n","Train Epoch: 8 [143360/155326 (92%)]\tLoss: 0.000794\n","Train Epoch: 8 [144000/155326 (93%)]\tLoss: 0.000527\n","Train Epoch: 8 [144640/155326 (93%)]\tLoss: 0.001976\n","Train Epoch: 8 [145280/155326 (94%)]\tLoss: 0.002313\n","Train Epoch: 8 [145920/155326 (94%)]\tLoss: 0.002821\n","Train Epoch: 8 [146560/155326 (94%)]\tLoss: 0.001391\n","Train Epoch: 8 [147200/155326 (95%)]\tLoss: 0.000600\n","Train Epoch: 8 [147840/155326 (95%)]\tLoss: 0.000509\n","Train Epoch: 8 [148480/155326 (96%)]\tLoss: 0.001164\n","Train Epoch: 8 [149120/155326 (96%)]\tLoss: 0.000795\n","Train Epoch: 8 [149760/155326 (96%)]\tLoss: 0.000388\n","Train Epoch: 8 [150400/155326 (97%)]\tLoss: 0.001015\n","Train Epoch: 8 [151040/155326 (97%)]\tLoss: 0.001624\n","Train Epoch: 8 [151680/155326 (98%)]\tLoss: 0.000537\n","Train Epoch: 8 [152320/155326 (98%)]\tLoss: 0.001113\n","Train Epoch: 8 [152960/155326 (98%)]\tLoss: 0.000592\n","Train Epoch: 8 [153600/155326 (99%)]\tLoss: 0.000860\n","Train Epoch: 8 [154240/155326 (99%)]\tLoss: 0.000457\n","Train Epoch: 8 [154880/155326 (100%)]\tLoss: 0.000969\n","Sample outputs (log probs): tensor([[-1.3130e+01, -1.6411e+01, -1.1115e+01, -1.2602e+01, -1.3638e+01,\n","         -1.1091e+01, -1.6236e+01, -1.4657e+01, -4.4670e-04, -1.0799e+01,\n","         -1.4028e+01, -8.1088e+00, -1.9375e+01, -1.1309e+01, -1.2204e+01,\n","         -1.1987e+01, -1.6231e+01, -1.5746e+01, -1.2253e+01, -1.0285e+01,\n","         -1.2827e+01, -1.1135e+01, -2.0367e+01, -1.3256e+01, -1.2187e+01,\n","         -1.4874e+01],\n","        [-3.0223e+01, -1.7152e+01, -2.1862e+01, -1.8517e+01, -1.3825e+01,\n","         -1.3534e+01, -2.3202e+01, -3.5485e+01, -1.3570e+01, -6.4039e+00,\n","         -3.2306e+01, -2.9790e+01, -3.5136e+01, -3.3023e+01, -2.0469e+01,\n","         -2.5000e+01, -2.3806e+01, -3.6862e+01, -1.6602e-03, -2.1085e+01,\n","         -2.7882e+01, -3.1099e+01, -3.7414e+01, -2.8489e+01, -2.0797e+01,\n","         -2.4229e+01],\n","        [-1.8295e+01, -1.9595e+01, -2.0645e+01, -1.6544e+01, -2.7177e+01,\n","         -1.3462e+01, -2.5250e+01, -2.0613e+01, -2.3744e+01, -2.8689e+01,\n","         -2.6533e+01, -2.9670e+01, -2.3849e+01, -1.8767e+01, -1.9313e+01,\n","         -2.6226e-06, -1.4262e+01, -1.5112e+01, -2.8126e+01, -1.7820e+01,\n","         -2.4337e+01, -1.7372e+01, -2.1824e+01, -2.8692e+01, -1.6770e+01,\n","         -2.4780e+01],\n","        [-2.6567e+01, -1.7244e+01, -1.8720e+01, -2.2548e+01, -1.1265e+01,\n","         -1.2821e+01, -1.6385e+01, -3.0585e+01, -1.7251e+01, -1.1974e+01,\n","         -2.6161e+01, -2.6982e+01, -3.4057e+01, -3.2513e+01, -1.9330e+01,\n","         -2.4860e+01, -2.0630e+01, -3.1534e+01, -2.2053e-05, -2.2959e+01,\n","         -2.5313e+01, -2.8294e+01, -3.5711e+01, -2.7611e+01, -2.2175e+01,\n","         -2.3991e+01],\n","        [-1.2341e+01, -2.1716e+01, -2.1528e+01, -1.7475e+01, -2.9812e+01,\n","         -2.4214e+01, -2.2996e+01, -8.0637e+00, -1.8639e+01, -2.3918e+01,\n","         -1.7063e+01, -2.4294e+01, -8.4180e+00, -7.9255e-04, -1.8416e+01,\n","         -1.2064e+01, -1.8659e+01, -1.5341e+01, -3.0000e+01, -2.0304e+01,\n","         -1.2486e+01, -1.1420e+01, -8.3711e+00, -2.2364e+01, -2.0253e+01,\n","         -2.8262e+01]], device='cuda:0')\n","Predicted classes: tensor([ 8, 18, 15, 18, 13], device='cuda:0')\n","Target classes: tensor([ 8, 18, 15, 18, 13], device='cuda:0')\n","\n","Test set: Average loss: 0.001765, Total sum loss: 0.536499, Accuracy: 37823/38832 (97%)\n","\n","Class A: 1303/1336 (98%)\n","Class B: 808/819 (99%)\n","Class C: 2004/2059 (97%)\n","Class D: 867/922 (94%)\n","Class E: 982/996 (99%)\n","Class F: 1813/1861 (97%)\n","Class G: 534/551 (97%)\n","Class H: 688/709 (97%)\n","Class I: 2394/2438 (98%)\n","Class J: 754/772 (98%)\n","Class K: 546/566 (96%)\n","Class L: 966/986 (98%)\n","Class M: 1807/1851 (98%)\n","Class N: 1583/1636 (97%)\n","Class O: 4919/5060 (97%)\n","Class P: 1744/1781 (98%)\n","Class Q: 569/589 (97%)\n","Class R: 1029/1056 (97%)\n","Class S: 4170/4209 (99%)\n","Class T: 1935/1960 (99%)\n","Class U: 2436/2562 (95%)\n","Class V: 953/988 (96%)\n","Class W: 957/990 (97%)\n","Class X: 581/601 (97%)\n","Class Y: 973/1022 (95%)\n","Class Z: 508/512 (99%)\n","Model saved with new best test loss: 0.0018 \n","\n","Train Epoch: 9 [0/155326 (0%)]\tLoss: 0.000961\n","Train Epoch: 9 [640/155326 (0%)]\tLoss: 0.000724\n","Train Epoch: 9 [1280/155326 (1%)]\tLoss: 0.001117\n","Train Epoch: 9 [1920/155326 (1%)]\tLoss: 0.000277\n","Train Epoch: 9 [2560/155326 (2%)]\tLoss: 0.001931\n","Train Epoch: 9 [3200/155326 (2%)]\tLoss: 0.000919\n","Train Epoch: 9 [3840/155326 (2%)]\tLoss: 0.000263\n","Train Epoch: 9 [4480/155326 (3%)]\tLoss: 0.000461\n","Train Epoch: 9 [5120/155326 (3%)]\tLoss: 0.000102\n","Train Epoch: 9 [5760/155326 (4%)]\tLoss: 0.000197\n","Train Epoch: 9 [6400/155326 (4%)]\tLoss: 0.001572\n","Train Epoch: 9 [7040/155326 (5%)]\tLoss: 0.000914\n","Train Epoch: 9 [7680/155326 (5%)]\tLoss: 0.001369\n","Train Epoch: 9 [8320/155326 (5%)]\tLoss: 0.000472\n","Train Epoch: 9 [8960/155326 (6%)]\tLoss: 0.000573\n","Train Epoch: 9 [9600/155326 (6%)]\tLoss: 0.000363\n","Train Epoch: 9 [10240/155326 (7%)]\tLoss: 0.001384\n","Train Epoch: 9 [10880/155326 (7%)]\tLoss: 0.000441\n","Train Epoch: 9 [11520/155326 (7%)]\tLoss: 0.003085\n","Train Epoch: 9 [12160/155326 (8%)]\tLoss: 0.002277\n","Train Epoch: 9 [12800/155326 (8%)]\tLoss: 0.000889\n","Train Epoch: 9 [13440/155326 (9%)]\tLoss: 0.000774\n","Train Epoch: 9 [14080/155326 (9%)]\tLoss: 0.001646\n","Train Epoch: 9 [14720/155326 (9%)]\tLoss: 0.000249\n","Train Epoch: 9 [15360/155326 (10%)]\tLoss: 0.001841\n","Train Epoch: 9 [16000/155326 (10%)]\tLoss: 0.001276\n","Train Epoch: 9 [16640/155326 (11%)]\tLoss: 0.000905\n","Train Epoch: 9 [17280/155326 (11%)]\tLoss: 0.000531\n","Train Epoch: 9 [17920/155326 (12%)]\tLoss: 0.000531\n","Train Epoch: 9 [18560/155326 (12%)]\tLoss: 0.000496\n","Train Epoch: 9 [19200/155326 (12%)]\tLoss: 0.000803\n","Train Epoch: 9 [19840/155326 (13%)]\tLoss: 0.000179\n","Train Epoch: 9 [20480/155326 (13%)]\tLoss: 0.000392\n","Train Epoch: 9 [21120/155326 (14%)]\tLoss: 0.001502\n","Train Epoch: 9 [21760/155326 (14%)]\tLoss: 0.000502\n","Train Epoch: 9 [22400/155326 (14%)]\tLoss: 0.001584\n","Train Epoch: 9 [23040/155326 (15%)]\tLoss: 0.002894\n","Train Epoch: 9 [23680/155326 (15%)]\tLoss: 0.002732\n","Train Epoch: 9 [24320/155326 (16%)]\tLoss: 0.000584\n","Train Epoch: 9 [24960/155326 (16%)]\tLoss: 0.000674\n","Train Epoch: 9 [25600/155326 (16%)]\tLoss: 0.000200\n","Train Epoch: 9 [26240/155326 (17%)]\tLoss: 0.001055\n","Train Epoch: 9 [26880/155326 (17%)]\tLoss: 0.001072\n","Train Epoch: 9 [27520/155326 (18%)]\tLoss: 0.000854\n","Train Epoch: 9 [28160/155326 (18%)]\tLoss: 0.000152\n","Train Epoch: 9 [28800/155326 (19%)]\tLoss: 0.002281\n","Train Epoch: 9 [29440/155326 (19%)]\tLoss: 0.000427\n","Train Epoch: 9 [30080/155326 (19%)]\tLoss: 0.000376\n","Train Epoch: 9 [30720/155326 (20%)]\tLoss: 0.000385\n","Train Epoch: 9 [31360/155326 (20%)]\tLoss: 0.001361\n","Train Epoch: 9 [32000/155326 (21%)]\tLoss: 0.000369\n","Train Epoch: 9 [32640/155326 (21%)]\tLoss: 0.000436\n","Train Epoch: 9 [33280/155326 (21%)]\tLoss: 0.001580\n","Train Epoch: 9 [33920/155326 (22%)]\tLoss: 0.000129\n","Train Epoch: 9 [34560/155326 (22%)]\tLoss: 0.002207\n","Train Epoch: 9 [35200/155326 (23%)]\tLoss: 0.000593\n","Train Epoch: 9 [35840/155326 (23%)]\tLoss: 0.000719\n","Train Epoch: 9 [36480/155326 (23%)]\tLoss: 0.000183\n","Train Epoch: 9 [37120/155326 (24%)]\tLoss: 0.000317\n","Train Epoch: 9 [37760/155326 (24%)]\tLoss: 0.000882\n","Train Epoch: 9 [38400/155326 (25%)]\tLoss: 0.000597\n","Train Epoch: 9 [39040/155326 (25%)]\tLoss: 0.000095\n","Train Epoch: 9 [39680/155326 (26%)]\tLoss: 0.000449\n","Train Epoch: 9 [40320/155326 (26%)]\tLoss: 0.000824\n","Train Epoch: 9 [40960/155326 (26%)]\tLoss: 0.000806\n","Train Epoch: 9 [41600/155326 (27%)]\tLoss: 0.000554\n","Train Epoch: 9 [42240/155326 (27%)]\tLoss: 0.000191\n","Train Epoch: 9 [42880/155326 (28%)]\tLoss: 0.000991\n","Train Epoch: 9 [43520/155326 (28%)]\tLoss: 0.001014\n","Train Epoch: 9 [44160/155326 (28%)]\tLoss: 0.000555\n","Train Epoch: 9 [44800/155326 (29%)]\tLoss: 0.000678\n","Train Epoch: 9 [45440/155326 (29%)]\tLoss: 0.000325\n","Train Epoch: 9 [46080/155326 (30%)]\tLoss: 0.000581\n","Train Epoch: 9 [46720/155326 (30%)]\tLoss: 0.000597\n","Train Epoch: 9 [47360/155326 (30%)]\tLoss: 0.002303\n","Train Epoch: 9 [48000/155326 (31%)]\tLoss: 0.000438\n","Train Epoch: 9 [48640/155326 (31%)]\tLoss: 0.001195\n","Train Epoch: 9 [49280/155326 (32%)]\tLoss: 0.000673\n","Train Epoch: 9 [49920/155326 (32%)]\tLoss: 0.000400\n","Train Epoch: 9 [50560/155326 (33%)]\tLoss: 0.001785\n","Train Epoch: 9 [51200/155326 (33%)]\tLoss: 0.000462\n","Train Epoch: 9 [51840/155326 (33%)]\tLoss: 0.001734\n","Train Epoch: 9 [52480/155326 (34%)]\tLoss: 0.000118\n","Train Epoch: 9 [53120/155326 (34%)]\tLoss: 0.001006\n","Train Epoch: 9 [53760/155326 (35%)]\tLoss: 0.001221\n","Train Epoch: 9 [54400/155326 (35%)]\tLoss: 0.001062\n","Train Epoch: 9 [55040/155326 (35%)]\tLoss: 0.000442\n","Train Epoch: 9 [55680/155326 (36%)]\tLoss: 0.000423\n","Train Epoch: 9 [56320/155326 (36%)]\tLoss: 0.001065\n","Train Epoch: 9 [56960/155326 (37%)]\tLoss: 0.000420\n","Train Epoch: 9 [57600/155326 (37%)]\tLoss: 0.000772\n","Train Epoch: 9 [58240/155326 (37%)]\tLoss: 0.000519\n","Train Epoch: 9 [58880/155326 (38%)]\tLoss: 0.002022\n","Train Epoch: 9 [59520/155326 (38%)]\tLoss: 0.000755\n","Train Epoch: 9 [60160/155326 (39%)]\tLoss: 0.000173\n","Train Epoch: 9 [60800/155326 (39%)]\tLoss: 0.000457\n","Train Epoch: 9 [61440/155326 (40%)]\tLoss: 0.000158\n","Train Epoch: 9 [62080/155326 (40%)]\tLoss: 0.002169\n","Train Epoch: 9 [62720/155326 (40%)]\tLoss: 0.002690\n","Train Epoch: 9 [63360/155326 (41%)]\tLoss: 0.001426\n","Train Epoch: 9 [64000/155326 (41%)]\tLoss: 0.002427\n","Train Epoch: 9 [64640/155326 (42%)]\tLoss: 0.002332\n","Train Epoch: 9 [65280/155326 (42%)]\tLoss: 0.001709\n","Train Epoch: 9 [65920/155326 (42%)]\tLoss: 0.000452\n","Train Epoch: 9 [66560/155326 (43%)]\tLoss: 0.000878\n","Train Epoch: 9 [67200/155326 (43%)]\tLoss: 0.000690\n","Train Epoch: 9 [67840/155326 (44%)]\tLoss: 0.001843\n","Train Epoch: 9 [68480/155326 (44%)]\tLoss: 0.000371\n","Train Epoch: 9 [69120/155326 (44%)]\tLoss: 0.001143\n","Train Epoch: 9 [69760/155326 (45%)]\tLoss: 0.000766\n","Train Epoch: 9 [70400/155326 (45%)]\tLoss: 0.000423\n","Train Epoch: 9 [71040/155326 (46%)]\tLoss: 0.000319\n","Train Epoch: 9 [71680/155326 (46%)]\tLoss: 0.001262\n","Train Epoch: 9 [72320/155326 (47%)]\tLoss: 0.001402\n","Train Epoch: 9 [72960/155326 (47%)]\tLoss: 0.001644\n","Train Epoch: 9 [73600/155326 (47%)]\tLoss: 0.003004\n","Train Epoch: 9 [74240/155326 (48%)]\tLoss: 0.000573\n","Train Epoch: 9 [74880/155326 (48%)]\tLoss: 0.001376\n","Train Epoch: 9 [75520/155326 (49%)]\tLoss: 0.000177\n","Train Epoch: 9 [76160/155326 (49%)]\tLoss: 0.000347\n","Train Epoch: 9 [76800/155326 (49%)]\tLoss: 0.000724\n","Train Epoch: 9 [77440/155326 (50%)]\tLoss: 0.000747\n","Train Epoch: 9 [78080/155326 (50%)]\tLoss: 0.000938\n","Train Epoch: 9 [78720/155326 (51%)]\tLoss: 0.001468\n","Train Epoch: 9 [79360/155326 (51%)]\tLoss: 0.001078\n","Train Epoch: 9 [80000/155326 (52%)]\tLoss: 0.000618\n","Train Epoch: 9 [80640/155326 (52%)]\tLoss: 0.000284\n","Train Epoch: 9 [81280/155326 (52%)]\tLoss: 0.000464\n","Train Epoch: 9 [81920/155326 (53%)]\tLoss: 0.000807\n","Train Epoch: 9 [82560/155326 (53%)]\tLoss: 0.001155\n","Train Epoch: 9 [83200/155326 (54%)]\tLoss: 0.000890\n","Train Epoch: 9 [83840/155326 (54%)]\tLoss: 0.000628\n","Train Epoch: 9 [84480/155326 (54%)]\tLoss: 0.002355\n","Train Epoch: 9 [85120/155326 (55%)]\tLoss: 0.002165\n","Train Epoch: 9 [85760/155326 (55%)]\tLoss: 0.000515\n","Train Epoch: 9 [86400/155326 (56%)]\tLoss: 0.000586\n","Train Epoch: 9 [87040/155326 (56%)]\tLoss: 0.000829\n","Train Epoch: 9 [87680/155326 (56%)]\tLoss: 0.001138\n","Train Epoch: 9 [88320/155326 (57%)]\tLoss: 0.002316\n","Train Epoch: 9 [88960/155326 (57%)]\tLoss: 0.001029\n","Train Epoch: 9 [89600/155326 (58%)]\tLoss: 0.000616\n","Train Epoch: 9 [90240/155326 (58%)]\tLoss: 0.000804\n","Train Epoch: 9 [90880/155326 (59%)]\tLoss: 0.000327\n","Train Epoch: 9 [91520/155326 (59%)]\tLoss: 0.002063\n","Train Epoch: 9 [92160/155326 (59%)]\tLoss: 0.000072\n","Train Epoch: 9 [92800/155326 (60%)]\tLoss: 0.001138\n","Train Epoch: 9 [93440/155326 (60%)]\tLoss: 0.000524\n","Train Epoch: 9 [94080/155326 (61%)]\tLoss: 0.002215\n","Train Epoch: 9 [94720/155326 (61%)]\tLoss: 0.001476\n","Train Epoch: 9 [95360/155326 (61%)]\tLoss: 0.001358\n","Train Epoch: 9 [96000/155326 (62%)]\tLoss: 0.002794\n","Train Epoch: 9 [96640/155326 (62%)]\tLoss: 0.000124\n","Train Epoch: 9 [97280/155326 (63%)]\tLoss: 0.000560\n","Train Epoch: 9 [97920/155326 (63%)]\tLoss: 0.000467\n","Train Epoch: 9 [98560/155326 (63%)]\tLoss: 0.000920\n","Train Epoch: 9 [99200/155326 (64%)]\tLoss: 0.000318\n","Train Epoch: 9 [99840/155326 (64%)]\tLoss: 0.000326\n","Train Epoch: 9 [100480/155326 (65%)]\tLoss: 0.000168\n","Train Epoch: 9 [101120/155326 (65%)]\tLoss: 0.000284\n","Train Epoch: 9 [101760/155326 (66%)]\tLoss: 0.000301\n","Train Epoch: 9 [102400/155326 (66%)]\tLoss: 0.000275\n","Train Epoch: 9 [103040/155326 (66%)]\tLoss: 0.001752\n","Train Epoch: 9 [103680/155326 (67%)]\tLoss: 0.000403\n","Train Epoch: 9 [104320/155326 (67%)]\tLoss: 0.001203\n","Train Epoch: 9 [104960/155326 (68%)]\tLoss: 0.000563\n","Train Epoch: 9 [105600/155326 (68%)]\tLoss: 0.000566\n","Train Epoch: 9 [106240/155326 (68%)]\tLoss: 0.000534\n","Train Epoch: 9 [106880/155326 (69%)]\tLoss: 0.000358\n","Train Epoch: 9 [107520/155326 (69%)]\tLoss: 0.000665\n","Train Epoch: 9 [108160/155326 (70%)]\tLoss: 0.001398\n","Train Epoch: 9 [108800/155326 (70%)]\tLoss: 0.000320\n","Train Epoch: 9 [109440/155326 (70%)]\tLoss: 0.000734\n","Train Epoch: 9 [110080/155326 (71%)]\tLoss: 0.000888\n","Train Epoch: 9 [110720/155326 (71%)]\tLoss: 0.003997\n","Train Epoch: 9 [111360/155326 (72%)]\tLoss: 0.000896\n","Train Epoch: 9 [112000/155326 (72%)]\tLoss: 0.001321\n","Train Epoch: 9 [112640/155326 (73%)]\tLoss: 0.000148\n","Train Epoch: 9 [113280/155326 (73%)]\tLoss: 0.000469\n","Train Epoch: 9 [113920/155326 (73%)]\tLoss: 0.000181\n","Train Epoch: 9 [114560/155326 (74%)]\tLoss: 0.003272\n","Train Epoch: 9 [115200/155326 (74%)]\tLoss: 0.001560\n","Train Epoch: 9 [115840/155326 (75%)]\tLoss: 0.000176\n","Train Epoch: 9 [116480/155326 (75%)]\tLoss: 0.000872\n","Train Epoch: 9 [117120/155326 (75%)]\tLoss: 0.000905\n","Train Epoch: 9 [117760/155326 (76%)]\tLoss: 0.001696\n","Train Epoch: 9 [118400/155326 (76%)]\tLoss: 0.000967\n","Train Epoch: 9 [119040/155326 (77%)]\tLoss: 0.002187\n","Train Epoch: 9 [119680/155326 (77%)]\tLoss: 0.000971\n","Train Epoch: 9 [120320/155326 (77%)]\tLoss: 0.000802\n","Train Epoch: 9 [120960/155326 (78%)]\tLoss: 0.000672\n","Train Epoch: 9 [121600/155326 (78%)]\tLoss: 0.000542\n","Train Epoch: 9 [122240/155326 (79%)]\tLoss: 0.000689\n","Train Epoch: 9 [122880/155326 (79%)]\tLoss: 0.000307\n","Train Epoch: 9 [123520/155326 (80%)]\tLoss: 0.001131\n","Train Epoch: 9 [124160/155326 (80%)]\tLoss: 0.001016\n","Train Epoch: 9 [124800/155326 (80%)]\tLoss: 0.000728\n","Train Epoch: 9 [125440/155326 (81%)]\tLoss: 0.000297\n","Train Epoch: 9 [126080/155326 (81%)]\tLoss: 0.000432\n","Train Epoch: 9 [126720/155326 (82%)]\tLoss: 0.000361\n","Train Epoch: 9 [127360/155326 (82%)]\tLoss: 0.000098\n","Train Epoch: 9 [128000/155326 (82%)]\tLoss: 0.000817\n","Train Epoch: 9 [128640/155326 (83%)]\tLoss: 0.000873\n","Train Epoch: 9 [129280/155326 (83%)]\tLoss: 0.000713\n","Train Epoch: 9 [129920/155326 (84%)]\tLoss: 0.001783\n","Train Epoch: 9 [130560/155326 (84%)]\tLoss: 0.001400\n","Train Epoch: 9 [131200/155326 (84%)]\tLoss: 0.001279\n","Train Epoch: 9 [131840/155326 (85%)]\tLoss: 0.000650\n","Train Epoch: 9 [132480/155326 (85%)]\tLoss: 0.000416\n","Train Epoch: 9 [133120/155326 (86%)]\tLoss: 0.000777\n","Train Epoch: 9 [133760/155326 (86%)]\tLoss: 0.002873\n","Train Epoch: 9 [134400/155326 (87%)]\tLoss: 0.000838\n","Train Epoch: 9 [135040/155326 (87%)]\tLoss: 0.000811\n","Train Epoch: 9 [135680/155326 (87%)]\tLoss: 0.001145\n","Train Epoch: 9 [136320/155326 (88%)]\tLoss: 0.000134\n","Train Epoch: 9 [136960/155326 (88%)]\tLoss: 0.000525\n","Train Epoch: 9 [137600/155326 (89%)]\tLoss: 0.000131\n","Train Epoch: 9 [138240/155326 (89%)]\tLoss: 0.001937\n","Train Epoch: 9 [138880/155326 (89%)]\tLoss: 0.001200\n","Train Epoch: 9 [139520/155326 (90%)]\tLoss: 0.002568\n","Train Epoch: 9 [140160/155326 (90%)]\tLoss: 0.000559\n","Train Epoch: 9 [140800/155326 (91%)]\tLoss: 0.001148\n","Train Epoch: 9 [141440/155326 (91%)]\tLoss: 0.001225\n","Train Epoch: 9 [142080/155326 (91%)]\tLoss: 0.000652\n","Train Epoch: 9 [142720/155326 (92%)]\tLoss: 0.001816\n","Train Epoch: 9 [143360/155326 (92%)]\tLoss: 0.000480\n","Train Epoch: 9 [144000/155326 (93%)]\tLoss: 0.001525\n","Train Epoch: 9 [144640/155326 (93%)]\tLoss: 0.000670\n","Train Epoch: 9 [145280/155326 (94%)]\tLoss: 0.000413\n","Train Epoch: 9 [145920/155326 (94%)]\tLoss: 0.000434\n","Train Epoch: 9 [146560/155326 (94%)]\tLoss: 0.000358\n","Train Epoch: 9 [147200/155326 (95%)]\tLoss: 0.000766\n","Train Epoch: 9 [147840/155326 (95%)]\tLoss: 0.002433\n","Train Epoch: 9 [148480/155326 (96%)]\tLoss: 0.000661\n","Train Epoch: 9 [149120/155326 (96%)]\tLoss: 0.001329\n","Train Epoch: 9 [149760/155326 (96%)]\tLoss: 0.000480\n","Train Epoch: 9 [150400/155326 (97%)]\tLoss: 0.000342\n","Train Epoch: 9 [151040/155326 (97%)]\tLoss: 0.000564\n","Train Epoch: 9 [151680/155326 (98%)]\tLoss: 0.000086\n","Train Epoch: 9 [152320/155326 (98%)]\tLoss: 0.000739\n","Train Epoch: 9 [152960/155326 (98%)]\tLoss: 0.000202\n","Train Epoch: 9 [153600/155326 (99%)]\tLoss: 0.002378\n","Train Epoch: 9 [154240/155326 (99%)]\tLoss: 0.000782\n","Train Epoch: 9 [154880/155326 (100%)]\tLoss: 0.000658\n","Sample outputs (log probs): tensor([[-2.6173e+01, -1.8753e+01, -1.6234e+01, -1.1191e+01, -2.7851e+01,\n","         -2.5157e+01, -1.9912e+01, -1.6255e+01, -1.6446e+01, -9.8968e+00,\n","         -2.1295e+01, -1.3296e+01, -1.6787e+01, -1.0633e+01, -1.0885e+01,\n","         -1.8615e+01, -1.2636e+01, -2.8746e+01, -1.7081e+01, -1.9272e+01,\n","         -1.5985e-03, -6.5584e+00, -1.1564e+01, -2.1399e+01, -9.7632e+00,\n","         -2.4004e+01],\n","        [-2.5495e+01, -2.0165e+01, -2.0776e+01, -2.1330e+01, -1.8733e+01,\n","         -2.1800e+01, -2.4394e+01, -2.9185e+01, -9.4590e+00, -2.2921e+01,\n","         -2.1822e+01, -1.1822e+01, -3.0874e+01, -2.6931e+01, -3.2683e+01,\n","         -2.3403e+01, -2.7966e+01, -1.6628e+01, -2.8267e+01, -1.7648e+01,\n","         -1.8657e+01, -2.6467e+01, -3.0833e+01, -1.0455e+01, -2.0248e+01,\n","         -1.1432e-04],\n","        [-1.7545e+01, -1.5218e+01, -2.4394e+01, -2.8346e+01, -2.1395e+01,\n","         -2.0304e+01, -2.3003e+01, -2.6271e+01, -2.9493e+01, -4.1522e+01,\n","         -1.6859e+01, -2.9837e+01, -2.8376e+01, -2.6667e+01, -3.3339e+01,\n","         -1.5537e+01, -1.6980e+01, -5.9605e-07, -3.0333e+01, -2.7396e+01,\n","         -2.9821e+01, -3.7173e+01, -3.2562e+01, -2.6354e+01, -3.1345e+01,\n","         -2.1351e+01],\n","        [-2.7877e+01, -1.8689e+01, -2.0416e+01, -1.8301e+01, -1.6649e+01,\n","         -1.0738e+01, -1.9989e+01, -3.3377e+01, -1.5335e+01, -7.0268e+00,\n","         -3.1156e+01, -2.4923e+01, -3.6284e+01, -3.3497e+01, -2.1452e+01,\n","         -2.3993e+01, -2.1335e+01, -3.7311e+01, -9.1011e-04, -2.2055e+01,\n","         -2.7974e+01, -3.1500e+01, -3.5556e+01, -2.6526e+01, -1.8286e+01,\n","         -2.4307e+01],\n","        [-1.1190e+01, -2.0257e+01, -2.5886e+01, -2.1131e+01, -2.9242e+01,\n","         -2.6869e+01, -1.6830e+01, -3.9016e+00, -2.1820e+01, -2.5169e+01,\n","         -1.0730e+01, -2.1623e+01, -2.0492e-02, -1.0238e+01, -2.2933e+01,\n","         -2.1618e+01, -2.3676e+01, -1.8923e+01, -2.5739e+01, -2.2191e+01,\n","         -1.4343e+01, -1.7687e+01, -1.3517e+01, -1.7905e+01, -1.3916e+01,\n","         -2.5824e+01]], device='cuda:0')\n","Predicted classes: tensor([20, 25, 17, 18, 12], device='cuda:0')\n","Target classes: tensor([20, 25, 17, 18, 12], device='cuda:0')\n","\n","Test set: Average loss: 0.001679, Total sum loss: 0.510359, Accuracy: 37864/38832 (98%)\n","\n","Class A: 1307/1336 (98%)\n","Class B: 806/819 (98%)\n","Class C: 2012/2059 (98%)\n","Class D: 867/922 (94%)\n","Class E: 986/996 (99%)\n","Class F: 1814/1861 (97%)\n","Class G: 536/551 (97%)\n","Class H: 682/709 (96%)\n","Class I: 2389/2438 (98%)\n","Class J: 760/772 (98%)\n","Class K: 549/566 (97%)\n","Class L: 960/986 (97%)\n","Class M: 1824/1851 (99%)\n","Class N: 1596/1636 (98%)\n","Class O: 4907/5060 (97%)\n","Class P: 1751/1781 (98%)\n","Class Q: 569/589 (97%)\n","Class R: 1026/1056 (97%)\n","Class S: 4160/4209 (99%)\n","Class T: 1928/1960 (98%)\n","Class U: 2467/2562 (96%)\n","Class V: 927/988 (94%)\n","Class W: 963/990 (97%)\n","Class X: 579/601 (96%)\n","Class Y: 991/1022 (97%)\n","Class Z: 508/512 (99%)\n","Model saved with new best test loss: 0.0017 \n","\n","Train Epoch: 10 [0/155326 (0%)]\tLoss: 0.000612\n","Train Epoch: 10 [640/155326 (0%)]\tLoss: 0.000559\n","Train Epoch: 10 [1280/155326 (1%)]\tLoss: 0.000375\n","Train Epoch: 10 [1920/155326 (1%)]\tLoss: 0.000296\n","Train Epoch: 10 [2560/155326 (2%)]\tLoss: 0.000202\n","Train Epoch: 10 [3200/155326 (2%)]\tLoss: 0.001213\n","Train Epoch: 10 [3840/155326 (2%)]\tLoss: 0.000195\n","Train Epoch: 10 [4480/155326 (3%)]\tLoss: 0.000889\n","Train Epoch: 10 [5120/155326 (3%)]\tLoss: 0.000133\n","Train Epoch: 10 [5760/155326 (4%)]\tLoss: 0.002283\n","Train Epoch: 10 [6400/155326 (4%)]\tLoss: 0.001158\n","Train Epoch: 10 [7040/155326 (5%)]\tLoss: 0.000104\n","Train Epoch: 10 [7680/155326 (5%)]\tLoss: 0.001113\n","Train Epoch: 10 [8320/155326 (5%)]\tLoss: 0.000330\n","Train Epoch: 10 [8960/155326 (6%)]\tLoss: 0.000711\n","Train Epoch: 10 [9600/155326 (6%)]\tLoss: 0.000278\n","Train Epoch: 10 [10240/155326 (7%)]\tLoss: 0.000248\n","Train Epoch: 10 [10880/155326 (7%)]\tLoss: 0.000201\n","Train Epoch: 10 [11520/155326 (7%)]\tLoss: 0.002493\n","Train Epoch: 10 [12160/155326 (8%)]\tLoss: 0.000466\n","Train Epoch: 10 [12800/155326 (8%)]\tLoss: 0.001120\n","Train Epoch: 10 [13440/155326 (9%)]\tLoss: 0.001124\n","Train Epoch: 10 [14080/155326 (9%)]\tLoss: 0.001620\n","Train Epoch: 10 [14720/155326 (9%)]\tLoss: 0.000207\n","Train Epoch: 10 [15360/155326 (10%)]\tLoss: 0.001435\n","Train Epoch: 10 [16000/155326 (10%)]\tLoss: 0.000222\n","Train Epoch: 10 [16640/155326 (11%)]\tLoss: 0.000762\n","Train Epoch: 10 [17280/155326 (11%)]\tLoss: 0.001093\n","Train Epoch: 10 [17920/155326 (12%)]\tLoss: 0.000652\n","Train Epoch: 10 [18560/155326 (12%)]\tLoss: 0.000718\n","Train Epoch: 10 [19200/155326 (12%)]\tLoss: 0.000835\n","Train Epoch: 10 [19840/155326 (13%)]\tLoss: 0.000570\n","Train Epoch: 10 [20480/155326 (13%)]\tLoss: 0.001729\n","Train Epoch: 10 [21120/155326 (14%)]\tLoss: 0.000839\n","Train Epoch: 10 [21760/155326 (14%)]\tLoss: 0.001037\n","Train Epoch: 10 [22400/155326 (14%)]\tLoss: 0.000382\n","Train Epoch: 10 [23040/155326 (15%)]\tLoss: 0.000173\n","Train Epoch: 10 [23680/155326 (15%)]\tLoss: 0.000625\n","Train Epoch: 10 [24320/155326 (16%)]\tLoss: 0.000316\n","Train Epoch: 10 [24960/155326 (16%)]\tLoss: 0.000167\n","Train Epoch: 10 [25600/155326 (16%)]\tLoss: 0.001243\n","Train Epoch: 10 [26240/155326 (17%)]\tLoss: 0.000587\n","Train Epoch: 10 [26880/155326 (17%)]\tLoss: 0.000337\n","Train Epoch: 10 [27520/155326 (18%)]\tLoss: 0.000604\n","Train Epoch: 10 [28160/155326 (18%)]\tLoss: 0.000364\n","Train Epoch: 10 [28800/155326 (19%)]\tLoss: 0.000995\n","Train Epoch: 10 [29440/155326 (19%)]\tLoss: 0.000491\n","Train Epoch: 10 [30080/155326 (19%)]\tLoss: 0.001334\n","Train Epoch: 10 [30720/155326 (20%)]\tLoss: 0.000152\n","Train Epoch: 10 [31360/155326 (20%)]\tLoss: 0.001236\n","Train Epoch: 10 [32000/155326 (21%)]\tLoss: 0.001276\n","Train Epoch: 10 [32640/155326 (21%)]\tLoss: 0.000743\n","Train Epoch: 10 [33280/155326 (21%)]\tLoss: 0.001226\n","Train Epoch: 10 [33920/155326 (22%)]\tLoss: 0.001089\n","Train Epoch: 10 [34560/155326 (22%)]\tLoss: 0.000995\n","Train Epoch: 10 [35200/155326 (23%)]\tLoss: 0.000552\n","Train Epoch: 10 [35840/155326 (23%)]\tLoss: 0.000961\n","Train Epoch: 10 [36480/155326 (23%)]\tLoss: 0.001062\n","Train Epoch: 10 [37120/155326 (24%)]\tLoss: 0.000324\n","Train Epoch: 10 [37760/155326 (24%)]\tLoss: 0.000677\n","Train Epoch: 10 [38400/155326 (25%)]\tLoss: 0.002058\n","Train Epoch: 10 [39040/155326 (25%)]\tLoss: 0.001459\n","Train Epoch: 10 [39680/155326 (26%)]\tLoss: 0.000988\n","Train Epoch: 10 [40320/155326 (26%)]\tLoss: 0.000657\n","Train Epoch: 10 [40960/155326 (26%)]\tLoss: 0.002739\n","Train Epoch: 10 [41600/155326 (27%)]\tLoss: 0.000476\n","Train Epoch: 10 [42240/155326 (27%)]\tLoss: 0.000434\n","Train Epoch: 10 [42880/155326 (28%)]\tLoss: 0.000693\n","Train Epoch: 10 [43520/155326 (28%)]\tLoss: 0.001074\n","Train Epoch: 10 [44160/155326 (28%)]\tLoss: 0.001412\n","Train Epoch: 10 [44800/155326 (29%)]\tLoss: 0.000550\n","Train Epoch: 10 [45440/155326 (29%)]\tLoss: 0.000478\n","Train Epoch: 10 [46080/155326 (30%)]\tLoss: 0.000434\n","Train Epoch: 10 [46720/155326 (30%)]\tLoss: 0.002072\n","Train Epoch: 10 [47360/155326 (30%)]\tLoss: 0.002454\n","Train Epoch: 10 [48000/155326 (31%)]\tLoss: 0.000241\n","Train Epoch: 10 [48640/155326 (31%)]\tLoss: 0.000403\n","Train Epoch: 10 [49280/155326 (32%)]\tLoss: 0.002461\n","Train Epoch: 10 [49920/155326 (32%)]\tLoss: 0.001804\n","Train Epoch: 10 [50560/155326 (33%)]\tLoss: 0.000392\n","Train Epoch: 10 [51200/155326 (33%)]\tLoss: 0.001506\n","Train Epoch: 10 [51840/155326 (33%)]\tLoss: 0.000757\n","Train Epoch: 10 [52480/155326 (34%)]\tLoss: 0.000641\n","Train Epoch: 10 [53120/155326 (34%)]\tLoss: 0.000582\n","Train Epoch: 10 [53760/155326 (35%)]\tLoss: 0.000747\n","Train Epoch: 10 [54400/155326 (35%)]\tLoss: 0.000322\n","Train Epoch: 10 [55040/155326 (35%)]\tLoss: 0.001552\n","Train Epoch: 10 [55680/155326 (36%)]\tLoss: 0.001205\n","Train Epoch: 10 [56320/155326 (36%)]\tLoss: 0.000242\n","Train Epoch: 10 [56960/155326 (37%)]\tLoss: 0.001014\n","Train Epoch: 10 [57600/155326 (37%)]\tLoss: 0.000561\n","Train Epoch: 10 [58240/155326 (37%)]\tLoss: 0.001221\n","Train Epoch: 10 [58880/155326 (38%)]\tLoss: 0.000168\n","Train Epoch: 10 [59520/155326 (38%)]\tLoss: 0.001049\n","Train Epoch: 10 [60160/155326 (39%)]\tLoss: 0.000297\n","Train Epoch: 10 [60800/155326 (39%)]\tLoss: 0.000450\n","Train Epoch: 10 [61440/155326 (40%)]\tLoss: 0.000610\n","Train Epoch: 10 [62080/155326 (40%)]\tLoss: 0.001749\n","Train Epoch: 10 [62720/155326 (40%)]\tLoss: 0.000490\n","Train Epoch: 10 [63360/155326 (41%)]\tLoss: 0.000644\n","Train Epoch: 10 [64000/155326 (41%)]\tLoss: 0.000272\n","Train Epoch: 10 [64640/155326 (42%)]\tLoss: 0.000443\n","Train Epoch: 10 [65280/155326 (42%)]\tLoss: 0.000457\n","Train Epoch: 10 [65920/155326 (42%)]\tLoss: 0.001081\n","Train Epoch: 10 [66560/155326 (43%)]\tLoss: 0.001952\n","Train Epoch: 10 [67200/155326 (43%)]\tLoss: 0.000821\n","Train Epoch: 10 [67840/155326 (44%)]\tLoss: 0.000378\n","Train Epoch: 10 [68480/155326 (44%)]\tLoss: 0.000306\n","Train Epoch: 10 [69120/155326 (44%)]\tLoss: 0.000581\n","Train Epoch: 10 [69760/155326 (45%)]\tLoss: 0.000638\n","Train Epoch: 10 [70400/155326 (45%)]\tLoss: 0.002289\n","Train Epoch: 10 [71040/155326 (46%)]\tLoss: 0.000691\n","Train Epoch: 10 [71680/155326 (46%)]\tLoss: 0.001142\n","Train Epoch: 10 [72320/155326 (47%)]\tLoss: 0.000227\n","Train Epoch: 10 [72960/155326 (47%)]\tLoss: 0.007411\n","Train Epoch: 10 [73600/155326 (47%)]\tLoss: 0.000874\n","Train Epoch: 10 [74240/155326 (48%)]\tLoss: 0.000398\n","Train Epoch: 10 [74880/155326 (48%)]\tLoss: 0.000338\n","Train Epoch: 10 [75520/155326 (49%)]\tLoss: 0.000211\n","Train Epoch: 10 [76160/155326 (49%)]\tLoss: 0.000598\n","Train Epoch: 10 [76800/155326 (49%)]\tLoss: 0.001304\n","Train Epoch: 10 [77440/155326 (50%)]\tLoss: 0.001373\n","Train Epoch: 10 [78080/155326 (50%)]\tLoss: 0.000609\n","Train Epoch: 10 [78720/155326 (51%)]\tLoss: 0.000362\n","Train Epoch: 10 [79360/155326 (51%)]\tLoss: 0.000834\n","Train Epoch: 10 [80000/155326 (52%)]\tLoss: 0.000276\n","Train Epoch: 10 [80640/155326 (52%)]\tLoss: 0.001511\n","Train Epoch: 10 [81280/155326 (52%)]\tLoss: 0.001053\n","Train Epoch: 10 [81920/155326 (53%)]\tLoss: 0.000961\n","Train Epoch: 10 [82560/155326 (53%)]\tLoss: 0.001132\n","Train Epoch: 10 [83200/155326 (54%)]\tLoss: 0.000637\n","Train Epoch: 10 [83840/155326 (54%)]\tLoss: 0.001006\n","Train Epoch: 10 [84480/155326 (54%)]\tLoss: 0.000547\n","Train Epoch: 10 [85120/155326 (55%)]\tLoss: 0.000171\n","Train Epoch: 10 [85760/155326 (55%)]\tLoss: 0.001843\n","Train Epoch: 10 [86400/155326 (56%)]\tLoss: 0.001029\n","Train Epoch: 10 [87040/155326 (56%)]\tLoss: 0.000883\n","Train Epoch: 10 [87680/155326 (56%)]\tLoss: 0.000317\n","Train Epoch: 10 [88320/155326 (57%)]\tLoss: 0.000702\n","Train Epoch: 10 [88960/155326 (57%)]\tLoss: 0.000719\n","Train Epoch: 10 [89600/155326 (58%)]\tLoss: 0.000444\n","Train Epoch: 10 [90240/155326 (58%)]\tLoss: 0.000393\n","Train Epoch: 10 [90880/155326 (59%)]\tLoss: 0.001636\n","Train Epoch: 10 [91520/155326 (59%)]\tLoss: 0.000993\n","Train Epoch: 10 [92160/155326 (59%)]\tLoss: 0.001106\n","Train Epoch: 10 [92800/155326 (60%)]\tLoss: 0.000348\n","Train Epoch: 10 [93440/155326 (60%)]\tLoss: 0.000513\n","Train Epoch: 10 [94080/155326 (61%)]\tLoss: 0.000675\n","Train Epoch: 10 [94720/155326 (61%)]\tLoss: 0.000591\n","Train Epoch: 10 [95360/155326 (61%)]\tLoss: 0.000450\n","Train Epoch: 10 [96000/155326 (62%)]\tLoss: 0.000741\n","Train Epoch: 10 [96640/155326 (62%)]\tLoss: 0.000320\n","Train Epoch: 10 [97280/155326 (63%)]\tLoss: 0.000500\n","Train Epoch: 10 [97920/155326 (63%)]\tLoss: 0.000650\n","Train Epoch: 10 [98560/155326 (63%)]\tLoss: 0.001230\n","Train Epoch: 10 [99200/155326 (64%)]\tLoss: 0.000673\n","Train Epoch: 10 [99840/155326 (64%)]\tLoss: 0.000399\n","Train Epoch: 10 [100480/155326 (65%)]\tLoss: 0.001467\n","Train Epoch: 10 [101120/155326 (65%)]\tLoss: 0.000308\n","Train Epoch: 10 [101760/155326 (66%)]\tLoss: 0.000142\n","Train Epoch: 10 [102400/155326 (66%)]\tLoss: 0.000780\n","Train Epoch: 10 [103040/155326 (66%)]\tLoss: 0.000916\n","Train Epoch: 10 [103680/155326 (67%)]\tLoss: 0.000359\n","Train Epoch: 10 [104320/155326 (67%)]\tLoss: 0.000300\n","Train Epoch: 10 [104960/155326 (68%)]\tLoss: 0.001182\n","Train Epoch: 10 [105600/155326 (68%)]\tLoss: 0.000626\n","Train Epoch: 10 [106240/155326 (68%)]\tLoss: 0.000533\n","Train Epoch: 10 [106880/155326 (69%)]\tLoss: 0.001106\n","Train Epoch: 10 [107520/155326 (69%)]\tLoss: 0.003222\n","Train Epoch: 10 [108160/155326 (70%)]\tLoss: 0.000309\n","Train Epoch: 10 [108800/155326 (70%)]\tLoss: 0.000695\n","Train Epoch: 10 [109440/155326 (70%)]\tLoss: 0.000194\n","Train Epoch: 10 [110080/155326 (71%)]\tLoss: 0.000460\n","Train Epoch: 10 [110720/155326 (71%)]\tLoss: 0.000515\n","Train Epoch: 10 [111360/155326 (72%)]\tLoss: 0.001962\n","Train Epoch: 10 [112000/155326 (72%)]\tLoss: 0.001499\n","Train Epoch: 10 [112640/155326 (73%)]\tLoss: 0.000891\n","Train Epoch: 10 [113280/155326 (73%)]\tLoss: 0.000310\n","Train Epoch: 10 [113920/155326 (73%)]\tLoss: 0.000907\n","Train Epoch: 10 [114560/155326 (74%)]\tLoss: 0.001046\n","Train Epoch: 10 [115200/155326 (74%)]\tLoss: 0.001224\n","Train Epoch: 10 [115840/155326 (75%)]\tLoss: 0.001110\n","Train Epoch: 10 [116480/155326 (75%)]\tLoss: 0.000987\n","Train Epoch: 10 [117120/155326 (75%)]\tLoss: 0.000439\n","Train Epoch: 10 [117760/155326 (76%)]\tLoss: 0.000993\n","Train Epoch: 10 [118400/155326 (76%)]\tLoss: 0.000599\n","Train Epoch: 10 [119040/155326 (77%)]\tLoss: 0.001301\n","Train Epoch: 10 [119680/155326 (77%)]\tLoss: 0.000255\n","Train Epoch: 10 [120320/155326 (77%)]\tLoss: 0.000640\n","Train Epoch: 10 [120960/155326 (78%)]\tLoss: 0.001230\n","Train Epoch: 10 [121600/155326 (78%)]\tLoss: 0.000725\n","Train Epoch: 10 [122240/155326 (79%)]\tLoss: 0.000320\n","Train Epoch: 10 [122880/155326 (79%)]\tLoss: 0.000411\n","Train Epoch: 10 [123520/155326 (80%)]\tLoss: 0.002389\n","Train Epoch: 10 [124160/155326 (80%)]\tLoss: 0.000454\n","Train Epoch: 10 [124800/155326 (80%)]\tLoss: 0.001333\n","Train Epoch: 10 [125440/155326 (81%)]\tLoss: 0.000570\n","Train Epoch: 10 [126080/155326 (81%)]\tLoss: 0.000555\n","Train Epoch: 10 [126720/155326 (82%)]\tLoss: 0.000384\n","Train Epoch: 10 [127360/155326 (82%)]\tLoss: 0.000209\n","Train Epoch: 10 [128000/155326 (82%)]\tLoss: 0.003336\n","Train Epoch: 10 [128640/155326 (83%)]\tLoss: 0.000896\n","Train Epoch: 10 [129280/155326 (83%)]\tLoss: 0.000723\n","Train Epoch: 10 [129920/155326 (84%)]\tLoss: 0.000407\n","Train Epoch: 10 [130560/155326 (84%)]\tLoss: 0.000090\n","Train Epoch: 10 [131200/155326 (84%)]\tLoss: 0.000434\n","Train Epoch: 10 [131840/155326 (85%)]\tLoss: 0.000225\n","Train Epoch: 10 [132480/155326 (85%)]\tLoss: 0.002025\n","Train Epoch: 10 [133120/155326 (86%)]\tLoss: 0.000496\n","Train Epoch: 10 [133760/155326 (86%)]\tLoss: 0.000358\n","Train Epoch: 10 [134400/155326 (87%)]\tLoss: 0.001745\n","Train Epoch: 10 [135040/155326 (87%)]\tLoss: 0.001554\n","Train Epoch: 10 [135680/155326 (87%)]\tLoss: 0.000689\n","Train Epoch: 10 [136320/155326 (88%)]\tLoss: 0.001201\n","Train Epoch: 10 [136960/155326 (88%)]\tLoss: 0.005120\n","Train Epoch: 10 [137600/155326 (89%)]\tLoss: 0.000377\n","Train Epoch: 10 [138240/155326 (89%)]\tLoss: 0.000388\n","Train Epoch: 10 [138880/155326 (89%)]\tLoss: 0.000170\n","Train Epoch: 10 [139520/155326 (90%)]\tLoss: 0.000142\n","Train Epoch: 10 [140160/155326 (90%)]\tLoss: 0.000883\n","Train Epoch: 10 [140800/155326 (91%)]\tLoss: 0.003722\n","Train Epoch: 10 [141440/155326 (91%)]\tLoss: 0.001816\n","Train Epoch: 10 [142080/155326 (91%)]\tLoss: 0.000410\n","Train Epoch: 10 [142720/155326 (92%)]\tLoss: 0.000291\n","Train Epoch: 10 [143360/155326 (92%)]\tLoss: 0.000139\n","Train Epoch: 10 [144000/155326 (93%)]\tLoss: 0.000931\n","Train Epoch: 10 [144640/155326 (93%)]\tLoss: 0.000435\n","Train Epoch: 10 [145280/155326 (94%)]\tLoss: 0.001084\n","Train Epoch: 10 [145920/155326 (94%)]\tLoss: 0.000195\n","Train Epoch: 10 [146560/155326 (94%)]\tLoss: 0.000166\n","Train Epoch: 10 [147200/155326 (95%)]\tLoss: 0.000858\n","Train Epoch: 10 [147840/155326 (95%)]\tLoss: 0.000423\n","Train Epoch: 10 [148480/155326 (96%)]\tLoss: 0.000725\n","Train Epoch: 10 [149120/155326 (96%)]\tLoss: 0.000385\n","Train Epoch: 10 [149760/155326 (96%)]\tLoss: 0.000235\n","Train Epoch: 10 [150400/155326 (97%)]\tLoss: 0.000615\n","Train Epoch: 10 [151040/155326 (97%)]\tLoss: 0.000339\n","Train Epoch: 10 [151680/155326 (98%)]\tLoss: 0.000345\n","Train Epoch: 10 [152320/155326 (98%)]\tLoss: 0.000366\n","Train Epoch: 10 [152960/155326 (98%)]\tLoss: 0.000653\n","Train Epoch: 10 [153600/155326 (99%)]\tLoss: 0.000254\n","Train Epoch: 10 [154240/155326 (99%)]\tLoss: 0.000309\n","Train Epoch: 10 [154880/155326 (100%)]\tLoss: 0.000454\n","Sample outputs (log probs): tensor([[-2.4206e+01, -2.3721e+01, -1.9187e+01, -1.1513e+01, -3.3720e+01,\n","         -2.5972e+01, -2.6865e+01, -1.3406e+01, -1.3040e+01, -1.2081e+01,\n","         -2.3133e+01, -1.7053e+01, -1.4197e+01, -5.3119e+00, -1.4891e+01,\n","         -1.5374e+01, -1.9513e+01, -2.9101e+01, -2.4535e+01, -1.6786e+01,\n","         -1.7460e+00, -1.9803e-01, -8.5158e+00, -1.9175e+01, -1.0720e+01,\n","         -2.3031e+01],\n","        [-2.8105e+01, -2.3137e+01, -1.9519e+01, -1.4692e+01, -3.3829e+01,\n","         -2.8777e+01, -2.4489e+01, -1.6079e+01, -1.9220e+01, -1.1804e+01,\n","         -2.4454e+01, -1.7481e+01, -1.8352e+01, -1.1320e+01, -1.3208e+01,\n","         -1.9861e+01, -1.7107e+01, -3.3525e+01, -2.1255e+01, -2.2136e+01,\n","         -4.9586e-03, -5.3149e+00, -1.2307e+01, -2.4893e+01, -1.3137e+01,\n","         -2.9018e+01],\n","        [-1.5221e+01, -2.2961e+01, -1.9511e+01, -2.2602e+01, -1.7620e+01,\n","         -1.1325e-05, -1.4506e+01, -1.7356e+01, -1.3541e+01, -1.4660e+01,\n","         -2.0594e+01, -1.5967e+01, -2.8398e+01, -2.3883e+01, -2.5967e+01,\n","         -1.4490e+01, -1.8635e+01, -2.1227e+01, -1.3331e+01, -1.1951e+01,\n","         -2.0780e+01, -1.9610e+01, -2.3382e+01, -1.9271e+01, -1.7951e+01,\n","         -1.9774e+01],\n","        [-1.6583e+01, -1.8203e+01, -1.5718e+01, -1.5186e+01, -2.4503e+01,\n","         -2.6289e+01, -1.3676e+01, -6.2782e+00, -1.3555e+01, -1.1562e+01,\n","         -9.5790e+00, -1.2361e+01, -6.4202e+00, -3.9492e+00, -1.5340e+01,\n","         -1.9894e+01, -1.4637e+01, -2.1547e+01, -2.0796e+01, -1.7473e+01,\n","         -6.3747e-02, -4.5113e+00, -3.5797e+00, -1.2231e+01, -1.0746e+01,\n","         -2.2142e+01],\n","        [-1.3884e+01, -1.5168e+01, -9.3353e+00, -6.7539e+00, -1.2624e+01,\n","         -5.4347e+00, -1.6839e+01, -1.9034e+01, -3.0441e-02, -9.3648e+00,\n","         -1.6835e+01, -1.3535e+01, -1.6146e+01, -1.0411e+01, -8.0040e+00,\n","         -3.9580e+00, -1.2856e+01, -1.3904e+01, -8.5711e+00, -5.7694e+00,\n","         -1.3449e+01, -6.5930e+00, -1.8129e+01, -1.5142e+01, -9.0127e+00,\n","         -1.6196e+01]], device='cuda:0')\n","Predicted classes: tensor([21, 20,  5, 20,  8], device='cuda:0')\n","Target classes: tensor([21, 20,  5, 20,  8], device='cuda:0')\n","\n","Test set: Average loss: 0.001628, Total sum loss: 0.495008, Accuracy: 37905/38832 (98%)\n","\n","Class A: 1314/1336 (98%)\n","Class B: 801/819 (98%)\n","Class C: 2004/2059 (97%)\n","Class D: 863/922 (94%)\n","Class E: 980/996 (98%)\n","Class F: 1803/1861 (97%)\n","Class G: 538/551 (98%)\n","Class H: 679/709 (96%)\n","Class I: 2390/2438 (98%)\n","Class J: 758/772 (98%)\n","Class K: 551/566 (97%)\n","Class L: 966/986 (98%)\n","Class M: 1825/1851 (99%)\n","Class N: 1601/1636 (98%)\n","Class O: 4950/5060 (98%)\n","Class P: 1755/1781 (99%)\n","Class Q: 572/589 (97%)\n","Class R: 1030/1056 (98%)\n","Class S: 4170/4209 (99%)\n","Class T: 1930/1960 (98%)\n","Class U: 2454/2562 (96%)\n","Class V: 940/988 (95%)\n","Class W: 963/990 (97%)\n","Class X: 580/601 (97%)\n","Class Y: 983/1022 (96%)\n","Class Z: 505/512 (99%)\n","Model saved with new best test loss: 0.0016 \n","\n","Train Epoch: 11 [0/155326 (0%)]\tLoss: 0.003394\n","Train Epoch: 11 [640/155326 (0%)]\tLoss: 0.001126\n","Train Epoch: 11 [1280/155326 (1%)]\tLoss: 0.000356\n","Train Epoch: 11 [1920/155326 (1%)]\tLoss: 0.002140\n","Train Epoch: 11 [2560/155326 (2%)]\tLoss: 0.002669\n","Train Epoch: 11 [3200/155326 (2%)]\tLoss: 0.000422\n","Train Epoch: 11 [3840/155326 (2%)]\tLoss: 0.000687\n","Train Epoch: 11 [4480/155326 (3%)]\tLoss: 0.001146\n","Train Epoch: 11 [5120/155326 (3%)]\tLoss: 0.000494\n","Train Epoch: 11 [5760/155326 (4%)]\tLoss: 0.000591\n","Train Epoch: 11 [6400/155326 (4%)]\tLoss: 0.000601\n","Train Epoch: 11 [7040/155326 (5%)]\tLoss: 0.000656\n","Train Epoch: 11 [7680/155326 (5%)]\tLoss: 0.002283\n","Train Epoch: 11 [8320/155326 (5%)]\tLoss: 0.002068\n","Train Epoch: 11 [8960/155326 (6%)]\tLoss: 0.002510\n","Train Epoch: 11 [9600/155326 (6%)]\tLoss: 0.001525\n","Train Epoch: 11 [10240/155326 (7%)]\tLoss: 0.000745\n","Train Epoch: 11 [10880/155326 (7%)]\tLoss: 0.000379\n","Train Epoch: 11 [11520/155326 (7%)]\tLoss: 0.000510\n","Train Epoch: 11 [12160/155326 (8%)]\tLoss: 0.000248\n","Train Epoch: 11 [12800/155326 (8%)]\tLoss: 0.000714\n","Train Epoch: 11 [13440/155326 (9%)]\tLoss: 0.000415\n","Train Epoch: 11 [14080/155326 (9%)]\tLoss: 0.001241\n","Train Epoch: 11 [14720/155326 (9%)]\tLoss: 0.000297\n","Train Epoch: 11 [15360/155326 (10%)]\tLoss: 0.000843\n","Train Epoch: 11 [16000/155326 (10%)]\tLoss: 0.000863\n","Train Epoch: 11 [16640/155326 (11%)]\tLoss: 0.000545\n","Train Epoch: 11 [17280/155326 (11%)]\tLoss: 0.001080\n","Train Epoch: 11 [17920/155326 (12%)]\tLoss: 0.000379\n","Train Epoch: 11 [18560/155326 (12%)]\tLoss: 0.000410\n","Train Epoch: 11 [19200/155326 (12%)]\tLoss: 0.001605\n","Train Epoch: 11 [19840/155326 (13%)]\tLoss: 0.001023\n","Train Epoch: 11 [20480/155326 (13%)]\tLoss: 0.000570\n","Train Epoch: 11 [21120/155326 (14%)]\tLoss: 0.000833\n","Train Epoch: 11 [21760/155326 (14%)]\tLoss: 0.001838\n","Train Epoch: 11 [22400/155326 (14%)]\tLoss: 0.000596\n","Train Epoch: 11 [23040/155326 (15%)]\tLoss: 0.000096\n","Train Epoch: 11 [23680/155326 (15%)]\tLoss: 0.000337\n","Train Epoch: 11 [24320/155326 (16%)]\tLoss: 0.001188\n","Train Epoch: 11 [24960/155326 (16%)]\tLoss: 0.000311\n","Train Epoch: 11 [25600/155326 (16%)]\tLoss: 0.000675\n","Train Epoch: 11 [26240/155326 (17%)]\tLoss: 0.000304\n","Train Epoch: 11 [26880/155326 (17%)]\tLoss: 0.000378\n","Train Epoch: 11 [27520/155326 (18%)]\tLoss: 0.000327\n","Train Epoch: 11 [28160/155326 (18%)]\tLoss: 0.000314\n","Train Epoch: 11 [28800/155326 (19%)]\tLoss: 0.001977\n","Train Epoch: 11 [29440/155326 (19%)]\tLoss: 0.000757\n","Train Epoch: 11 [30080/155326 (19%)]\tLoss: 0.000151\n","Train Epoch: 11 [30720/155326 (20%)]\tLoss: 0.001220\n","Train Epoch: 11 [31360/155326 (20%)]\tLoss: 0.000336\n","Train Epoch: 11 [32000/155326 (21%)]\tLoss: 0.000201\n","Train Epoch: 11 [32640/155326 (21%)]\tLoss: 0.000402\n","Train Epoch: 11 [33280/155326 (21%)]\tLoss: 0.000454\n","Train Epoch: 11 [33920/155326 (22%)]\tLoss: 0.001394\n","Train Epoch: 11 [34560/155326 (22%)]\tLoss: 0.000372\n","Train Epoch: 11 [35200/155326 (23%)]\tLoss: 0.000130\n","Train Epoch: 11 [35840/155326 (23%)]\tLoss: 0.000113\n","Train Epoch: 11 [36480/155326 (23%)]\tLoss: 0.000854\n","Train Epoch: 11 [37120/155326 (24%)]\tLoss: 0.000439\n","Train Epoch: 11 [37760/155326 (24%)]\tLoss: 0.000936\n","Train Epoch: 11 [38400/155326 (25%)]\tLoss: 0.001401\n","Train Epoch: 11 [39040/155326 (25%)]\tLoss: 0.001053\n","Train Epoch: 11 [39680/155326 (26%)]\tLoss: 0.000836\n","Train Epoch: 11 [40320/155326 (26%)]\tLoss: 0.001009\n","Train Epoch: 11 [40960/155326 (26%)]\tLoss: 0.000986\n","Train Epoch: 11 [41600/155326 (27%)]\tLoss: 0.000734\n","Train Epoch: 11 [42240/155326 (27%)]\tLoss: 0.000592\n","Train Epoch: 11 [42880/155326 (28%)]\tLoss: 0.000866\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-068174fc00f5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-068174fc00f5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     train_losses, train_accuracies, test_losses, test_accuracies = train_and_evaluate(\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     )\n","\u001b[0;32m<ipython-input-11-068174fc00f5>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(args, model, device, train_loader, test_loader, optimizer, scheduler, criterion)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-068174fc00f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch, criterion)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}